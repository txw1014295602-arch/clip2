
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å¢å¼ºç‰ˆæ™ºèƒ½å‰ªè¾‘ç³»ç»Ÿ - è§£å†³æ‰€æœ‰é—®é¢˜çš„å®Œæ•´æ–¹æ¡ˆ
1. æ™ºèƒ½å‰§æƒ…ç±»å‹è¯†åˆ«ï¼Œä¸é™åˆ¶æ­»
2. å®Œæ•´ä¸Šä¸‹æ–‡åˆ†æï¼Œé¿å…å‰²è£‚
3. æ¯é›†å¤šä¸ªçŸ­è§†é¢‘ï¼ŒAIåˆ¤æ–­å®Œæ•´å†…å®¹
4. è‡ªåŠ¨å‰ªè¾‘ç”Ÿæˆè§†é¢‘å’Œæ—ç™½
5. ä¿æŒå‰§æƒ…è¿è´¯æ€§å’Œåè½¬å¤„ç†
"""

import os
import re
import json
import subprocess
from typing import List, Dict, Optional, Tuple
from api_config_helper import config_helper

class EnhancedIntelligentClipper:
    def __init__(self):
        self.config = config_helper.load_config()
        self.enabled = self.config.get('enabled', False)
        
        # åŠ¨æ€å‰§æƒ…å…ƒç´ åº“ï¼ˆä¸é™åˆ¶æ­»ï¼‰
        self.dynamic_elements = {
            'plot_keywords': [],  # åŠ¨æ€å­¦ä¹ å‰§æƒ…å…³é”®è¯
            'character_names': [],  # åŠ¨æ€è¯†åˆ«è§’è‰²å
            'key_locations': [],  # é‡è¦åœºæ™¯åœ°ç‚¹
            'emotional_markers': [],  # æƒ…æ„Ÿæ ‡è¯†è¯
            'tension_patterns': []  # å¼ åŠ›æ¨¡å¼
        }
        
        # å…¨å‰§æƒ…è®°å¿†ç³»ç»Ÿ
        self.plot_memory = {
            'character_arcs': {},  # è§’è‰²å‘å±•è½¨è¿¹
            'plot_threads': {},    # å‰§æƒ…çº¿ç´¢
            'foreshadowing': [],   # ä¼ç¬”è®°å½•
            'reveals': [],         # æ­éœ²æ—¶åˆ»
            'reversals': []        # åè½¬è®°å½•
        }
        
        # çŸ­è§†é¢‘æ ‡å‡†
        self.clip_standards = {
            'min_duration': 45,    # æœ€çŸ­45ç§’
            'max_duration': 180,   # æœ€é•¿3åˆ†é’Ÿ
            'ideal_duration': 90,  # ç†æƒ³1.5åˆ†é’Ÿ
            'sentence_buffer': 3   # ä¿è¯å¥å­å®Œæ•´çš„ç¼“å†²ç§’æ•°
        }

    def analyze_complete_episode(self, srt_file: str) -> Dict:
        """å®Œæ•´åˆ†æå•é›†ï¼Œä¸é€å¥è°ƒç”¨API"""
        print(f"ğŸ” å®Œæ•´åˆ†æ: {srt_file}")
        
        # è§£æå®Œæ•´å­—å¹•
        subtitles = self.parse_srt_file(srt_file)
        if not subtitles:
            return {}
        
        # æ„å»ºå®Œæ•´å‰§æƒ…æ–‡æœ¬ï¼ˆè§£å†³å†…å®¹ä¸è¿è´¯é—®é¢˜ï¼‰
        full_episode_text = self.build_coherent_text(subtitles)
        
        # ä¸€æ¬¡æ€§AIåˆ†ææ•´é›†ï¼ˆå¤§å¹…å‡å°‘APIè°ƒç”¨ï¼‰
        episode_analysis = self.ai_analyze_full_episode(full_episode_text, srt_file)
        
        # è¯†åˆ«å¤šä¸ªç²¾å½©ç‰‡æ®µ
        highlight_segments = self.identify_multiple_highlights(
            subtitles, episode_analysis, full_episode_text
        )
        
        # ç¡®ä¿å‰§æƒ…è¿è´¯æ€§
        coherent_clips = self.ensure_plot_coherence(highlight_segments, episode_analysis)
        
        return {
            'episode_file': srt_file,
            'full_analysis': episode_analysis,
            'highlight_clips': coherent_clips,
            'plot_context': self.extract_plot_context(episode_analysis),
            'next_episode_hooks': self.identify_episode_hooks(episode_analysis)
        }

    def parse_srt_file(self, srt_file: str) -> List[Dict]:
        """è§£æSRTå­—å¹•æ–‡ä»¶"""
        srt_path = os.path.join('srt', srt_file)
        if not os.path.exists(srt_path):
            print(f"âŒ å­—å¹•æ–‡ä»¶ä¸å­˜åœ¨: {srt_path}")
            return []
        
        try:
            with open(srt_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            # æ™ºèƒ½é”™è¯¯ä¿®æ­£
            content = self.fix_subtitle_errors(content)
            
            # è§£æSRTæ ¼å¼
            subtitles = []
            blocks = re.split(r'\n\s*\n', content.strip())
            
            for block in blocks:
                lines = block.strip().split('\n')
                if len(lines) >= 3:
                    try:
                        index = int(lines[0])
                        time_match = re.match(r'(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})', lines[1])
                        if time_match:
                            start_time = time_match.group(1)
                            end_time = time_match.group(2)
                            text = ' '.join(lines[2:]).strip()
                            
                            subtitles.append({
                                'index': index,
                                'start': start_time,
                                'end': end_time,
                                'text': text,
                                'start_seconds': self.time_to_seconds(start_time),
                                'end_seconds': self.time_to_seconds(end_time)
                            })
                    except (ValueError, IndexError):
                        continue
            
            print(f"  ğŸ“„ è§£æå®Œæˆ: {len(subtitles)} æ¡å­—å¹•")
            return subtitles
            
        except Exception as e:
            print(f"âŒ è§£æå­—å¹•å¤±è´¥: {e}")
            return []

    def fix_subtitle_errors(self, content: str) -> str:
        """æ™ºèƒ½ä¿®æ­£å­—å¹•é”™è¯¯"""
        corrections = {
            # å¸¸è§è¯­éŸ³è¯†åˆ«é”™è¯¯
            'é˜²è¡›': 'é˜²å«', 'æ­£ç•¶': 'æ­£å½“', 'è¨¼æ“š': 'è¯æ®', 'æª¢å¯Ÿå®˜': 'æ£€å¯Ÿå®˜',
            'ç™¼ç¾': 'å‘ç°', 'è¨­è¨ˆ': 'è®¾è®¡', 'é–‹å§‹': 'å¼€å§‹', 'çµæŸ': 'ç»“æŸ',
            'å•é¡Œ': 'é—®é¢˜', 'æ©Ÿæœƒ': 'æœºä¼š', 'æ±ºå®š': 'å†³å®š', 'é¸æ“‡': 'é€‰æ‹©',
            'è½è­‰æœƒ': 'å¬è¯ä¼š', 'è¾¯è­·': 'è¾©æŠ¤', 'å¯©åˆ¤': 'å®¡åˆ¤', 'èª¿æŸ¥': 'è°ƒæŸ¥',
            # å¸¸è§é”™éŸ³
            'æ³•ç®¡': 'æ³•å®˜', 'æ¡ˆå­': 'æ¡ˆä»¶', 'ä»€ä¹ˆ': 'ä»€ä¹ˆ', 'æ€ä¹ˆ': 'æ€ä¹ˆ'
        }
        
        for old, new in corrections.items():
            content = content.replace(old, new)
        
        return content

    def build_coherent_text(self, subtitles: List[Dict]) -> str:
        """æ„å»ºè¿è´¯çš„å®Œæ•´æ–‡æœ¬"""
        # æŒ‰æ—¶é—´åˆ†æ®µï¼Œæ¯æ®µ10-15åˆ†é’Ÿ
        segments = []
        current_segment = []
        segment_start_time = 0
        
        for subtitle in subtitles:
            current_segment.append(subtitle['text'])
            
            # æ¯10åˆ†é’Ÿæˆ–600ç§’åˆ†ä¸€æ®µ
            if subtitle['start_seconds'] - segment_start_time >= 600:
                segments.append(' '.join(current_segment))
                current_segment = []
                segment_start_time = subtitle['start_seconds']
        
        # æ·»åŠ æœ€åä¸€æ®µ
        if current_segment:
            segments.append(' '.join(current_segment))
        
        return '\n\n=== æ—¶é—´æ®µåˆ†å‰² ===\n\n'.join(segments)

    def ai_analyze_full_episode(self, full_text: str, episode_file: str) -> Dict:
        """ä¸€æ¬¡æ€§AIåˆ†ææ•´é›†ï¼ˆå‡å°‘APIè°ƒç”¨ï¼‰"""
        if not self.enabled:
            return self.fallback_analysis(full_text, episode_file)
        
        # æå–é›†æ•°
        episode_match = re.search(r'[Ee](\d+)', episode_file)
        episode_num = episode_match.group(1) if episode_match else "1"
        
        prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„å½±è§†å‰§æƒ…åˆ†æå¸ˆã€‚è¯·æ·±åº¦åˆ†æç¬¬{episode_num}é›†çš„å®Œæ•´å‰§æƒ…å†…å®¹ã€‚

ã€å®Œæ•´å‰§æƒ…æ–‡æœ¬ã€‘
{full_text[:4000]}...

ã€åˆ†æè¦æ±‚ã€‘
1. ä¸è¦é™åˆ¶å‰§æƒ…ç±»å‹ï¼Œæ ¹æ®å®é™…å†…å®¹åŠ¨æ€è¯†åˆ«
2. åˆ†æå®Œæ•´ä¸Šä¸‹æ–‡ï¼Œç†è§£å‰§æƒ…å‘å±•è„‰ç»œ
3. è¯†åˆ«3-5ä¸ªæœ€ç²¾å½©çš„ç‰‡æ®µï¼Œæ¯ä¸ªç‰‡æ®µè¦å®Œæ•´è¡¨è¾¾ä¸€ä¸ªæƒ…èŠ‚ç‚¹
4. åˆ†æè§’è‰²å…³ç³»å‘å±•å’Œæƒ…æ„Ÿå˜åŒ–
5. è¯†åˆ«ä¼ç¬”ã€åè½¬ã€æ­éœ²ç­‰å…³é”®å‰§æƒ…å…ƒç´ 
6. ç¡®ä¿ç‰‡æ®µä¹‹é—´æœ‰é€»è¾‘è¿è´¯æ€§

ã€è¾“å‡ºJSONæ ¼å¼ã€‘
{{
    "episode_theme": "æœ¬é›†æ ¸å¿ƒä¸»é¢˜",
    "genre_elements": ["åŠ¨æ€è¯†åˆ«çš„å‰§æƒ…å…ƒç´ "],
    "character_development": {{
        "ä¸»è¦è§’è‰²": "å‘å±•è½¨è¿¹æè¿°"
    }},
    "plot_threads": ["ä¸»è¦å‰§æƒ…çº¿ç´¢"],
    "highlight_moments": [
        {{
            "title": "ç‰‡æ®µæ ‡é¢˜",
            "plot_significance": "å‰§æƒ…é‡è¦æ€§",
            "emotional_peak": "æƒ…æ„Ÿé«˜æ½®ç‚¹",
            "time_estimate": "å¤§æ¦‚æ—¶é—´æ®µï¼ˆå¦‚ï¼šç¬¬15-18åˆ†é’Ÿï¼‰",
            "key_content": "æ ¸å¿ƒå†…å®¹æè¿°",
            "coherence_with_prev": "ä¸å‰é¢æƒ…èŠ‚çš„è”ç³»",
            "setup_for_next": "ä¸ºåç»­æƒ…èŠ‚çš„é“ºå«"
        }}
    ],
    "foreshadowing_elements": ["ä¼ç¬”å…ƒç´ "],
    "reveal_moments": ["æ­éœ²æ—¶åˆ»"],
    "plot_reversals": ["åè½¬æƒ…èŠ‚"],
    "episode_ending_hook": "æœ¬é›†ç»“å°¾çš„æ‚¬å¿µ",
    "overall_narrative_arc": "æ•´ä½“å™äº‹å¼§çº¿"
}}"""

        try:
            response = self.call_ai_api(prompt)
            if response:
                return self.parse_analysis_response(response, episode_file)
        except Exception as e:
            print(f"âš  AIåˆ†æå¤±è´¥: {e}")
        
        return self.fallback_analysis(full_text, episode_file)

    def identify_multiple_highlights(self, subtitles: List[Dict], 
                                   episode_analysis: Dict, 
                                   full_text: str) -> List[Dict]:
        """è¯†åˆ«å¤šä¸ªç²¾å½©ç‰‡æ®µ"""
        highlight_moments = episode_analysis.get('highlight_moments', [])
        
        if not highlight_moments:
            # ä½¿ç”¨å¤‡ç”¨æ–¹æ³•è¯†åˆ«
            return self.fallback_highlight_detection(subtitles)
        
        clips = []
        for i, moment in enumerate(highlight_moments):
            # æ ¹æ®AIåˆ†æçš„æ—¶é—´ä¼°è®¡æ‰¾åˆ°å¯¹åº”å­—å¹•ç‰‡æ®µ
            time_estimate = moment.get('time_estimate', '')
            
            # è§£ææ—¶é—´ä¼°è®¡ï¼ˆå¦‚ï¼š"ç¬¬15-18åˆ†é’Ÿ"ï¼‰
            time_match = re.search(r'(\d+)-(\d+)åˆ†é’Ÿ', time_estimate)
            if time_match:
                start_min = int(time_match.group(1))
                end_min = int(time_match.group(2))
                
                start_seconds = start_min * 60
                end_seconds = end_min * 60
                
                # æ‰¾åˆ°å¯¹åº”çš„å­—å¹•æ®µè½
                segment_subs = [sub for sub in subtitles 
                              if start_seconds <= sub['start_seconds'] <= end_seconds]
                
                if segment_subs:
                    # ç¡®ä¿å¥å­å®Œæ•´æ€§
                    refined_segment = self.ensure_sentence_completeness(
                        segment_subs, subtitles
                    )
                    
                    clips.append({
                        'clip_id': i + 1,
                        'title': moment.get('title', f'ç²¾å½©ç‰‡æ®µ{i+1}'),
                        'subtitles': refined_segment,
                        'plot_significance': moment.get('plot_significance', ''),
                        'emotional_peak': moment.get('emotional_peak', ''),
                        'key_content': moment.get('key_content', ''),
                        'coherence_info': {
                            'prev_connection': moment.get('coherence_with_prev', ''),
                            'next_setup': moment.get('setup_for_next', '')
                        }
                    })
        
        return clips

    def ensure_sentence_completeness(self, segment_subs: List[Dict], 
                                   all_subs: List[Dict]) -> List[Dict]:
        """ç¡®ä¿å¥å­å®Œæ•´æ€§"""
        if not segment_subs:
            return []
        
        # æ‰¾åˆ°æ®µè½åœ¨å…¨éƒ¨å­—å¹•ä¸­çš„ä½ç½®
        start_idx = None
        end_idx = None
        
        for i, sub in enumerate(all_subs):
            if sub['index'] == segment_subs[0]['index']:
                start_idx = i
            if sub['index'] == segment_subs[-1]['index']:
                end_idx = i
                break
        
        if start_idx is None or end_idx is None:
            return segment_subs
        
        # å‘å‰æ‰©å±•ï¼Œç¡®ä¿å¼€å¤´å¥å­å®Œæ•´
        while start_idx > 0:
            prev_sub = all_subs[start_idx - 1]
            if (prev_sub['text'].endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?')) or 
                segment_subs[0]['start_seconds'] - prev_sub['end_seconds'] > 3):
                break
            start_idx -= 1
        
        # å‘åæ‰©å±•ï¼Œç¡®ä¿ç»“å°¾å¥å­å®Œæ•´
        while end_idx < len(all_subs) - 1:
            current_sub = all_subs[end_idx]
            if (current_sub['text'].endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?')) or 
                all_subs[end_idx + 1]['start_seconds'] - current_sub['end_seconds'] > 3):
                break
            end_idx += 1
        
        return all_subs[start_idx:end_idx + 1]

    def ensure_plot_coherence(self, clips: List[Dict], episode_analysis: Dict) -> List[Dict]:
        """ç¡®ä¿å‰§æƒ…è¿è´¯æ€§"""
        if len(clips) <= 1:
            return clips
        
        # åˆ†æå‰§æƒ…çº¿ç´¢è¿æ¥
        plot_threads = episode_analysis.get('plot_threads', [])
        
        for i in range(len(clips)):
            current_clip = clips[i]
            
            # æ·»åŠ ä¸å‰ä¸€ä¸ªç‰‡æ®µçš„è¿æ¥è¯´æ˜
            if i > 0:
                current_clip['connection_to_prev'] = self.analyze_clip_connection(
                    clips[i-1], current_clip, plot_threads
                )
            
            # æ·»åŠ ä¸ºä¸‹ä¸€ä¸ªç‰‡æ®µçš„é“ºå«è¯´æ˜
            if i < len(clips) - 1:
                current_clip['setup_for_next'] = self.analyze_next_setup(
                    current_clip, clips[i+1], plot_threads
                )
        
        return clips

    def create_video_clips(self, episode_data: Dict) -> List[str]:
        """åˆ›å»ºå®é™…çš„è§†é¢‘ç‰‡æ®µ"""
        episode_file = episode_data['episode_file']
        clips_data = episode_data['highlight_clips']
        
        # æŸ¥æ‰¾å¯¹åº”è§†é¢‘æ–‡ä»¶
        video_file = self.find_matching_video(episode_file)
        if not video_file:
            print(f"âŒ æœªæ‰¾åˆ°å¯¹åº”è§†é¢‘: {episode_file}")
            return []
        
        print(f"ğŸ¬ å¼€å§‹å‰ªè¾‘: {os.path.basename(video_file)}")
        
        created_clips = []
        
        for clip_data in clips_data:
            clip_file = self.create_single_video_clip(video_file, clip_data, episode_file)
            if clip_file:
                # ç”Ÿæˆæ—ç™½æ–‡ä»¶
                narration_file = self.generate_narration_file(clip_file, clip_data, episode_data)
                created_clips.append({
                    'video_file': clip_file,
                    'narration_file': narration_file,
                    'clip_data': clip_data
                })
        
        return created_clips

    def create_single_video_clip(self, video_file: str, clip_data: Dict, episode_file: str) -> Optional[str]:
        """åˆ›å»ºå•ä¸ªè§†é¢‘ç‰‡æ®µ"""
        try:
            subtitles = clip_data['subtitles']
            if not subtitles:
                return None
            
            # è®¡ç®—æ—¶é—´èŒƒå›´
            start_time = subtitles[0]['start']
            end_time = subtitles[-1]['end']
            
            # æ·»åŠ ç¼“å†²ç¡®ä¿å®Œæ•´æ€§
            start_seconds = self.time_to_seconds(start_time) - self.clip_standards['sentence_buffer']
            end_seconds = self.time_to_seconds(end_time) + self.clip_standards['sentence_buffer']
            
            start_seconds = max(0, start_seconds)
            duration = end_seconds - start_seconds
            
            # æ£€æŸ¥æ—¶é•¿æ˜¯å¦åˆé€‚
            if duration < self.clip_standards['min_duration']:
                print(f"  âš  ç‰‡æ®µè¿‡çŸ­ï¼Œè·³è¿‡: {duration:.1f}ç§’")
                return None
            
            if duration > self.clip_standards['max_duration']:
                # æˆªå–åˆ°æœ€å¤§æ—¶é•¿
                duration = self.clip_standards['max_duration']
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            safe_title = re.sub(r'[^\w\u4e00-\u9fff]', '_', clip_data['title'])
            episode_num = re.search(r'[Ee](\d+)', episode_file)
            ep_num = episode_num.group(1) if episode_num else "1"
            
            output_name = f"E{ep_num}_{safe_title}.mp4"
            output_path = os.path.join('intelligent_clips', output_name)
            
            print(f"  ğŸ¯ å‰ªè¾‘ç‰‡æ®µ: {clip_data['title']} ({duration:.1f}ç§’)")
            
            # FFmpegå‰ªè¾‘å‘½ä»¤
            cmd = [
                'ffmpeg',
                '-i', video_file,
                '-ss', str(start_seconds),
                '-t', str(duration),
                '-c:v', 'libx264',
                '-c:a', 'aac',
                '-crf', '23',
                '-preset', 'medium',
                '-movflags', '+faststart',
                output_path,
                '-y'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0 and os.path.exists(output_path):
                file_size = os.path.getsize(output_path) / (1024 * 1024)
                print(f"    âœ… æˆåŠŸ: {output_name} ({file_size:.1f}MB)")
                return output_path
            else:
                print(f"    âŒ å¤±è´¥: {result.stderr[:100]}")
                return None
                
        except Exception as e:
            print(f"    âŒ å‰ªè¾‘å‡ºé”™: {e}")
            return None

    def generate_narration_file(self, video_file: str, clip_data: Dict, episode_data: Dict) -> str:
        """ç”Ÿæˆæ—ç™½è§£è¯´æ–‡ä»¶"""
        narration_path = video_file.replace('.mp4', '_æ—ç™½.txt')
        
        # æ„å»ºå®Œæ•´çš„å‰§æƒ…ç†è§£åˆ†æ
        narration_content = f"""ğŸ¬ çŸ­è§†é¢‘æ—ç™½è§£è¯´
{"=" * 50}

ğŸ“º ç‰‡æ®µæ ‡é¢˜: {clip_data['title']}
ğŸ“ å‰§æƒ…ç†è§£åˆ†æ:

ã€æ ¸å¿ƒå‰§æƒ…æ„ä¹‰ã€‘
{clip_data['plot_significance']}

ã€æƒ…æ„Ÿé«˜æ½®ç‚¹ã€‘
{clip_data['emotional_peak']}

ã€å…³é”®å†…å®¹è§£æã€‘
{clip_data['key_content']}

ã€ä¸å‰æƒ…çš„è”ç³»ã€‘
{clip_data.get('coherence_info', {}).get('prev_connection', 'æœ¬ç‰‡æ®µä¸ºç‹¬ç«‹æƒ…èŠ‚')}

ã€ä¸ºåç»­é“ºå«ã€‘
{clip_data.get('coherence_info', {}).get('next_setup', 'ä¸ºåç»­å‰§æƒ…å‘å±•å¥ å®šåŸºç¡€')}

ã€æ•´ä½“å™äº‹ä»·å€¼ã€‘
è¿™ä¸ªç‰‡æ®µåœ¨æ•´ä½“å‰§æƒ…ä¸­èµ·åˆ°äº†{clip_data['plot_significance']}çš„é‡è¦ä½œç”¨ï¼Œ
é€šè¿‡{clip_data['emotional_peak']}æ¥æ¨è¿›æ•…äº‹å‘å±•ï¼Œæ˜¯ç†è§£æ•´ä¸ªå‰§æƒ…çš„å…³é”®èŠ‚ç‚¹ã€‚

ã€è§‚ä¼—è§£è¯´è¯å»ºè®®ã€‘
"åœ¨è¿™ä¸ªç²¾å½©ç‰‡æ®µä¸­ï¼Œ{clip_data['title']}å±•ç°äº†{clip_data['plot_significance']}ã€‚
{clip_data['emotional_peak']}ï¼Œè®©è§‚ä¼—æ·±åˆ»æ„Ÿå—åˆ°å‰§æƒ…çš„å¼ åŠ›ã€‚
è¿™ä¸€æƒ…èŠ‚ä¸ä»…{clip_data.get('coherence_info', {}).get('prev_connection', 'å»¶ç»­äº†å‰é¢çš„å‘å±•')}ï¼Œ
æ›´ä¸º{clip_data.get('coherence_info', {}).get('next_setup', 'åç»­çš„å‘å±•')}åŸ‹ä¸‹äº†é‡è¦ä¼ç¬”ã€‚"

ã€æ—¶é—´è½´å¯¹åº”ã€‘
"""
        
        # æ·»åŠ è¯¦ç»†æ—¶é—´è½´
        for i, subtitle in enumerate(clip_data['subtitles'][:10]):  # æ˜¾ç¤ºå‰10æ¡
            narration_content += f"{subtitle['start']} --> {subtitle['end']}: {subtitle['text']}\n"
        
        if len(clip_data['subtitles']) > 10:
            narration_content += f"... è¿˜æœ‰ {len(clip_data['subtitles']) - 10} æ¡å­—å¹•\n"
        
        try:
            with open(narration_path, 'w', encoding='utf-8') as f:
                f.write(narration_content)
            
            print(f"    ğŸ“„ æ—ç™½æ–‡ä»¶: {os.path.basename(narration_path)}")
            return narration_path
            
        except Exception as e:
            print(f"    âš  ç”Ÿæˆæ—ç™½å¤±è´¥: {e}")
            return ""

    def find_matching_video(self, srt_file: str) -> Optional[str]:
        """æŸ¥æ‰¾åŒ¹é…çš„è§†é¢‘æ–‡ä»¶"""
        base_name = os.path.splitext(srt_file)[0]
        video_extensions = ['.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv']
        
        # æ£€æŸ¥videosç›®å½•
        videos_dir = 'videos'
        if not os.path.exists(videos_dir):
            return None
        
        # ç²¾ç¡®åŒ¹é…
        for ext in video_extensions:
            video_path = os.path.join(videos_dir, base_name + ext)
            if os.path.exists(video_path):
                return video_path
        
        # æ¨¡ç³ŠåŒ¹é…ï¼ˆé›†æ•°ï¼‰
        episode_match = re.search(r'[Ee](\d+)', base_name)
        if episode_match:
            episode_num = episode_match.group(1)
            
            for file in os.listdir(videos_dir):
                if any(file.lower().endswith(ext) for ext in video_extensions):
                    file_episode = re.search(r'[Ee](\d+)', file)
                    if file_episode and file_episode.group(1) == episode_num:
                        return os.path.join(videos_dir, file)
        
        return None

    def process_complete_series(self) -> Dict:
        """å¤„ç†å®Œæ•´å‰§é›†"""
        print("ğŸš€ å¯åŠ¨å¢å¼ºç‰ˆæ™ºèƒ½å‰ªè¾‘ç³»ç»Ÿ")
        print("=" * 60)
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs('intelligent_clips', exist_ok=True)
        
        # è·å–æ‰€æœ‰å­—å¹•æ–‡ä»¶
        srt_files = [f for f in os.listdir('srt') if f.endswith('.srt')]
        srt_files.sort()
        
        if not srt_files:
            print("âŒ srtç›®å½•ä¸­æ²¡æœ‰å­—å¹•æ–‡ä»¶")
            return {}
        
        print(f"ğŸ“º æ‰¾åˆ° {len(srt_files)} é›†")
        
        all_episodes_data = []
        all_created_clips = []
        
        # å¤„ç†æ¯ä¸€é›†
        for srt_file in srt_files:
            print(f"\n{'='*20} å¤„ç† {srt_file} {'='*20}")
            
            # å®Œæ•´åˆ†æå•é›†
            episode_data = self.analyze_complete_episode(srt_file)
            
            if episode_data:
                all_episodes_data.append(episode_data)
                
                # åˆ›å»ºè§†é¢‘ç‰‡æ®µ
                created_clips = self.create_video_clips(episode_data)
                all_created_clips.extend(created_clips)
                
                print(f"âœ… {srt_file}: åˆ›å»ºäº† {len(created_clips)} ä¸ªçŸ­è§†é¢‘")
        
        # ç”Ÿæˆè¿è´¯æ€§æŠ¥å‘Š
        self.generate_coherence_report(all_episodes_data, all_created_clips)
        
        return {
            'episodes_processed': len(all_episodes_data),
            'clips_created': len(all_created_clips),
            'episodes_data': all_episodes_data,
            'created_clips': all_created_clips
        }

    def generate_coherence_report(self, episodes_data: List[Dict], created_clips: List[Dict]):
        """ç”Ÿæˆå‰§æƒ…è¿è´¯æ€§æŠ¥å‘Š"""
        report_path = os.path.join('intelligent_clips', 'å®Œæ•´å‰§é›†è¿è´¯æ€§åˆ†æ.txt')
        
        content = f"""ğŸ“º å®Œæ•´å‰§é›†è¿è´¯æ€§åˆ†ææŠ¥å‘Š
{"=" * 80}

ğŸ“Š æ€»ä½“ç»Ÿè®¡:
â€¢ å¤„ç†é›†æ•°: {len(episodes_data)} é›†
â€¢ åˆ›å»ºçŸ­è§†é¢‘: {len(created_clips)} ä¸ª
â€¢ åˆ†ææ¨¡å¼: AIæ·±åº¦åˆ†æ + ä¸Šä¸‹æ–‡è¿è´¯

ğŸ­ å‰§æƒ…è¿è´¯æ€§åˆ†æ:
"""
        
        # åˆ†ææ¯é›†çš„ä¸»è¦å‰§æƒ…çº¿ç´¢
        for i, episode_data in enumerate(episodes_data, 1):
            content += f"\nç¬¬{i}é›† - {episode_data.get('full_analysis', {}).get('episode_theme', 'ä¸»è¦å‰§æƒ…')}:\n"
            
            plot_threads = episode_data.get('full_analysis', {}).get('plot_threads', [])
            for thread in plot_threads:
                content += f"  â€¢ {thread}\n"
            
            # æœ¬é›†çš„çŸ­è§†é¢‘ç‰‡æ®µ
            clips = episode_data.get('highlight_clips', [])
            content += f"  ğŸ“º æœ¬é›†çŸ­è§†é¢‘ç‰‡æ®µ ({len(clips)}ä¸ª):\n"
            
            for clip in clips:
                content += f"    - {clip['title']}: {clip['plot_significance']}\n"
        
        content += f"\nğŸ”— è·¨é›†è¿è´¯æ€§ä¿è¯:\n"
        content += "â€¢ æ¯ä¸ªçŸ­è§†é¢‘éƒ½åŒ…å«å®Œæ•´çš„æƒ…èŠ‚è¡¨è¾¾\n"
        content += "â€¢ ä¿æŒè§’è‰²å‘å±•è½¨è¿¹çš„ä¸€è‡´æ€§\n"
        content += "â€¢ é‡è¦ä¼ç¬”å’Œåè½¬éƒ½æœ‰å¯¹åº”å¤„ç†\n"
        content += "â€¢ ç¡®ä¿æ‰€æœ‰çŸ­è§†é¢‘ç»„åˆèƒ½å®Œæ•´å™è¿°æ•´ä¸ªæ•…äº‹\n"
        
        content += f"\nğŸ“„ ä½¿ç”¨è¯´æ˜:\n"
        content += "â€¢ æ¯ä¸ªçŸ­è§†é¢‘éƒ½æœ‰å¯¹åº”çš„æ—ç™½è§£è¯´æ–‡ä»¶\n"
        content += "â€¢ æ—ç™½æ–‡ä»¶è¯¦ç»†è§£é‡Šäº†å‰§æƒ…ç†è§£å’Œä¸Šä¸‹æ–‡å…³ç³»\n"
        content += "â€¢ å»ºè®®æŒ‰é›†æ•°é¡ºåºè§‚çœ‹ä»¥ä¿æŒæœ€ä½³å‰§æƒ…è¿è´¯æ€§\n"
        
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"\nğŸ“„ è¿è´¯æ€§æŠ¥å‘Š: {report_path}")
        except Exception as e:
            print(f"âš  ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")

    # è¾…åŠ©æ–¹æ³•
    def time_to_seconds(self, time_str: str) -> float:
        """æ—¶é—´è½¬æ¢ä¸ºç§’"""
        try:
            h, m, s_ms = time_str.split(':')
            s, ms = s_ms.split(',')
            return int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000
        except:
            return 0

    def call_ai_api(self, prompt: str) -> Optional[str]:
        """è°ƒç”¨AI API"""
        if not self.enabled:
            return None
        
        try:
            return config_helper.call_ai_api(prompt, self.config)
        except Exception as e:
            print(f"âš  AIè°ƒç”¨å¤±è´¥: {e}")
            return None

    def parse_analysis_response(self, response: str, episode_file: str) -> Dict:
        """è§£æAIåˆ†æå“åº”"""
        try:
            if "```json" in response:
                json_start = response.find("```json") + 7
                json_end = response.find("```", json_start)
                json_text = response[json_start:json_end]
            else:
                start = response.find("{")
                end = response.rfind("}") + 1
                json_text = response[start:end]
            
            return json.loads(json_text)
        
        except Exception as e:
            print(f"âš  è§£æAIå“åº”å¤±è´¥: {e}")
            return self.fallback_analysis("", episode_file)

    def fallback_analysis(self, full_text: str, episode_file: str) -> Dict:
        """å¤‡ç”¨åˆ†ææ–¹æ³•"""
        episode_match = re.search(r'[Ee](\d+)', episode_file)
        episode_num = episode_match.group(1) if episode_match else "1"
        
        return {
            'episode_theme': f'ç¬¬{episode_num}é›†ç²¾å½©å†…å®¹',
            'genre_elements': ['å‰§æƒ…å‘å±•'],
            'character_development': {},
            'plot_threads': ['ä¸»è¦æ•…äº‹çº¿'],
            'highlight_moments': [
                {
                    'title': f'ç¬¬{episode_num}é›†ç²¾å½©ç‰‡æ®µ',
                    'plot_significance': 'é‡è¦å‰§æƒ…å‘å±•',
                    'emotional_peak': 'æƒ…æ„Ÿé«˜æ½®',
                    'time_estimate': 'ç¬¬10-15åˆ†é’Ÿ',
                    'key_content': 'æ ¸å¿ƒå‰§æƒ…å†…å®¹',
                    'coherence_with_prev': 'å»¶ç»­å‰æƒ…å‘å±•',
                    'setup_for_next': 'ä¸ºåç»­é“ºå«'
                }
            ],
            'foreshadowing_elements': [],
            'reveal_moments': [],
            'plot_reversals': [],
            'episode_ending_hook': 'ç²¾å½©ç»§ç»­',
            'overall_narrative_arc': 'æ•…äº‹æ¨è¿›'
        }

    def fallback_highlight_detection(self, subtitles: List[Dict]) -> List[Dict]:
        """å¤‡ç”¨ç²¾å½©ç‰‡æ®µæ£€æµ‹"""
        # åŸºäºå…³é”®è¯çš„ç®€å•æ£€æµ‹
        keywords = ['å‘ç°', 'çœŸç›¸', 'ç§˜å¯†', 'çªç„¶', 'ä¸å¯èƒ½', 'éœ‡æƒŠ', 'åŸæ¥']
        
        clips = []
        for i, subtitle in enumerate(subtitles):
            if any(keyword in subtitle['text'] for keyword in keywords):
                # åˆ›å»ºå›´ç»•è¿™ä¸ªå­—å¹•çš„ç‰‡æ®µ
                start_idx = max(0, i - 20)
                end_idx = min(len(subtitles), i + 20)
                
                segment_subs = subtitles[start_idx:end_idx]
                
                clips.append({
                    'clip_id': len(clips) + 1,
                    'title': f'ç²¾å½©ç‰‡æ®µ{len(clips) + 1}',
                    'subtitles': segment_subs,
                    'plot_significance': 'é‡è¦å‰§æƒ…å‘å±•',
                    'emotional_peak': 'æƒ…æ„Ÿé«˜æ½®',
                    'key_content': subtitle['text'],
                    'coherence_info': {
                        'prev_connection': 'å»¶ç»­å‰æƒ…',
                        'next_setup': 'åç»­é“ºå«'
                    }
                })
                
                if len(clips) >= 3:  # æœ€å¤š3ä¸ª
                    break
        
        return clips

    def analyze_clip_connection(self, prev_clip: Dict, current_clip: Dict, plot_threads: List[str]) -> str:
        """åˆ†æç‰‡æ®µé—´çš„è¿æ¥"""
        return f"æ‰¿æ¥ä¸Šä¸€ç‰‡æ®µçš„{prev_clip['title']}ï¼Œé€šè¿‡{current_clip['emotional_peak']}è¿›ä¸€æ­¥æ¨è¿›å‰§æƒ…"

    def analyze_next_setup(self, current_clip: Dict, next_clip: Dict, plot_threads: List[str]) -> str:
        """åˆ†æå¯¹ä¸‹ä¸€ç‰‡æ®µçš„é“ºå«"""
        return f"é€šè¿‡{current_clip['emotional_peak']}ä¸º{next_clip['title']}åšäº†é‡è¦é“ºå«"

    def extract_plot_context(self, episode_analysis: Dict) -> Dict:
        """æå–å‰§æƒ…ä¸Šä¸‹æ–‡"""
        return {
            'main_threads': episode_analysis.get('plot_threads', []),
            'character_arcs': episode_analysis.get('character_development', {}),
            'foreshadowing': episode_analysis.get('foreshadowing_elements', []),
            'reveals': episode_analysis.get('reveal_moments', [])
        }

    def identify_episode_hooks(self, episode_analysis: Dict) -> List[str]:
        """è¯†åˆ«é›†é—´é’©å­"""
        return [episode_analysis.get('episode_ending_hook', 'ç²¾å½©ç»§ç»­')]

# è¿è¡Œå‡½æ•°
def run_enhanced_clipper():
    """è¿è¡Œå¢å¼ºç‰ˆå‰ªè¾‘å™¨"""
    clipper = EnhancedIntelligentClipper()
    result = clipper.process_complete_series()
    
    print(f"\nğŸ‰ å‰ªè¾‘å®Œæˆ!")
    print(f"ğŸ“º å¤„ç†äº† {result['episodes_processed']} é›†")
    print(f"ğŸ¬ åˆ›å»ºäº† {result['clips_created']} ä¸ªçŸ­è§†é¢‘")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: intelligent_clips/")
    print(f"ğŸ“„ æ¯ä¸ªçŸ­è§†é¢‘éƒ½æœ‰å¯¹åº”çš„æ—ç™½è§£è¯´æ–‡ä»¶")

if __name__ == "__main__":
    run_enhanced_clipper()
