#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç”µè§†å‰§AIåˆ†ææ¨¡å—
æ”¯æŒå®Œæ•´å‰§æƒ…åˆ†æã€ç¼“å­˜æœºåˆ¶ã€è·¨é›†è¿è´¯æ€§
"""

import os
import json
import hashlib
from typing import Dict, List, Optional


class TVAIAnalyzer:
    """ç”µè§†å‰§AIåˆ†æå™¨ - æ”¯æŒç¼“å­˜å’Œè·¨é›†è¿è´¯"""

    def __init__(self, ai_config: Dict, cache_folder: str = "tv_cache"):
        """åˆå§‹åŒ–AIåˆ†æå™¨"""
        self.ai_config = ai_config
        self.cache_folder = cache_folder
        os.makedirs(cache_folder, exist_ok=True)

    def analyze_episode(
        self,
        episode_name: str,
        subtitles: List[Dict],
        previous_context: Optional[Dict] = None
    ) -> Optional[Dict]:
        """
        åˆ†æå•é›†ç”µè§†å‰§

        Args:
            episode_name: é›†æ•°åç§°
            subtitles: å­—å¹•åˆ—è¡¨
            previous_context: ä¸Šä¸€é›†çš„è¡”æ¥ä¿¡æ¯

        Returns:
            åˆ†æç»“æœï¼ˆåŒ…å«å‰ªè¾‘ç‚¹ã€æ—ç™½ã€è¡”æ¥ä¿¡æ¯ï¼‰
        """
        # æ£€æŸ¥ç¼“å­˜
        cache_path = self._get_cache_path(episode_name, subtitles)
        cached_analysis = self._load_cache(cache_path)

        if cached_analysis:
            print(f"ğŸ’¾ ä½¿ç”¨ç¼“å­˜çš„AIåˆ†æç»“æœ")
            return cached_analysis

        # è°ƒç”¨AIåˆ†æ
        print(f"ğŸ¤– AIåˆ†æä¸­: {episode_name}")
        analysis = self._call_ai_for_analysis(episode_name, subtitles, previous_context)

        if not analysis:
            print(f"âŒ AIåˆ†æå¤±è´¥ï¼Œç›´æ¥è¿”å›")
            return None

        # ä¿å­˜ç¼“å­˜
        self._save_cache(cache_path, analysis)
        return analysis

    def _get_cache_path(self, episode_name: str, subtitles: List[Dict]) -> str:
        """ç”Ÿæˆç¼“å­˜è·¯å¾„ï¼ˆç¡®ä¿ä¸€è‡´æ€§ï¼‰"""
        # ä½¿ç”¨å­—å¹•å†…å®¹å“ˆå¸Œç¡®ä¿ç›¸åŒå­—å¹•å¾—åˆ°ç›¸åŒç»“æœ
        content_for_hash = json.dumps(
            [s['text'] for s in subtitles[:100]],  # ä½¿ç”¨å‰100æ¡å­—å¹•ç”Ÿæˆå“ˆå¸Œ
            ensure_ascii=False,
            sort_keys=True
        )
        content_hash = hashlib.md5(content_for_hash.encode()).hexdigest()[:16]

        safe_name = episode_name.replace('/', '_').replace('\\', '_')
        return os.path.join(self.cache_folder, f"analysis_{safe_name}_{content_hash}.json")

    def _load_cache(self, cache_path: str) -> Optional[Dict]:
        """åŠ è½½ç¼“å­˜"""
        if os.path.exists(cache_path):
            try:
                with open(cache_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸ ç¼“å­˜åŠ è½½å¤±è´¥: {e}")
        return None

    def _save_cache(self, cache_path: str, analysis: Dict) -> bool:
        """ä¿å­˜ç¼“å­˜"""
        try:
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(analysis, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ AIåˆ†æç»“æœå·²ç¼“å­˜")
            return True
        except Exception as e:
            print(f"âš ï¸ ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")
            return False

    def _call_ai_for_analysis(
        self,
        episode_name: str,
        subtitles: List[Dict],
        previous_context: Optional[Dict]
    ) -> Optional[Dict]:
        """è°ƒç”¨AIè¿›è¡Œå®Œæ•´å‰§æƒ…åˆ†æ"""
        if not self.ai_config.get('enabled'):
            print("âŒ AIæœªé…ç½®")
            return None

        # æ„å»ºå®Œæ•´å¯¹è¯å†…å®¹
        full_dialogue = self._build_full_dialogue(subtitles)

        # æ„å»ºAIæç¤ºè¯
        prompt = self._build_analysis_prompt(episode_name, full_dialogue, previous_context)

        # è°ƒç”¨AI API
        try:
            response = self._call_ai_api(prompt)
            if not response:
                return None

            # è§£æAIå“åº”
            analysis = self._parse_ai_response(response)
            return analysis

        except Exception as e:
            print(f"âŒ AIè°ƒç”¨å¼‚å¸¸: {e}")
            return None

    def _build_full_dialogue(self, subtitles: List[Dict]) -> str:
        """æ„å»ºå®Œæ•´å¯¹è¯å†…å®¹"""
        dialogue_lines = []
        for sub in subtitles:
            time_str = sub['start_time']
            text = sub['text']
            dialogue_lines.append(f"[{time_str}] {text}")

        return '\n'.join(dialogue_lines)

    def _build_analysis_prompt(
        self,
        episode_name: str,
        full_dialogue: str,
        previous_context: Optional[Dict]
    ) -> str:
        """æ„å»ºAIåˆ†ææç¤ºè¯"""

        # ä¸Šä¸€é›†è¡”æ¥ä¿¡æ¯
        context_section = ""
        if previous_context:
            context_section = f"""
ã€ä¸Šä¸€é›†è¡”æ¥ä¿¡æ¯ã€‘
ä¸»çº¿å‰§æƒ…: {previous_context.get('main_storyline', 'æ— ')}
å…³é”®äººç‰©: {', '.join(previous_context.get('key_characters', []))}
æœªè§£å†³çº¿ç´¢: {', '.join(previous_context.get('unresolved_clues', []))}
ä¸‹é›†é¢„å‘Š: {previous_context.get('next_episode_hint', 'æ— ')}
"""

        prompt = f"""ä½ æ˜¯ä¸–ç•Œé¡¶çº§çš„ç”µè§†å‰§åˆ†æå¤§å¸ˆã€‚è¯·å¯¹è¿™é›†ç”µè§†å‰§è¿›è¡Œ100% AIé©±åŠ¨çš„æ·±åº¦åˆ†æã€‚

ã€é›†æ•°ã€‘{episode_name}
{context_section}

ã€å®Œæ•´å¯¹è¯å†…å®¹ã€‘
{full_dialogue[:15000]}

è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

1. **å‰§æƒ…ç†è§£** - æ·±åº¦ç†è§£æœ¬é›†å®Œæ•´å‰§æƒ…ï¼Œè¯†åˆ«å…³é”®å‰§æƒ…ç‚¹
2. **ç²¾å½©ç‰‡æ®µè¯†åˆ«** - æ‰¾å‡º3-8ä¸ªæœ€ç²¾å½©çš„ç‰‡æ®µï¼ˆå…³é”®å†²çªã€äººç‰©è½¬æŠ˜ã€çº¿ç´¢æ­éœ²ç­‰ï¼‰
3. **å‰ªè¾‘ç‚¹è§„åˆ’** - æ¯ä¸ªç‰‡æ®µå¿…é¡»ä¿è¯å¯¹è¯å®Œæ•´ï¼Œä¸èƒ½åœ¨å¥å­ä¸­é—´æˆªæ–­
4. **æ—è§‚è€…å™è¿°** - ä¸ºæ¯ä¸ªç‰‡æ®µç”Ÿæˆè¯¦ç»†çš„æ—è§‚è€…è§†è§’å™è¿°ï¼ˆç¬¬ä¸‰äººç§°ï¼‰
5. **è·¨é›†è¿è´¯** - åˆ†ææœ¬é›†ä¸ä¸‹ä¸€é›†çš„è¡”æ¥ç‚¹

è¿”å›JSONæ ¼å¼ï¼š
{{
    "episode_name": "{episode_name}",
    "analysis_status": "success",
    "main_storyline": "æœ¬é›†ä¸»çº¿å‰§æƒ…æ¦‚è¿°",
    "key_characters": ["è§’è‰²1", "è§’è‰²2", "è§’è‰²3"],
    "story_summary": "æœ¬é›†å®Œæ•´æ•…äº‹æ€»ç»“",

    "highlight_clips": [
        {{
            "clip_id": 1,
            "title": "ç‰‡æ®µæ ‡é¢˜",
            "plot_type": "å‰§æƒ…ç‚¹ç±»å‹ï¼ˆå†²çª/è½¬æŠ˜/æ­éœ²/é«˜æ½®ç­‰ï¼‰",
            "start_time": "å¼€å§‹æ—¶é—´(HH:MM:SS,mmm)",
            "end_time": "ç»“æŸæ—¶é—´(HH:MM:SS,mmm)",
            "duration_seconds": å®é™…ç§’æ•°,
            "dialogue_content": "è¿™æ®µæ—¶é—´å†…çš„å®Œæ•´å¯¹è¯å†…å®¹",
            "narrator_commentary": {{
                "opening": "å¼€åœºæ—ç™½ï¼ˆä»‹ç»èƒŒæ™¯ï¼‰",
                "development": "å‘å±•æ—ç™½ï¼ˆè§£é‡Šè¿‡ç¨‹ï¼‰",
                "climax": "é«˜æ½®æ—ç™½ï¼ˆå¼ºè°ƒé‡ç‚¹ï¼‰",
                "conclusion": "ç»“å°¾æ—ç™½ï¼ˆæ€»ç»“æ„ä¹‰ï¼‰",
                "complete_narration": "å®Œæ•´è¿è´¯çš„æ—è§‚è€…å™è¿°"
            }},
            "why_exciting": "ä¸ºä»€ä¹ˆè¿™æ®µç²¾å½©",
            "key_moments": ["å…³é”®æ—¶åˆ»1", "å…³é”®æ—¶åˆ»2"],
            "connection_to_previous": "ä¸å‰é¢å‰§æƒ…çš„è”ç³»",
            "connection_to_next": "ä¸åç»­å‰§æƒ…çš„è”ç³»"
        }}
    ],

    "next_episode_connection": {{
        "main_storyline": "ä¸»çº¿å‰§æƒ…è¿›å±•",
        "unresolved_clues": ["æœªè§£å†³çš„çº¿ç´¢1", "æœªè§£å†³çš„çº¿ç´¢2"],
        "character_status": "ä¸»è¦è§’è‰²å½“å‰çŠ¶æ€",
        "next_episode_hint": "ä¸‹ä¸€é›†è¡”æ¥ç‚¹è¯´æ˜"
    }},

    "content_highlights": "æœ¬é›†å†…å®¹äº®ç‚¹æ€»ç»“",
    "editing_notes": "å‰ªè¾‘æ³¨æ„äº‹é¡¹"
}}

åˆ†æè¦æ±‚ï¼š
1. å¿…é¡»100% AIåˆ¤æ–­ï¼Œä¸ä½¿ç”¨ä»»ä½•é¢„è®¾è§„åˆ™
2. å‰ªè¾‘ç‚¹å¿…é¡»ä¿è¯å¯¹è¯å®Œæ•´ï¼Œä¸èƒ½åœ¨å¥å­ä¸­é—´æˆªæ–­
3. æ—è§‚è€…å™è¿°è¦è¯¦ç»†æ¸…æ™°ï¼Œå¸®åŠ©è§‚ä¼—ç†è§£å‰§æƒ…
4. æ‰€æœ‰çŸ­è§†é¢‘åˆèµ·æ¥èƒ½å®Œæ•´å™è¿°æœ¬é›†å‰§æƒ…
5. å¦‚æœæœ‰åè½¬ç­‰ç‰¹æ®Šæƒ…å†µï¼Œéœ€è¦åœ¨æ—ç™½ä¸­è”ç³»å‰é¢çš„å‰§æƒ…
6. å¦‚æœæ— æ³•å……åˆ†åˆ†æï¼Œè¯·è¿”å›åˆ†æå¤±è´¥çŠ¶æ€"""

        return prompt

    def _call_ai_api(self, prompt: str) -> Optional[str]:
        """è°ƒç”¨AI API"""
        config = self.ai_config

        try:
            if config.get('api_type') == 'official':
                return self._call_gemini_official(prompt, config)
            else:
                return self._call_proxy_api(prompt, config)
        except Exception as e:
            print(f"âš ï¸ APIè°ƒç”¨å¤±è´¥: {e}")
            return None

    def _call_gemini_official(self, prompt: str, config: Dict) -> Optional[str]:
        """è°ƒç”¨Geminiå®˜æ–¹API"""
        try:
            from google import genai

            client = genai.Client(api_key=config['api_key'])
            response = client.models.generate_content(
                model=config['model'],
                contents=prompt
            )
            return response.text
        except Exception as e:
            print(f"Gemini APIè°ƒç”¨å¤±è´¥: {e}")
            return None

    def _call_proxy_api(self, prompt: str, config: Dict) -> Optional[str]:
        """è°ƒç”¨ä¸­è½¬APIï¼ˆOpenAIå…¼å®¹ï¼‰"""
        try:
            from openai import OpenAI
            client = OpenAI(
                api_key=config['api_key'],
                base_url=config['base_url']
            )

            response = client.chat.completions.create(
                model=config['model'],
                messages=[
                    {'role': 'system', 'content': 'ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§åˆ†æå¸ˆï¼Œå¿…é¡»è¿›è¡Œ100% AIé©±åŠ¨çš„æ·±åº¦åˆ†æã€‚ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›ã€‚'},
                    {'role': 'user', 'content': prompt}
                ],
                max_tokens=8000,
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"ä¸­è½¬APIè°ƒç”¨å¤±è´¥: {e}")
            return None

    def _parse_ai_response(self, response: str) -> Optional[Dict]:
        """è§£æAIå“åº”"""
        try:
            # æå–JSONå†…å®¹
            if "```json" in response:
                start = response.find("```json") + 7
                end = response.find("```", start)
                json_str = response[start:end].strip()
            else:
                start = response.find("{")
                end = response.rfind("}") + 1
                if start >= 0 and end > start:
                    json_str = response[start:end]
                else:
                    return None

            analysis = json.loads(json_str)

            # éªŒè¯å¿…è¦å­—æ®µ
            if analysis.get('analysis_status') != 'success':
                print("âŒ AIåˆ†æçŠ¶æ€ä¸æ˜¯success")
                return None

            if not analysis.get('highlight_clips'):
                print("âŒ æ²¡æœ‰æ‰¾åˆ°ç²¾å½©ç‰‡æ®µ")
                return None

            print(f"âœ… AIåˆ†ææˆåŠŸï¼Œæ‰¾åˆ° {len(analysis['highlight_clips'])} ä¸ªç²¾å½©ç‰‡æ®µ")
            return analysis

        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSONè§£æé”™è¯¯: {e}")
            return None
