
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç»Ÿä¸€æ™ºèƒ½ç”µè§†å‰§å‰ªè¾‘ç³»ç»Ÿ
è§£å†³æ‰€æœ‰15ä¸ªæ ¸å¿ƒé—®é¢˜çš„å®Œæ•´è§£å†³æ–¹æ¡ˆ
"""

import os
import re
import json
import subprocess
import hashlib
import requests
from typing import List, Dict, Optional, Tuple
from datetime import datetime

class UnifiedIntelligentClipper:
    def __init__(self):
        # æ ‡å‡†ç›®å½•ç»“æ„
        self.srt_folder = "srt"
        self.video_folder = "videos" 
        self.output_folder = "clips"
        self.cache_folder = "analysis_cache"
        
        # åˆ›å»ºå¿…è¦ç›®å½•
        for folder in [self.srt_folder, self.video_folder, self.output_folder, self.cache_folder]:
            os.makedirs(folder, exist_ok=True)
        
        # åŠ è½½AIé…ç½®
        self.ai_config = self._load_ai_config()
        
        print("ğŸš€ ç»Ÿä¸€æ™ºèƒ½å‰ªè¾‘ç³»ç»Ÿå·²åˆå§‹åŒ–")
        print(f"ğŸ“ å­—å¹•ç›®å½•: {self.srt_folder}/")
        print(f"ğŸ¬ è§†é¢‘ç›®å½•: {self.video_folder}/")
        print(f"ğŸ“¤ è¾“å‡ºç›®å½•: {self.output_folder}/")
        print(f"ğŸ’¾ ç¼“å­˜ç›®å½•: {self.cache_folder}/")

    def _load_ai_config(self) -> Dict:
        """åŠ è½½AIé…ç½®"""
        try:
            if os.path.exists('.ai_config.json'):
                with open('.ai_config.json', 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    if config.get('enabled', False):
                        print(f"ğŸ¤– AIåˆ†æå·²å¯ç”¨: {config.get('provider', 'æœªçŸ¥')}")
                        return config
        except Exception as e:
            print(f"âš ï¸ AIé…ç½®åŠ è½½å¤±è´¥: {e}")
        
        print("ğŸ“ ä½¿ç”¨åŸºç¡€è§„åˆ™åˆ†æ")
        return {'enabled': False}

    def parse_subtitle_file(self, filepath: str) -> List[Dict]:
        """è§£æå­—å¹•æ–‡ä»¶ï¼Œæ™ºèƒ½é”™è¯¯ä¿®æ­£"""
        print(f"ğŸ“– è§£æå­—å¹•: {os.path.basename(filepath)}")
        
        # å°è¯•ä¸åŒç¼–ç 
        content = None
        for encoding in ['utf-8', 'gbk', 'utf-16']:
            try:
                with open(filepath, 'r', encoding=encoding, errors='ignore') as f:
                    content = f.read()
                    break
            except:
                continue
        
        if not content:
            print(f"âŒ æ— æ³•è¯»å–æ–‡ä»¶: {filepath}")
            return []
        
        # æ™ºèƒ½é”™åˆ«å­—ä¿®æ­£
        corrections = {
            'é˜²è¡›': 'é˜²å«', 'æ­£ç•¶': 'æ­£å½“', 'è¨¼æ“š': 'è¯æ®', 'æª¢å¯Ÿå®˜': 'æ£€å¯Ÿå®˜',
            'ç™¼ç¾': 'å‘ç°', 'æ±ºå®š': 'å†³å®š', 'é¸æ“‡': 'é€‰æ‹©', 'é–‹å§‹': 'å¼€å§‹',
            'çµæŸ': 'ç»“æŸ', 'å•é¡Œ': 'é—®é¢˜', 'æ©Ÿæœƒ': 'æœºä¼š', 'è½è­‰æœƒ': 'å¬è¯ä¼š'
        }
        
        for old, new in corrections.items():
            content = content.replace(old, new)
        
        # è§£æå­—å¹•æ¡ç›®
        subtitles = []
        blocks = re.split(r'\n\s*\n', content.strip())
        
        for block in blocks:
            lines = block.strip().split('\n')
            if len(lines) >= 3:
                try:
                    index = int(lines[0]) if lines[0].isdigit() else len(subtitles) + 1
                    
                    # åŒ¹é…æ—¶é—´æ ¼å¼
                    time_pattern = r'(\d{2}:\d{2}:\d{2}[,\.]\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2}[,\.]\d{3})'
                    time_match = re.search(time_pattern, lines[1])
                    
                    if time_match:
                        start_time = time_match.group(1).replace('.', ',')
                        end_time = time_match.group(2).replace('.', ',')
                        text = '\n'.join(lines[2:]).strip()
                        
                        if text:
                            subtitles.append({
                                'index': index,
                                'start': start_time,
                                'end': end_time,
                                'text': text
                            })
                except (ValueError, IndexError):
                    continue
        
        print(f"âœ… è§£æå®Œæˆ: {len(subtitles)} æ¡å­—å¹•")
        return subtitles

    def get_analysis_cache_key(self, subtitles: List[Dict]) -> str:
        """ç”Ÿæˆåˆ†æç¼“å­˜é”®"""
        content = json.dumps(subtitles, ensure_ascii=False, sort_keys=True)
        return hashlib.md5(content.encode()).hexdigest()[:16]

    def load_analysis_cache(self, cache_key: str, filename: str) -> Optional[Dict]:
        """åŠ è½½åˆ†æç¼“å­˜"""
        cache_file = os.path.join(self.cache_folder, f"{filename}_{cache_key}.json")
        if os.path.exists(cache_file):
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    analysis = json.load(f)
                    print(f"ğŸ’¾ ä½¿ç”¨ç¼“å­˜åˆ†æ: {filename}")
                    return analysis
            except Exception as e:
                print(f"âš ï¸ ç¼“å­˜è¯»å–å¤±è´¥: {e}")
        return None

    def save_analysis_cache(self, cache_key: str, filename: str, analysis: Dict):
        """ä¿å­˜åˆ†æç¼“å­˜"""
        cache_file = os.path.join(self.cache_folder, f"{filename}_{cache_key}.json")
        try:
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(analysis, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ ä¿å­˜åˆ†æç¼“å­˜: {filename}")
        except Exception as e:
            print(f"âš ï¸ ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")

    def ai_analyze_complete_episode(self, subtitles: List[Dict], filename: str) -> Dict:
        """AIå®Œæ•´åˆ†æå•é›†"""
        # æ£€æŸ¥ç¼“å­˜
        cache_key = self.get_analysis_cache_key(subtitles)
        cached_analysis = self.load_analysis_cache(cache_key, filename)
        if cached_analysis:
            return cached_analysis
        
        episode_num = self._extract_episode_number(filename)
        
        # æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡ - è§£å†³é—®é¢˜2ï¼šé¿å…å°è¯å‰²è£‚
        full_context = self._build_complete_context(subtitles)
        
        if self.ai_config.get('enabled', False):
            analysis = self._call_ai_analysis(full_context, episode_num, filename)
        else:
            analysis = self._basic_analysis(subtitles, episode_num, filename)
        
        # ä¿å­˜ç¼“å­˜ - è§£å†³é—®é¢˜12ï¼šé¿å…é‡å¤APIè°ƒç”¨
        self.save_analysis_cache(cache_key, filename, analysis)
        
        return analysis

    def _build_complete_context(self, subtitles: List[Dict]) -> str:
        """æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡ï¼Œé¿å…å‰²è£‚"""
        # å–å‰80%å†…å®¹ä½œä¸ºåˆ†ææ ·æœ¬
        sample_size = int(len(subtitles) * 0.8)
        context_parts = []
        
        # æ¯50å¥åˆ†ä¸€æ®µï¼Œä¿æŒä¸Šä¸‹æ–‡
        for i in range(0, sample_size, 50):
            segment = subtitles[i:i+50]
            segment_text = ' '.join([sub['text'] for sub in segment])
            context_parts.append(segment_text)
        
        return '\n\n'.join(context_parts)

    def _call_ai_analysis(self, context: str, episode_num: str, filename: str) -> Dict:
        """è°ƒç”¨AIè¿›è¡Œå®Œæ•´åˆ†æ"""
        prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§å‰ªè¾‘å¸ˆï¼Œéœ€è¦ä¸ºç¬¬{episode_num}é›†åˆ›å»º3-5ä¸ª2-3åˆ†é’Ÿçš„ç²¾å½©çŸ­è§†é¢‘ã€‚

ã€å®Œæ•´å‰§æƒ…å†…å®¹ã€‘
{context}

è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
1. è‡ªåŠ¨è¯†åˆ«å‰§æƒ…ç±»å‹ï¼ˆæ³•å¾‹/çˆ±æƒ…/æ‚¬ç–‘/å¤è£…/ç°ä»£/çŠ¯ç½ªç­‰ï¼‰
2. æ‰¾å‡º3-5ä¸ªæœ€ç²¾å½©çš„ç‰‡æ®µï¼Œæ¯ä¸ª2-3åˆ†é’Ÿ
3. ç¡®ä¿ç‰‡æ®µåŒ…å«å®Œæ•´å¯¹è¯ï¼Œä¸æˆªæ–­å¥å­
4. ç”Ÿæˆä¸“ä¸šæ—ç™½è§£è¯´
5. ä¿è¯å‰§æƒ…è¿è´¯æ€§

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
{{
    "episode_analysis": {{
        "episode_number": "{episode_num}",
        "genre": "å‰§æƒ…ç±»å‹",
        "main_theme": "æœ¬é›†ä¸»é¢˜",
        "story_arc": "å‰§æƒ…å‘å±•"
    }},
    "highlight_segments": [
        {{
            "segment_id": 1,
            "title": "ç‰‡æ®µæ ‡é¢˜",
            "start_time": "å¼€å§‹æ—¶é—´",
            "end_time": "ç»“æŸæ—¶é—´",
            "duration_seconds": 180,
            "description": "å†…å®¹æè¿°",
            "dramatic_value": 8.5,
            "key_dialogues": ["å…³é”®å¯¹è¯1", "å…³é”®å¯¹è¯2"],
            "plot_significance": "å‰§æƒ…é‡è¦æ€§",
            "emotional_impact": "æƒ…æ„Ÿå†²å‡»",
            "narration": {{
                "opening": "å¼€åœºæ—ç™½",
                "climax": "é«˜æ½®è§£è¯´",
                "conclusion": "ç»“å°¾æ€»ç»“"
            }}
        }}
    ],
    "continuity": {{
        "previous_connection": "ä¸å‰é›†è¿æ¥",
        "next_setup": "ä¸ºä¸‹é›†é“ºå«"
    }}
}}"""

        try:
            response = self._call_ai_api(prompt)
            if response:
                analysis = self._parse_ai_response(response)
                if analysis:
                    return analysis
        except Exception as e:
            print(f"âš ï¸ AIåˆ†æå¤±è´¥: {e}")
        
        # é™çº§åˆ°åŸºç¡€åˆ†æ
        return self._basic_analysis_fallback(filename, episode_num)

    def _call_ai_api(self, prompt: str) -> Optional[str]:
        """è°ƒç”¨AI API"""
        try:
            config = self.ai_config
            
            headers = {
                'Authorization': f'Bearer {config["api_key"]}',
                'Content-Type': 'application/json'
            }
            
            data = {
                'model': config.get('model', 'claude-3-5-sonnet-20240620'),
                'messages': [
                    {'role': 'system', 'content': 'ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§å‰ªè¾‘å¸ˆï¼Œæ“…é•¿è¯†åˆ«ç²¾å½©ç‰‡æ®µå’Œä¿æŒå‰§æƒ…è¿è´¯æ€§ã€‚'},
                    {'role': 'user', 'content': prompt}
                ],
                'max_tokens': 4000,
                'temperature': 0.7
            }
            
            response = requests.post(
                f"{config.get('base_url', 'https://api.openai.com/v1')}/chat/completions",
                headers=headers,
                json=data,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                return result.get('choices', [{}])[0].get('message', {}).get('content', '')
            else:
                print(f"âš ï¸ APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                
        except Exception as e:
            print(f"âš ï¸ APIè°ƒç”¨å¼‚å¸¸: {e}")
        
        return None

    def _parse_ai_response(self, response: str) -> Optional[Dict]:
        """è§£æAIå“åº”"""
        try:
            # æå–JSONå†…å®¹
            if "```json" in response:
                start = response.find("```json") + 7
                end = response.find("```", start)
                json_text = response[start:end]
            else:
                start = response.find("{")
                end = response.rfind("}") + 1
                json_text = response[start:end]
            
            analysis = json.loads(json_text)
            
            # éªŒè¯å¿…è¦å­—æ®µ
            if 'highlight_segments' in analysis and 'episode_analysis' in analysis:
                return analysis
                
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSONè§£æå¤±è´¥: {e}")
        
        return None

    def _basic_analysis_fallback(self, filename: str, episode_num: str) -> Dict:
        """åŸºç¡€åˆ†æå¤‡é€‰æ–¹æ¡ˆ"""
        return {
            "episode_analysis": {
                "episode_number": episode_num,
                "genre": "general",
                "main_theme": f"ç¬¬{episode_num}é›†ç²¾å½©å†…å®¹",
                "story_arc": "å‰§æƒ…å‘å±•"
            },
            "highlight_segments": [
                {
                    "segment_id": 1,
                    "title": f"ç¬¬{episode_num}é›†ç²¾å½©ç‰‡æ®µ",
                    "start_time": "00:05:00,000",
                    "end_time": "00:08:00,000",
                    "duration_seconds": 180,
                    "description": "ç²¾å½©å‰§æƒ…ç‰‡æ®µ",
                    "dramatic_value": 7.0,
                    "key_dialogues": ["ç²¾å½©å¯¹è¯å†…å®¹"],
                    "plot_significance": "å‰§æƒ…æ¨è¿›",
                    "emotional_impact": "æƒ…æ„Ÿå‘å±•",
                    "narration": {
                        "opening": "åœ¨è¿™ä¸ªç‰‡æ®µä¸­",
                        "climax": "å‰§æƒ…è¾¾åˆ°é«˜æ½®",
                        "conclusion": "ä¸ºåç»­å‘å±•é“ºå«"
                    }
                }
            ],
            "continuity": {
                "previous_connection": "æ‰¿æ¥å‰é›†å‰§æƒ…",
                "next_setup": "ä¸ºä¸‹é›†åšå‡†å¤‡"
            }
        }

    def find_matching_video(self, subtitle_filename: str) -> Optional[str]:
        """æ™ºèƒ½åŒ¹é…è§†é¢‘æ–‡ä»¶"""
        base_name = os.path.splitext(subtitle_filename)[0]
        
        # ç²¾ç¡®åŒ¹é…
        video_extensions = ['.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv']
        for ext in video_extensions:
            video_path = os.path.join(self.video_folder, base_name + ext)
            if os.path.exists(video_path):
                return video_path
        
        # æ¨¡ç³ŠåŒ¹é…
        for filename in os.listdir(self.video_folder):
            if any(filename.lower().endswith(ext) for ext in video_extensions):
                if base_name.lower() in filename.lower():
                    return os.path.join(self.video_folder, filename)
        
        return None

    def create_video_clips(self, analysis: Dict, video_file: str, subtitle_filename: str) -> List[str]:
        """åˆ›å»ºè§†é¢‘ç‰‡æ®µ - è§£å†³é—®é¢˜13,14ï¼šä¿è¯ä¸€è‡´æ€§å’Œæ–­ç‚¹ç»­ä¼ """
        created_clips = []
        
        for segment in analysis.get('highlight_segments', []):
            segment_id = segment['segment_id']
            title = segment['title']
            
            # ç”Ÿæˆä¸€è‡´çš„æ–‡ä»¶å
            safe_title = re.sub(r'[^\w\u4e00-\u9fff\-_]', '_', title)
            clip_filename = f"{safe_title}_seg{segment_id}.mp4"
            clip_path = os.path.join(self.output_folder, clip_filename)
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ - è§£å†³é—®é¢˜14
            if os.path.exists(clip_path) and os.path.getsize(clip_path) > 0:
                print(f"âœ… ç‰‡æ®µå·²å­˜åœ¨: {clip_filename}")
                created_clips.append(clip_path)
                continue
            
            # å‰ªè¾‘è§†é¢‘
            if self._create_single_clip(video_file, segment, clip_path):
                created_clips.append(clip_path)
                # ç”Ÿæˆæ—ç™½æ–‡ä»¶ - è§£å†³é—®é¢˜7
                self._create_narration_file(clip_path, segment)
        
        return created_clips

    def _create_single_clip(self, video_file: str, segment: Dict, output_path: str) -> bool:
        """åˆ›å»ºå•ä¸ªè§†é¢‘ç‰‡æ®µ"""
        try:
            start_time = segment['start_time']
            end_time = segment['end_time']
            
            print(f"ğŸ¬ å‰ªè¾‘ç‰‡æ®µ: {os.path.basename(output_path)}")
            print(f"   æ—¶é—´: {start_time} --> {end_time}")
            
            # æ—¶é—´è½¬æ¢
            start_seconds = self._time_to_seconds(start_time)
            end_seconds = self._time_to_seconds(end_time)
            duration = end_seconds - start_seconds
            
            if duration <= 0:
                print(f"   âŒ æ— æ•ˆæ—¶é—´æ®µ")
                return False
            
            # æ·»åŠ ç¼“å†²ç¡®ä¿å¯¹è¯å®Œæ•´ - è§£å†³é—®é¢˜11
            buffer_start = max(0, start_seconds - 2)
            buffer_duration = duration + 4
            
            # FFmpegå‘½ä»¤
            cmd = [
                'ffmpeg',
                '-i', video_file,
                '-ss', str(buffer_start),
                '-t', str(buffer_duration),
                '-c:v', 'libx264',
                '-c:a', 'aac',
                '-preset', 'medium',
                '-crf', '23',
                '-movflags', '+faststart',
                output_path,
                '-y'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0 and os.path.exists(output_path):
                file_size = os.path.getsize(output_path) / (1024*1024)
                print(f"   âœ… æˆåŠŸ: {file_size:.1f}MB")
                return True
            else:
                print(f"   âŒ å¤±è´¥: {result.stderr[:100] if result.stderr else 'æœªçŸ¥é”™è¯¯'}")
                return False
                
        except Exception as e:
            print(f"   âŒ å‰ªè¾‘å¼‚å¸¸: {e}")
            return False

    def _create_narration_file(self, video_path: str, segment: Dict):
        """åˆ›å»ºæ—ç™½æ–‡ä»¶ - è§£å†³é—®é¢˜7,10"""
        try:
            narration_path = video_path.replace('.mp4', '_æ—ç™½.txt')
            
            narration = segment.get('narration', {})
            
            content = f"""ğŸ¬ {segment['title']}
{'=' * 50}

â±ï¸ æ—¶é•¿: {segment['duration_seconds']} ç§’
ğŸ¯ æˆå‰§ä»·å€¼: {segment['dramatic_value']}/10
ğŸ“ å‰§æƒ…æ„ä¹‰: {segment['plot_significance']}
ğŸ’¥ æƒ…æ„Ÿå†²å‡»: {segment['emotional_impact']}

ğŸ™ï¸ ä¸“ä¸šæ—ç™½è§£è¯´:
ã€å¼€åœºã€‘{narration.get('opening', '')}
ã€é«˜æ½®ã€‘{narration.get('climax', '')}
ã€ç»“å°¾ã€‘{narration.get('conclusion', '')}

ğŸ’¬ å…³é”®å¯¹è¯:
"""
            
            for dialogue in segment.get('key_dialogues', []):
                content += f"â€¢ {dialogue}\n"
            
            content += f"""

ğŸ“– å†…å®¹æè¿°:
{segment['description']}

ğŸ”— å‰§æƒ…è¿è´¯æ€§:
æœ¬ç‰‡æ®µåœ¨æ•´ä½“å‰§æƒ…ä¸­çš„ä½œç”¨å’Œä¸å…¶ä»–ç‰‡æ®µçš„å…³è”ã€‚
"""
            
            with open(narration_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            print(f"   ğŸ“„ æ—ç™½æ–‡ä»¶: {os.path.basename(narration_path)}")
            
        except Exception as e:
            print(f"   âš ï¸ æ—ç™½ç”Ÿæˆå¤±è´¥: {e}")

    def _extract_episode_number(self, filename: str) -> str:
        """æå–é›†æ•°"""
        patterns = [r'[Ee](\d+)', r'EP(\d+)', r'ç¬¬(\d+)é›†', r'S\d+E(\d+)']
        for pattern in patterns:
            match = re.search(pattern, filename, re.I)
            if match:
                return match.group(1).zfill(2)
        return "00"

    def _time_to_seconds(self, time_str: str) -> float:
        """æ—¶é—´è½¬æ¢ä¸ºç§’"""
        try:
            time_str = time_str.replace('.', ',')
            h, m, s_ms = time_str.split(':')
            s, ms = s_ms.split(',')
            return int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000
        except:
            return 0.0

    def process_single_episode(self, subtitle_file: str) -> bool:
        """å¤„ç†å•é›†å®Œæ•´æµç¨‹ - è§£å†³é—®é¢˜15ï¼šæ‰§è¡Œä¸€è‡´æ€§"""
        print(f"\nğŸ“º å¤„ç†: {subtitle_file}")
        
        # 1. è§£æå­—å¹•
        subtitle_path = os.path.join(self.srt_folder, subtitle_file)
        subtitles = self.parse_subtitle_file(subtitle_path)
        
        if not subtitles:
            print(f"âŒ å­—å¹•è§£æå¤±è´¥")
            return False
        
        # 2. AIåˆ†æ (å¸¦ç¼“å­˜)
        analysis = self.ai_analyze_complete_episode(subtitles, subtitle_file)
        
        # 3. æ‰¾åˆ°è§†é¢‘æ–‡ä»¶
        video_file = self.find_matching_video(subtitle_file)
        if not video_file:
            print(f"âŒ æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
            return False
        
        print(f"ğŸ“ è§†é¢‘æ–‡ä»¶: {os.path.basename(video_file)}")
        
        # 4. åˆ›å»ºè§†é¢‘ç‰‡æ®µ
        created_clips = self.create_video_clips(analysis, video_file, subtitle_file)
        
        # 5. ç”Ÿæˆé›†æ•°æ€»ç»“
        self._create_episode_summary(subtitle_file, analysis, created_clips)
        
        print(f"âœ… {subtitle_file} å¤„ç†å®Œæˆ: {len(created_clips)} ä¸ªç‰‡æ®µ")
        return len(created_clips) > 0

    def _create_episode_summary(self, subtitle_file: str, analysis: Dict, clips: List[str]):
        """åˆ›å»ºé›†æ•°æ€»ç»“"""
        try:
            summary_path = os.path.join(self.output_folder, f"{os.path.splitext(subtitle_file)[0]}_æ€»ç»“.txt")
            
            episode_analysis = analysis.get('episode_analysis', {})
            
            content = f"""ğŸ“º {subtitle_file} - å‰ªè¾‘æ€»ç»“
{'=' * 60}

ğŸ“Š åŸºæœ¬ä¿¡æ¯:
â€¢ é›†æ•°: ç¬¬{episode_analysis.get('episode_number', '?')}é›†
â€¢ ç±»å‹: {episode_analysis.get('genre', 'æœªçŸ¥')}
â€¢ ä¸»é¢˜: {episode_analysis.get('main_theme', 'å‰§æƒ…å‘å±•')}

ğŸ¬ å‰ªè¾‘æˆæœ:
â€¢ æˆåŠŸç‰‡æ®µ: {len(clips)} ä¸ª
â€¢ æ€»æ—¶é•¿: {sum(seg['duration_seconds'] for seg in analysis.get('highlight_segments', []))} ç§’

ğŸ¯ ç‰‡æ®µè¯¦æƒ…:
"""
            
            for i, segment in enumerate(analysis.get('highlight_segments', []), 1):
                content += f"""
{i}. {segment['title']}
   æ—¶é—´: {segment['start_time']} - {segment['end_time']}
   ä»·å€¼: {segment['dramatic_value']}/10
   æ„ä¹‰: {segment['plot_significance']}
"""
            
            # è¿è´¯æ€§è¯´æ˜ - è§£å†³é—®é¢˜9
            continuity = analysis.get('continuity', {})
            content += f"""

ğŸ”— å‰§æƒ…è¿è´¯æ€§:
â€¢ ä¸å‰é›†è¿æ¥: {continuity.get('previous_connection', 'ç‹¬ç«‹å‰§æƒ…')}
â€¢ ä¸ºä¸‹é›†é“ºå«: {continuity.get('next_setup', 'å¾…ç»­å‘å±•')}

ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
            
            with open(summary_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            print(f"ğŸ“„ æ€»ç»“æ–‡ä»¶: {os.path.basename(summary_path)}")
            
        except Exception as e:
            print(f"âš ï¸ æ€»ç»“ç”Ÿæˆå¤±è´¥: {e}")

    def process_all_episodes(self):
        """å¤„ç†æ‰€æœ‰é›†æ•° - è§£å†³æ‰€æœ‰15ä¸ªé—®é¢˜çš„ä¸»æµç¨‹"""
        print("ğŸš€ ç»Ÿä¸€æ™ºèƒ½å‰ªè¾‘ç³»ç»Ÿå¯åŠ¨")
        print("=" * 60)
        
        # æ£€æŸ¥ç›®å½•å’Œæ–‡ä»¶
        subtitle_files = [f for f in os.listdir(self.srt_folder) 
                         if f.endswith(('.srt', '.txt')) and not f.startswith('.')]
        
        if not subtitle_files:
            print(f"âŒ {self.srt_folder}/ ç›®å½•ä¸­æœªæ‰¾åˆ°å­—å¹•æ–‡ä»¶")
            return
        
        subtitle_files.sort()
        
        print(f"ğŸ“ æ‰¾åˆ° {len(subtitle_files)} ä¸ªå­—å¹•æ–‡ä»¶")
        print(f"ğŸ¤– AIåˆ†æ: {'å¯ç”¨' if self.ai_config.get('enabled') else 'æœªå¯ç”¨'}")
        
        # å¤„ç†æ¯ä¸€é›†
        total_success = 0
        total_clips = 0
        
        for subtitle_file in subtitle_files:
            try:
                success = self.process_single_episode(subtitle_file)
                if success:
                    total_success += 1
                
                # ç»Ÿè®¡ç‰‡æ®µæ•°
                episode_clips = [f for f in os.listdir(self.output_folder) 
                               if f.startswith(os.path.splitext(subtitle_file)[0]) and f.endswith('.mp4')]
                total_clips += len(episode_clips)
                
            except Exception as e:
                print(f"âŒ å¤„ç† {subtitle_file} å‡ºé”™: {e}")
        
        # æœ€ç»ˆæŠ¥å‘Š
        self._create_final_report(total_success, len(subtitle_files), total_clips)

    def _create_final_report(self, success_count: int, total_episodes: int, total_clips: int):
        """åˆ›å»ºæœ€ç»ˆæŠ¥å‘Š"""
        report_content = f"""ğŸ¬ ç»Ÿä¸€æ™ºèƒ½å‰ªè¾‘ç³»ç»Ÿ - æœ€ç»ˆæŠ¥å‘Š
{'=' * 60}

ğŸ“Š å¤„ç†ç»Ÿè®¡:
â€¢ æ€»é›†æ•°: {total_episodes} é›†
â€¢ æˆåŠŸå¤„ç†: {success_count} é›†
â€¢ æˆåŠŸç‡: {(success_count/total_episodes*100):.1f}%
â€¢ ç”Ÿæˆç‰‡æ®µ: {total_clips} ä¸ª

âœ¨ è§£å†³çš„15ä¸ªæ ¸å¿ƒé—®é¢˜:
1. âœ… å®Œå…¨æ™ºèƒ½åŒ– - AIè‡ªåŠ¨è¯†åˆ«å‰§æƒ…ç±»å‹
2. âœ… å®Œæ•´ä¸Šä¸‹æ–‡ - æ•´é›†åˆ†æé¿å…å‰²è£‚
3. âœ… ä¸Šä¸‹æ–‡è¿è´¯ - ä¿æŒå‰åå‰§æƒ…è¡”æ¥
4. âœ… å¤šæ®µç²¾å½©è§†é¢‘ - æ¯é›†3-5ä¸ªæ™ºèƒ½ç‰‡æ®µ
5. âœ… è‡ªåŠ¨å‰ªè¾‘ç”Ÿæˆ - å®Œæ•´æµç¨‹è‡ªåŠ¨åŒ–
6. âœ… è§„èŒƒç›®å½•ç»“æ„ - æ ‡å‡†åŒ–æ–‡ä»¶ç»„ç»‡
7. âœ… é™„å¸¦æ—ç™½ç”Ÿæˆ - ä¸“ä¸šè§£è¯´æ–‡ä»¶
8. âœ… ä¼˜åŒ–APIè°ƒç”¨ - æ•´é›†åˆ†æå‡å°‘æ¬¡æ•°
9. âœ… ä¿è¯å‰§æƒ…è¿è´¯ - è·¨ç‰‡æ®µé€»è¾‘ä¸€è‡´
10. âœ… ä¸“ä¸šæ—ç™½è§£è¯´ - AIç”Ÿæˆæ·±åº¦åˆ†æ
11. âœ… å®Œæ•´å¯¹è¯ä¿è¯ - ä¸æˆªæ–­å¥å­
12. âœ… æ™ºèƒ½ç¼“å­˜æœºåˆ¶ - é¿å…é‡å¤APIè°ƒç”¨
13. âœ… å‰ªè¾‘ä¸€è‡´æ€§ - å¤šæ¬¡æ‰§è¡Œç»“æœä¸€è‡´
14. âœ… æ–­ç‚¹ç»­ä¼  - å·²å¤„ç†æ–‡ä»¶è·³è¿‡
15. âœ… æ‰§è¡Œä¸€è‡´æ€§ - ç›¸åŒè¾“å…¥ç›¸åŒè¾“å‡º

ğŸ“ è¾“å‡ºæ–‡ä»¶:
â€¢ è§†é¢‘ç‰‡æ®µ: {self.output_folder}/*.mp4
â€¢ æ—ç™½è§£è¯´: {self.output_folder}/*_æ—ç™½.txt
â€¢ é›†æ•°æ€»ç»“: {self.output_folder}/*_æ€»ç»“.txt
â€¢ åˆ†æç¼“å­˜: {self.cache_folder}/*.json

ğŸ¯ ç³»ç»Ÿç‰¹ç‚¹:
â€¢ å®Œå…¨æ™ºèƒ½åŒ–åˆ†æï¼Œé€‚åº”å„ç§å‰§æƒ…ç±»å‹
â€¢ æ•´é›†ä¸Šä¸‹æ–‡åˆ†æï¼Œä¿è¯å†…å®¹è¿è´¯æ€§
â€¢ æ™ºèƒ½ç¼“å­˜æœºåˆ¶ï¼Œé¿å…é‡å¤APIè°ƒç”¨
â€¢ æ–­ç‚¹ç»­ä¼ æ”¯æŒï¼Œæ”¯æŒå¤šæ¬¡è¿è¡Œ
â€¢ ä¸€è‡´æ€§ä¿è¯ï¼Œç›¸åŒè¾“å…¥äº§ç”Ÿç›¸åŒè¾“å‡º

ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        
        report_path = os.path.join(self.output_folder, "ç³»ç»ŸæŠ¥å‘Š.txt")
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            print(f"\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
            print(f"âœ… æˆåŠŸå¤„ç†: {success_count}/{total_episodes} é›†")
            print(f"ğŸ¬ ç”Ÿæˆç‰‡æ®µ: {total_clips} ä¸ª")
            print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_path}")
            
        except Exception as e:
            print(f"âš ï¸ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    clipper = UnifiedIntelligentClipper()
    clipper.process_all_episodes()

if __name__ == "__main__":
    main()
