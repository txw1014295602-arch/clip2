
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ™ºèƒ½AIç”µè§†å‰§å‰ªè¾‘ç³»ç»Ÿ - åŸºäºå¤§æ¨¡å‹çš„è‡ªé€‚åº”åˆ†æ
ç‰¹ç‚¹ï¼š
1. AIé©±åŠ¨åˆ†æï¼Œè‡ªé€‚åº”å„ç§å‰§æƒ…ç±»å‹
2. æ™ºèƒ½é”™åˆ«å­—ä¿®æ­£å’Œæ ¼å¼å…¼å®¹
3. æ¯é›†ç²¾é€‰ä¸€ä¸ª2-3åˆ†é’Ÿæ ¸å¿ƒç‰‡æ®µ
4. è·¨é›†å‰§æƒ…è¿è´¯æ€§ä¿è¯
5. æ”¯æŒå¤šç§AIæ¨¡å‹æ¥å£
"""

import os
import re
import json
import subprocess
import requests
from typing import List, Dict, Optional, Tuple
from datetime import datetime

class IntelligentAIClipper:
    def __init__(self, video_folder: str = "videos", output_folder: str = "ai_clips"):
        self.video_folder = video_folder
        self.output_folder = output_folder
        
        # åˆ›å»ºå¿…è¦ç›®å½•
        for folder in [self.video_folder, self.output_folder]:
            if not os.path.exists(folder):
                os.makedirs(folder)
                print(f"âœ“ åˆ›å»ºç›®å½•: {folder}/")
        
        # AIé…ç½®
        self.ai_config = self.load_ai_config()
        
        # å‰§æƒ…è¿è´¯æ€§ç¼“å­˜
        self.episode_summaries = []
        self.previous_episode_ending = ""

    def load_ai_config(self) -> Dict:
        """åŠ è½½AIé…ç½®"""
        try:
            with open('.ai_config.json', 'r', encoding='utf-8') as f:
                config = json.load(f)
                if config.get('enabled', False) and config.get('api_key'):
                    print(f"âœ… AIåˆ†æå·²å¯ç”¨: {config.get('provider', 'unknown')} / {config.get('model', 'unknown')}")
                    return config
        except:
            pass
        
        # å°è¯•ä»ç¯å¢ƒå˜é‡è·å–
        import os
        api_key = os.environ.get('AI_API_KEY') or os.environ.get('OPENAI_API_KEY')
        if api_key:
            return {
                'enabled': True,
                'api_key': api_key,
                'base_url': 'https://api.openai.com/v1',
                'model': 'gpt-3.5-turbo'
            }
        
        print("âš ï¸ AIåˆ†ææœªé…ç½®ï¼Œå°†ä½¿ç”¨åŸºç¡€è§„åˆ™åˆ†æ")
        return {'enabled': False}

    def parse_subtitle_file(self, filepath: str) -> List[Dict]:
        """æ™ºèƒ½è§£æå­—å¹•æ–‡ä»¶ï¼Œæ”¯æŒå¤šç§æ ¼å¼å’Œç¼–ç """
        subtitles = []
        
        # å°è¯•ä¸åŒç¼–ç 
        encodings = ['utf-8', 'gbk', 'utf-16', 'gb2312', 'big5']
        content = None
        
        for encoding in encodings:
            try:
                with open(filepath, 'r', encoding=encoding, errors='ignore') as f:
                    content = f.read()
                    break
            except:
                continue
        
        if not content:
            print(f"âŒ æ— æ³•è¯»å–æ–‡ä»¶: {filepath}")
            return []
        
        # æ™ºèƒ½é”™åˆ«å­—ä¿®æ­£ï¼ˆæ‰©å±•ç‰ˆï¼‰
        corrections = {
            # ç¹ä½“å­—ä¿®æ­£
            'è­‰æ“š': 'è¯æ®', 'æª¢å¯Ÿå®˜': 'æ£€å¯Ÿå®˜', 'å¯©åˆ¤': 'å®¡åˆ¤', 'è¾¯è­·': 'è¾©æŠ¤',
            'ç™¼ç¾': 'å‘ç°', 'æ±ºå®š': 'å†³å®š', 'é¸æ“‡': 'é€‰æ‹©', 'é–‹å§‹': 'å¼€å§‹',
            'çµæŸ': 'ç»“æŸ', 'å•é¡Œ': 'é—®é¢˜', 'æ©Ÿæœƒ': 'æœºä¼š', 'è½è­‰æœƒ': 'å¬è¯ä¼š',
            'èª¿æŸ¥': 'è°ƒæŸ¥', 'èµ·è¨´': 'èµ·è¯‰', 'ç„¡ç½ª': 'æ— ç½ª', 'æœ‰ç½ª': 'æœ‰ç½ª',
            # å¸¸è§é”™å­—ä¿®æ­£
            'é˜²è¡›': 'é˜²å«', 'æ­£ç•¶': 'æ­£å½“', 'å®Ÿç¾': 'å®ç°', 'å¯¾è©±': 'å¯¹è¯',
            'é–¢ä¿‚': 'å…³ç³»', 'å®Ÿé™…': 'å®é™…', 'å¯¾äº': 'å¯¹äº', 'å¤‰åŒ–': 'å˜åŒ–',
            'åé›†': 'æ”¶é›†', 'å‡¦ç†': 'å¤„ç†', 'ç¢ºèª': 'ç¡®è®¤', 'æƒ…å ±': 'æƒ…æŠ¥'
        }
        
        for old, new in corrections.items():
            content = content.replace(old, new)
        
        # æ™ºèƒ½åˆ†å‰²å­—å¹•å—ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
        if '-->' in content:
            # SRTæ ¼å¼
            blocks = re.split(r'\n\s*\n', content.strip())
            for block in blocks:
                lines = block.strip().split('\n')
                if len(lines) >= 3:
                    try:
                        index = int(lines[0]) if lines[0].isdigit() else len(subtitles) + 1
                        
                        time_match = re.search(r'(\d{2}:\d{2}:\d{2}[,\.]\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2}[,\.]\d{3})', lines[1])
                        if time_match:
                            start_time = time_match.group(1).replace('.', ',')
                            end_time = time_match.group(2).replace('.', ',')
                            text = '\n'.join(lines[2:]).strip()
                            
                            if text:
                                subtitles.append({
                                    'index': index,
                                    'start': start_time,
                                    'end': end_time,
                                    'text': text,
                                    'episode': os.path.basename(filepath)
                                })
                    except (ValueError, IndexError):
                        continue
        else:
            # ç®€å•æ–‡æœ¬æ ¼å¼ï¼Œç”Ÿæˆè™šæ‹Ÿæ—¶é—´æˆ³
            lines = content.split('\n')
            for i, line in enumerate(lines):
                line = line.strip()
                if line and not line.isdigit():
                    start_seconds = i * 3
                    end_seconds = start_seconds + 3
                    start_time = f"00:{start_seconds//60:02d}:{start_seconds%60:02d},000"
                    end_time = f"00:{end_seconds//60:02d}:{end_seconds%60:02d},000"
                    
                    subtitles.append({
                        'index': i + 1,
                        'start': start_time,
                        'end': end_time,
                        'text': line,
                        'episode': os.path.basename(filepath)
                    })
        
        print(f"âœ“ è§£æå­—å¹•: {len(subtitles)} æ¡")
        return subtitles

    def ai_analyze_episode(self, subtitles: List[Dict], episode_num: str) -> Dict:
        """ä½¿ç”¨AIåˆ†ææ•´é›†å†…å®¹ï¼Œæ‰¾å‡ºæœ€ç²¾å½©ç‰‡æ®µ"""
        
        # å‡†å¤‡åˆ†æå†…å®¹ï¼ˆé€‰æ‹©æœ‰ä»£è¡¨æ€§çš„å¯¹è¯ï¼‰
        sample_dialogues = []
        for i in range(0, len(subtitles), max(1, len(subtitles) // 50)):  # å–çº¦50ä¸ªæ ·æœ¬
            if i < len(subtitles):
                sub = subtitles[i]
                sample_dialogues.append(f"[{sub['start']}] {sub['text']}")
        
        content_sample = '\n'.join(sample_dialogues)
        
        # æ„å»ºAIåˆ†ææç¤ºè¯
        prompt = self._build_analysis_prompt(content_sample, episode_num)
        
        if self.ai_config.get('enabled', False):
            ai_result = self._call_ai_api(prompt)
            if ai_result:
                try:
                    analysis = json.loads(ai_result)
                    return self._process_ai_analysis(analysis, subtitles, episode_num)
                except json.JSONDecodeError:
                    print(f"âš ï¸ AIè¿”å›æ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨å¤‡ç”¨åˆ†æ")
        
        # å¤‡ç”¨åˆ†ææ–¹æ³•
        return self._fallback_analysis(subtitles, episode_num)

    def _build_analysis_prompt(self, content: str, episode_num: str) -> str:
        """æ„å»ºAIåˆ†ææç¤ºè¯"""
        
        # è€ƒè™‘å‰ä¸€é›†çš„ç»“å°¾ï¼Œä¿æŒè¿è´¯æ€§
        context = ""
        if self.previous_episode_ending:
            context = f"\nã€å‰ä¸€é›†ç»“å°¾ã€‘: {self.previous_episode_ending}\n"
        
        return f"""ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§å‰ªè¾‘å¸ˆï¼Œéœ€è¦ä¸ºç¬¬{episode_num}é›†é€‰æ‹©æœ€ç²¾å½©çš„2-3åˆ†é’Ÿç‰‡æ®µåˆ¶ä½œçŸ­è§†é¢‘ã€‚

{context}
ã€æœ¬é›†å¯¹è¯å†…å®¹ã€‘:
{content}

è¯·åˆ†æè¿™ä¸€é›†çš„å†…å®¹ï¼Œå¹¶è¿”å›JSONæ ¼å¼çš„åˆ†æç»“æœï¼š

{{
    "genre": "å‰§æƒ…ç±»å‹(å¦‚:æ³•å¾‹å‰§/çˆ±æƒ…å‰§/çŠ¯ç½ªå‰§/å¤è£…å‰§/ç°ä»£å‰§ç­‰)",
    "theme": "æœ¬é›†æ ¸å¿ƒä¸»é¢˜",
    "best_segment": {{
        "start_time": "æ¨èç‰‡æ®µå¼€å§‹æ—¶é—´(æ ¼å¼:HH:MM:SS,mmm)",
        "end_time": "æ¨èç‰‡æ®µç»“æŸæ—¶é—´(æ ¼å¼:HH:MM:SS,mmm)",
        "reason": "é€‰æ‹©è¿™ä¸ªç‰‡æ®µçš„åŸå› ",
        "content_summary": "ç‰‡æ®µå†…å®¹æ¦‚è¦"
    }},
    "plot_significance": "è¿™ä¸ªç‰‡æ®µçš„å‰§æƒ…é‡è¦æ€§",
    "emotional_peak": "æƒ…æ„Ÿé«˜æ½®ç‚¹æè¿°",
    "key_dialogues": ["å…³é”®å°è¯1", "å…³é”®å°è¯2", "å…³é”®å°è¯3"],
    "next_episode_connection": "ä¸ä¸‹ä¸€é›†çš„è¡”æ¥ç‚¹æè¿°",
    "content_highlights": ["äº®ç‚¹1", "äº®ç‚¹2", "äº®ç‚¹3"]
}}

é€‰æ‹©æ ‡å‡†ï¼š
1. å‰§æƒ…æ¨è¿›æœ€é‡è¦çš„åœºæ™¯
2. æƒ…æ„Ÿå†²çªæœ€æ¿€çƒˆçš„å¯¹è¯
3. ä¿¡æ¯å¯†åº¦æœ€é«˜çš„ç‰‡æ®µ
4. èƒ½å¤Ÿç‹¬ç«‹æˆç¯‡çš„å®Œæ•´åœºæ™¯
5. ä¸æ•´ä½“æ•…äº‹çº¿è¿è´¯çš„å…³é”®èŠ‚ç‚¹

æ—¶é—´ç‰‡æ®µè¦ç¡®ä¿å®Œæ•´å¯¹è¯åœºæ™¯ï¼Œä¸è¦æˆªæ–­é‡è¦å¯¹è¯ã€‚"""

    def _call_ai_api(self, prompt: str) -> Optional[str]:
        """è°ƒç”¨AI API"""
        try:
            config = self.ai_config
            
            headers = {
                'Authorization': f'Bearer {config["api_key"]}',
                'Content-Type': 'application/json'
            }
            
            # æ„å»ºè¯·æ±‚æ•°æ®
            data = {
                'model': config.get('model', 'gpt-3.5-turbo'),
                'messages': [
                    {
                        'role': 'system', 
                        'content': 'ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§å‰ªè¾‘å¸ˆï¼Œæ“…é•¿è¯†åˆ«å‰§æƒ…é«˜æ½®å’Œç²¾å½©ç‰‡æ®µã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚'
                    },
                    {
                        'role': 'user', 
                        'content': prompt
                    }
                ],
                'max_tokens': 2000,
                'temperature': 0.7
            }
            
            # å¤„ç†ä¸åŒAPIæ ¼å¼
            base_url = config.get('base_url', 'https://api.openai.com/v1')
            if not base_url.endswith('/chat/completions'):
                if base_url.endswith('/v1'):
                    url = base_url + '/chat/completions'
                else:
                    url = base_url + '/v1/chat/completions'
            else:
                url = base_url
            
            response = requests.post(url, headers=headers, json=data, timeout=60)
            
            if response.status_code == 200:
                result = response.json()
                content = result.get('choices', [{}])[0].get('message', {}).get('content', '')
                return content.strip()
            else:
                print(f"âš ï¸ APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text[:200]}")
                return None
                
        except Exception as e:
            print(f"âš ï¸ AIè°ƒç”¨å‡ºé”™: {e}")
            return None

    def _process_ai_analysis(self, analysis: Dict, subtitles: List[Dict], episode_num: str) -> Dict:
        """å¤„ç†AIåˆ†æç»“æœ"""
        
        # æå–æ¨èçš„æ—¶é—´æ®µ
        best_segment = analysis.get('best_segment', {})
        start_time = best_segment.get('start_time', '')
        end_time = best_segment.get('end_time', '')
        
        # å¦‚æœAIæ²¡æœ‰æä¾›æ—¶é—´ï¼Œä½¿ç”¨æ™ºèƒ½é€‰æ‹©
        if not start_time or not end_time:
            segment = self._smart_segment_selection(subtitles, analysis)
            start_time = segment['start_time']
            end_time = segment['end_time']
        
        # éªŒè¯å’Œä¼˜åŒ–æ—¶é—´æ®µ
        start_time, end_time = self._optimize_time_range(subtitles, start_time, end_time)
        
        # è®¡ç®—æ—¶é•¿
        duration = self.time_to_seconds(end_time) - self.time_to_seconds(start_time)
        
        # ç”Ÿæˆä¸»é¢˜æ ‡é¢˜
        theme = self._generate_theme_title(analysis, episode_num)
        
        # æ›´æ–°è¿è´¯æ€§ä¿¡æ¯
        self.previous_episode_ending = analysis.get('next_episode_connection', '')
        
        return {
            'episode_number': episode_num,
            'theme': theme,
            'start_time': start_time,
            'end_time': end_time,
            'duration': duration,
            'genre': analysis.get('genre', 'å‰§æƒ…ç‰‡'),
            'plot_significance': analysis.get('plot_significance', 'é‡è¦å‰§æƒ…æ¨è¿›'),
            'emotional_peak': analysis.get('emotional_peak', 'æƒ…æ„Ÿé«˜æ½®'),
            'key_dialogues': analysis.get('key_dialogues', []),
            'next_episode_connection': analysis.get('next_episode_connection', ''),
            'content_highlights': analysis.get('content_highlights', []),
            'content_summary': best_segment.get('content_summary', 'ç²¾å½©ç‰‡æ®µ'),
            'ai_analysis': True
        }

    def _smart_segment_selection(self, subtitles: List[Dict], analysis: Dict) -> Dict:
        """æ™ºèƒ½é€‰æ‹©ç‰‡æ®µï¼ˆå½“AIæœªæä¾›å…·ä½“æ—¶é—´æ—¶ï¼‰"""
        
        # åŸºäºå…³é”®è¯å¯†åº¦é€‰æ‹©
        key_dialogues = analysis.get('key_dialogues', [])
        
        best_start_idx = 0
        best_score = 0
        
        for i in range(len(subtitles)):
            # è®¡ç®—ä»¥å½“å‰ä½ç½®ä¸ºä¸­å¿ƒçš„ç‰‡æ®µå¾—åˆ†
            window_start = max(0, i - 30)
            window_end = min(len(subtitles), i + 30)
            
            window_text = ' '.join([subtitles[j]['text'] for j in range(window_start, window_end)])
            
            score = 0
            for key_dialogue in key_dialogues:
                if key_dialogue.lower() in window_text.lower():
                    score += 3
            
            # å¯¹è¯å¯†åº¦è¯„åˆ†
            score += window_text.count('ï¼') + window_text.count('ï¼Ÿ') * 0.5
            
            if score > best_score:
                best_score = score
                best_start_idx = window_start
        
        # ç¡®ä¿2-3åˆ†é’Ÿæ—¶é•¿
        target_duration = 150  # 2.5åˆ†é’Ÿ
        end_idx = best_start_idx
        
        for i in range(best_start_idx, len(subtitles)):
            current_duration = self.time_to_seconds(subtitles[i]['end']) - self.time_to_seconds(subtitles[best_start_idx]['start'])
            if current_duration >= target_duration:
                end_idx = i
                break
        
        return {
            'start_time': subtitles[best_start_idx]['start'],
            'end_time': subtitles[min(end_idx, len(subtitles)-1)]['end']
        }

    def _optimize_time_range(self, subtitles: List[Dict], start_time: str, end_time: str) -> Tuple[str, str]:
        """ä¼˜åŒ–æ—¶é—´èŒƒå›´ï¼Œç¡®ä¿å®Œæ•´å¯¹è¯å’Œåˆé€‚æ—¶é•¿"""
        
        # æ‰¾åˆ°æœ€æ¥è¿‘çš„å­—å¹•æ¡ç›®
        start_idx = self._find_closest_subtitle_index(subtitles, start_time)
        end_idx = self._find_closest_subtitle_index(subtitles, end_time)
        
        # å¯»æ‰¾è‡ªç„¶çš„å¼€å§‹ç‚¹
        for i in range(max(0, start_idx - 5), start_idx + 5):
            if i < len(subtitles):
                text = subtitles[i]['text']
                if any(marker in text for marker in ['é‚£ä¹ˆ', 'ç°åœ¨', 'è¿™æ—¶', 'çªç„¶', 'æ¥ä¸‹æ¥']):
                    start_idx = i
                    break
        
        # å¯»æ‰¾è‡ªç„¶çš„ç»“æŸç‚¹
        for i in range(end_idx, min(len(subtitles), end_idx + 5)):
            text = subtitles[i]['text']
            if any(marker in text for marker in ['å¥½çš„', 'ç»“æŸ', 'æ˜ç™½', 'çŸ¥é“äº†', 'ç®—äº†']):
                end_idx = i
                break
        
        # ç¡®ä¿æ—¶é•¿åœ¨åˆç†èŒƒå›´å†…ï¼ˆ90-200ç§’ï¼‰
        duration = self.time_to_seconds(subtitles[end_idx]['end']) - self.time_to_seconds(subtitles[start_idx]['start'])
        
        if duration < 90:
            # æ‰©å±•ç‰‡æ®µ
            while end_idx < len(subtitles) - 1 and duration < 120:
                end_idx += 1
                duration = self.time_to_seconds(subtitles[end_idx]['end']) - self.time_to_seconds(subtitles[start_idx]['start'])
        
        elif duration > 200:
            # ç¼©å‡ç‰‡æ®µ
            while start_idx < end_idx and duration > 180:
                start_idx += 1
                duration = self.time_to_seconds(subtitles[end_idx]['end']) - self.time_to_seconds(subtitles[start_idx]['start'])
        
        return subtitles[start_idx]['start'], subtitles[end_idx]['end']

    def _find_closest_subtitle_index(self, subtitles: List[Dict], target_time: str) -> int:
        """æ‰¾åˆ°æœ€æ¥è¿‘ç›®æ ‡æ—¶é—´çš„å­—å¹•ç´¢å¼•"""
        target_seconds = self.time_to_seconds(target_time)
        
        closest_idx = 0
        min_diff = float('inf')
        
        for i, sub in enumerate(subtitles):
            sub_seconds = self.time_to_seconds(sub['start'])
            diff = abs(sub_seconds - target_seconds)
            
            if diff < min_diff:
                min_diff = diff
                closest_idx = i
        
        return closest_idx

    def _generate_theme_title(self, analysis: Dict, episode_num: str) -> str:
        """ç”Ÿæˆä¸»é¢˜æ ‡é¢˜"""
        theme_base = analysis.get('theme', 'ç²¾å½©ç‰‡æ®µ')
        significance = analysis.get('plot_significance', '')
        
        # æ™ºèƒ½ç”Ÿæˆæ ‡é¢˜
        if 'æ¡ˆä»¶' in significance or 'æ³•å¾‹' in significance:
            title = f"E{episode_num}ï¼š{theme_base} - æ³•å¾‹è¾ƒé‡å…³é”®æ—¶åˆ»"
        elif 'æƒ…æ„Ÿ' in significance or 'çˆ±æƒ…' in significance:
            title = f"E{episode_num}ï¼š{theme_base} - æƒ…æ„Ÿé«˜æ½®éœ‡æ’¼äººå¿ƒ"
        elif 'çœŸç›¸' in significance or 'æ­éœ²' in significance:
            title = f"E{episode_num}ï¼š{theme_base} - çœŸç›¸å¤§ç™½æƒŠå¿ƒåŠ¨é­„"
        elif 'å†²çª' in significance or 'å¯¹æŠ—' in significance:
            title = f"E{episode_num}ï¼š{theme_base} - æ¿€çƒˆå†²çªç²¾å½©å¯¹å†³"
        else:
            title = f"E{episode_num}ï¼š{theme_base} - æ ¸å¿ƒå‰§æƒ…ç²¾å½©å‘ˆç°"
        
        return title

    def _fallback_analysis(self, subtitles: List[Dict], episode_num: str) -> Dict:
        """å¤‡ç”¨åˆ†ææ–¹æ³•ï¼ˆå½“AIä¸å¯ç”¨æ—¶ï¼‰"""
        
        # ç®€å•çš„å…³é”®è¯è¯„åˆ†
        high_score_indices = []
        
        for i, sub in enumerate(subtitles):
            score = 0
            text = sub['text']
            
            # æƒ…æ„Ÿè¯æ±‡
            emotional_words = ['æ„¤æ€’', 'æ¿€åŠ¨', 'éœ‡æƒŠ', 'æ„ŸåŠ¨', 'ç—›è‹¦', 'å¼€å¿ƒ', 'å®³æ€•', 'ç´§å¼ ']
            for word in emotional_words:
                if word in text:
                    score += 2
            
            # å‰§æƒ…å…³é”®è¯
            plot_words = ['çœŸç›¸', 'ç§˜å¯†', 'å‘ç°', 'è¯æ®', 'å†³å®š', 'é€‰æ‹©', 'é‡è¦', 'å…³é”®']
            for word in plot_words:
                if word in text:
                    score += 3
            
            # å¯¹è¯å¼ºåº¦
            score += text.count('ï¼') + text.count('ï¼Ÿ') * 0.5
            
            if score >= 3:
                high_score_indices.append((i, score))
        
        if high_score_indices:
            # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„ç‰‡æ®µ
            high_score_indices.sort(key=lambda x: x[1], reverse=True)
            center_idx = high_score_indices[0][0]
            
            start_idx = max(0, center_idx - 25)
            end_idx = min(len(subtitles) - 1, center_idx + 25)
        else:
            # é€‰æ‹©ä¸­é—´éƒ¨åˆ†
            mid = len(subtitles) // 2
            start_idx = max(0, mid - 25)
            end_idx = min(len(subtitles) - 1, mid + 25)
        
        return {
            'episode_number': episode_num,
            'theme': f"E{episode_num}ï¼šç²¾å½©å‰§æƒ…ç‰‡æ®µ",
            'start_time': subtitles[start_idx]['start'],
            'end_time': subtitles[end_idx]['end'],
            'duration': self.time_to_seconds(subtitles[end_idx]['end']) - self.time_to_seconds(subtitles[start_idx]['start']),
            'genre': 'å‰§æƒ…ç‰‡',
            'plot_significance': 'é‡è¦å‰§æƒ…å‘å±•',
            'emotional_peak': 'ç²¾å½©å¯¹è¯',
            'key_dialogues': [subtitles[start_idx]['text']],
            'next_episode_connection': 'å‰§æƒ…æŒç»­å‘å±•',
            'content_highlights': ['ç²¾å½©å¯¹è¯', 'é‡è¦æƒ…èŠ‚'],
            'content_summary': 'æ ¸å¿ƒå‰§æƒ…ç‰‡æ®µ',
            'ai_analysis': False
        }

    def time_to_seconds(self, time_str: str) -> float:
        """æ—¶é—´è½¬æ¢ä¸ºç§’"""
        try:
            time_str = time_str.replace('.', ',')
            h, m, s_ms = time_str.split(':')
            s, ms = s_ms.split(',')
            return int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000
        except:
            return 0

    def find_video_file(self, subtitle_filename: str) -> Optional[str]:
        """æ™ºèƒ½åŒ¹é…è§†é¢‘æ–‡ä»¶"""
        if not os.path.exists(self.video_folder):
            return None
        
        base_name = os.path.splitext(subtitle_filename)[0]
        video_extensions = ['.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv', '.ts']
        
        # ç²¾ç¡®åŒ¹é…
        for ext in video_extensions:
            video_path = os.path.join(self.video_folder, base_name + ext)
            if os.path.exists(video_path):
                return video_path
        
        # æå–é›†æ•°è¿›è¡Œæ¨¡ç³ŠåŒ¹é…
        episode_patterns = [r'[Ee](\d+)', r'EP(\d+)', r'ç¬¬(\d+)é›†', r'S\d+E(\d+)']
        subtitle_episode = None
        
        for pattern in episode_patterns:
            match = re.search(pattern, base_name, re.I)
            if match:
                subtitle_episode = match.group(1)
                break
        
        if subtitle_episode:
            for filename in os.listdir(self.video_folder):
                if any(filename.lower().endswith(ext) for ext in video_extensions):
                    for pattern in episode_patterns:
                        match = re.search(pattern, filename, re.I)
                        if match and match.group(1) == subtitle_episode:
                            return os.path.join(self.video_folder, filename)
        
        return None

    def create_clip(self, analysis_result: Dict, video_file: str) -> bool:
        """åˆ›å»ºè§†é¢‘ç‰‡æ®µ"""
        try:
            theme = analysis_result['theme']
            start_time = analysis_result['start_time']
            end_time = analysis_result['end_time']
            
            # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
            safe_theme = re.sub(r'[^\w\u4e00-\u9fff\-_]', '_', theme)
            output_name = f"{safe_theme}.mp4"
            output_path = os.path.join(self.output_folder, output_name)
            
            print(f"\nğŸ¬ åˆ›å»ºAIæ™ºèƒ½ç‰‡æ®µ: {theme}")
            print(f"ğŸ“ æºè§†é¢‘: {os.path.basename(video_file)}")
            print(f"â±ï¸ æ—¶é—´æ®µ: {start_time} --> {end_time}")
            print(f"ğŸ“ æ—¶é•¿: {analysis_result['duration']:.1f}ç§’")
            print(f"ğŸ­ å‰§æƒ…ç±»å‹: {analysis_result['genre']}")
            print(f"ğŸ¤– AIåˆ†æ: {'æ˜¯' if analysis_result.get('ai_analysis') else 'å¦'}")
            
            # è®¡ç®—æ—¶é—´
            start_seconds = self.time_to_seconds(start_time)
            end_seconds = self.time_to_seconds(end_time)
            duration = end_seconds - start_seconds
            
            # æ·»åŠ ç¼“å†²æ—¶é—´
            buffer_start = max(0, start_seconds - 1)
            buffer_duration = duration + 2
            
            # FFmpegå‘½ä»¤
            cmd = [
                'ffmpeg',
                '-i', video_file,
                '-ss', str(buffer_start),
                '-t', str(buffer_duration),
                '-c:v', 'libx264',
                '-c:a', 'aac',
                '-preset', 'medium',
                '-crf', '23',
                '-movflags', '+faststart',
                '-avoid_negative_ts', 'make_zero',
                output_path,
                '-y'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0 and os.path.exists(output_path):
                file_size = os.path.getsize(output_path) / (1024*1024)
                print(f"  âœ… æˆåŠŸåˆ›å»º: {output_name} ({file_size:.1f}MB)")
                
                # åˆ›å»ºè¯¦ç»†è¯´æ˜æ–‡ä»¶
                self.create_description_file(output_path, analysis_result)
                
                return True
            else:
                error_msg = result.stderr[:200] if result.stderr else "æœªçŸ¥é”™è¯¯"
                print(f"  âŒ å‰ªè¾‘å¤±è´¥: {error_msg}")
                return False
                
        except Exception as e:
            print(f"  âŒ åˆ›å»ºç‰‡æ®µæ—¶å‡ºé”™: {e}")
            return False

    def create_description_file(self, video_path: str, analysis_result: Dict):
        """åˆ›å»ºè¯¦ç»†è¯´æ˜æ–‡ä»¶"""
        try:
            desc_path = video_path.replace('.mp4', '_æ™ºèƒ½åˆ†æè¯´æ˜.txt')
            
            content = f"""ğŸ“º {analysis_result['theme']}
{"=" * 60}

ğŸ¤– AIæ™ºèƒ½åˆ†æ: {'æ˜¯' if analysis_result.get('ai_analysis') else 'å¦'}
ğŸ­ å‰§æƒ…ç±»å‹: {analysis_result['genre']}
â±ï¸ æ—¶é—´ç‰‡æ®µ: {analysis_result['start_time']} --> {analysis_result['end_time']}
ğŸ“ ç‰‡æ®µæ—¶é•¿: {analysis_result['duration']:.1f} ç§’ ({analysis_result['duration']/60:.1f} åˆ†é’Ÿ)

ğŸ’¡ å‰§æƒ…é‡è¦æ€§: 
{analysis_result['plot_significance']}

ğŸ˜Š æƒ…æ„Ÿé«˜æ½®:
{analysis_result['emotional_peak']}

ğŸ“ å…³é”®å°è¯:
"""
            for dialogue in analysis_result['key_dialogues']:
                content += f"â€¢ {dialogue}\n"
            
            content += f"""
âœ¨ å†…å®¹äº®ç‚¹:
"""
            for highlight in analysis_result['content_highlights']:
                content += f"â€¢ {highlight}\n"
            
            content += f"""
ğŸ¯ å†…å®¹æ¦‚è¦:
{analysis_result['content_summary']}

ğŸ”— ä¸‹é›†è¡”æ¥:
{analysis_result['next_episode_connection']}

ğŸ“„ AIåˆ†æè¯´æ˜:
â€¢ æœ¬ç‰‡æ®µç»è¿‡{'AIæ™ºèƒ½' if analysis_result.get('ai_analysis') else 'è§„åˆ™'}åˆ†æé€‰å‡º
â€¢ å‰§æƒ…ç±»å‹è‡ªåŠ¨è¯†åˆ«: {analysis_result['genre']}
â€¢ æ—¶é•¿ä¼˜åŒ–åœ¨2-3åˆ†é’Ÿï¼Œçªå‡ºæ ¸å¿ƒå‰§æƒ…
â€¢ ä¿è¯å®Œæ•´å¯¹è¯åœºæ™¯ï¼Œä¸æˆªæ–­é‡è¦å†…å®¹
â€¢ ä¸å‰åé›†ä¿æŒå‰§æƒ…è¿è´¯æ€§
â€¢ é€‚åˆçŸ­è§†é¢‘å¹³å°ä¼ æ’­å’Œå‰§æƒ…ä»‹ç»
"""
            
            with open(desc_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            print(f"    ğŸ“„ ç”Ÿæˆæ™ºèƒ½åˆ†æè¯´æ˜: {os.path.basename(desc_path)}")
            
        except Exception as e:
            print(f"    âš  ç”Ÿæˆè¯´æ˜æ–‡ä»¶å¤±è´¥: {e}")

def main():
    """ä¸»ç¨‹åº"""
    print("ğŸš€ æ™ºèƒ½AIç”µè§†å‰§å‰ªè¾‘ç³»ç»Ÿå¯åŠ¨")
    print("=" * 60)
    print("ğŸ¤– ç³»ç»Ÿç‰¹æ€§:")
    print("â€¢ AIæ™ºèƒ½åˆ†æï¼Œè‡ªé€‚åº”å„ç§å‰§æƒ…ç±»å‹")
    print("â€¢ æ¯é›†é€‰æ‹©æœ€ç²¾å½©çš„2-3åˆ†é’Ÿç‰‡æ®µ")
    print("â€¢ è‡ªåŠ¨é”™åˆ«å­—ä¿®æ­£å’Œæ ¼å¼å…¼å®¹")
    print("â€¢ è·¨é›†å‰§æƒ…è¿è´¯æ€§ä¿è¯")
    print("â€¢ æ”¯æŒå¤šç§AIæ¨¡å‹æ¥å£")
    print("â€¢ æ™ºèƒ½è§†é¢‘æ–‡ä»¶åŒ¹é…")
    print("=" * 60)
    
    clipper = IntelligentAIClipper()
    
    # è·å–æ‰€æœ‰å­—å¹•æ–‡ä»¶
    subtitle_files = []
    for file in os.listdir('.'):
        if file.endswith(('.txt', '.srt')) and not file.startswith('.') and not file.endswith('è¯´æ˜.txt'):
            subtitle_files.append(file)
    
    subtitle_files.sort()
    
    if not subtitle_files:
        print("âŒ æœªæ‰¾åˆ°å­—å¹•æ–‡ä»¶")
        print("è¯·å°†å­—å¹•æ–‡ä»¶æ”¾åœ¨é¡¹ç›®æ ¹ç›®å½•")
        print("æ”¯æŒæ ¼å¼: .txt, .srt")
        return
    
    print(f"ğŸ“„ æ‰¾åˆ° {len(subtitle_files)} ä¸ªå­—å¹•æ–‡ä»¶: {', '.join(subtitle_files[:5])}")
    if len(subtitle_files) > 5:
        print(f"   ... ç­‰ {len(subtitle_files)} ä¸ªæ–‡ä»¶")
    
    # æ£€æŸ¥è§†é¢‘ç›®å½•
    if not os.path.exists(clipper.video_folder):
        print(f"âŒ è§†é¢‘ç›®å½•ä¸å­˜åœ¨: {clipper.video_folder}")
        print("è¯·åˆ›å»ºvideosç›®å½•å¹¶æ”¾å…¥å¯¹åº”çš„è§†é¢‘æ–‡ä»¶")
        return
    
    video_files = [f for f in os.listdir(clipper.video_folder) 
                   if f.lower().endswith(('.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv', '.ts'))]
    
    if not video_files:
        print(f"âŒ è§†é¢‘ç›®å½•ä¸­æ²¡æœ‰è§†é¢‘æ–‡ä»¶")
        return
    
    print(f"ğŸ¬ æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
    
    created_clips = []
    all_analysis = []
    
    for i, subtitle_file in enumerate(subtitle_files, 1):
        print(f"\nğŸ“º AIæ™ºèƒ½åˆ†æç¬¬ {i} é›†: {subtitle_file}")
        
        # è§£æå­—å¹•
        subtitles = clipper.parse_subtitle_file(subtitle_file)
        if not subtitles:
            print(f"  âŒ å­—å¹•è§£æå¤±è´¥")
            continue
        
        # æå–é›†æ•°
        episode_patterns = [r'[Ee](\d+)', r'EP(\d+)', r'ç¬¬(\d+)é›†', r'S\d+E(\d+)']
        episode_num = None
        
        for pattern in episode_patterns:
            match = re.search(pattern, subtitle_file, re.I)
            if match:
                episode_num = match.group(1).zfill(2)
                break
        
        if not episode_num:
            episode_num = str(i).zfill(2)
        
        # AIæ™ºèƒ½åˆ†æ
        analysis_result = clipper.ai_analyze_episode(subtitles, episode_num)
        all_analysis.append(analysis_result)
        
        print(f"  ğŸ¯ ä¸»é¢˜: {analysis_result['theme']}")
        print(f"  ğŸ­ ç±»å‹: {analysis_result['genre']}")
        print(f"  â±ï¸ ç‰‡æ®µ: {analysis_result['start_time']} --> {analysis_result['end_time']} ({analysis_result['duration']:.1f}ç§’)")
        print(f"  ğŸ’¡ æ„ä¹‰: {analysis_result['plot_significance']}")
        print(f"  ğŸ¤– AIåˆ†æ: {'æ˜¯' if analysis_result.get('ai_analysis') else 'å¦'}")
        
        # æ‰¾åˆ°å¯¹åº”è§†é¢‘æ–‡ä»¶
        video_file = clipper.find_video_file(subtitle_file)
        if not video_file:
            print(f"  âš  æœªæ‰¾åˆ°å¯¹åº”è§†é¢‘æ–‡ä»¶")
            continue
        
        # åˆ›å»ºçŸ­è§†é¢‘
        if clipper.create_clip(analysis_result, video_file):
            safe_theme = re.sub(r'[^\w\u4e00-\u9fff\-_]', '_', analysis_result['theme'])
            output_name = f"{safe_theme}.mp4"
            created_clips.append(os.path.join(clipper.output_folder, output_name))
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    generate_ai_analysis_report(all_analysis, clipper, created_clips)
    
    print(f"\nğŸ“Š AIæ™ºèƒ½å‰ªè¾‘å®Œæˆç»Ÿè®¡:")
    print(f"âœ… åˆ†æé›†æ•°: {len(all_analysis)} é›†")
    print(f"âœ… æˆåŠŸåˆ¶ä½œ: {len(created_clips)} ä¸ªçŸ­è§†é¢‘")
    print(f"ğŸ¤– AIåˆ†æç‡: {sum(1 for a in all_analysis if a.get('ai_analysis', False))}/{len(all_analysis)}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {clipper.output_folder}/")
    print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: ai_intelligent_analysis_report.txt")

def generate_ai_analysis_report(analyses: List[Dict], clipper, created_clips: List[str]):
    """ç”ŸæˆAIåˆ†ææŠ¥å‘Š"""
    if not analyses:
        return
    
    content = "ğŸ“º AIæ™ºèƒ½ç”µè§†å‰§å‰ªè¾‘åˆ†ææŠ¥å‘Š\n"
    content += "=" * 80 + "\n\n"
    
    content += "ğŸ¤– AIæ™ºèƒ½ç³»ç»Ÿä¿¡æ¯ï¼š\n"
    content += f"â€¢ AIåˆ†æçŠ¶æ€: {'å¯ç”¨' if clipper.ai_config.get('enabled') else 'æœªå¯ç”¨'}\n"
    if clipper.ai_config.get('enabled'):
        content += f"â€¢ AIæ¨¡å‹: {clipper.ai_config.get('model', 'unknown')}\n"
        content += f"â€¢ APIæä¾›å•†: {clipper.ai_config.get('provider', 'unknown')}\n"
    content += f"â€¢ åˆ†æé›†æ•°: {len(analyses)} é›†\n"
    content += f"â€¢ æˆåŠŸåˆ¶ä½œ: {len(created_clips)} ä¸ªçŸ­è§†é¢‘\n"
    content += f"â€¢ AIåˆ†ææˆåŠŸç‡: {sum(1 for a in analyses if a.get('ai_analysis', False))}/{len(analyses)}\n\n"
    
    # å‰§æƒ…ç±»å‹ç»Ÿè®¡
    genre_stats = {}
    for analysis in analyses:
        genre = analysis.get('genre', 'unknown')
        genre_stats[genre] = genre_stats.get(genre, 0) + 1
    
    content += "ğŸ“Š å‰§æƒ…ç±»å‹åˆ†å¸ƒï¼š\n"
    for genre, count in genre_stats.items():
        content += f"â€¢ {genre}: {count} é›†\n"
    content += "\n"
    
    total_duration = 0
    ai_count = 0
    
    for i, analysis in enumerate(analyses, 1):
        content += f"ğŸ“º {analysis['theme']}\n"
        content += "-" * 60 + "\n"
        content += f"AIåˆ†æ: {'æ˜¯' if analysis.get('ai_analysis') else 'å¦'}\n"
        content += f"å‰§æƒ…ç±»å‹: {analysis['genre']}\n"
        content += f"æ—¶é—´ç‰‡æ®µ: {analysis['start_time']} --> {analysis['end_time']}\n"
        content += f"ç‰‡æ®µæ—¶é•¿: {analysis['duration']:.1f} ç§’ ({analysis['duration']/60:.1f} åˆ†é’Ÿ)\n"
        content += f"å‰§æƒ…é‡è¦æ€§: {analysis['plot_significance']}\n"
        content += f"æƒ…æ„Ÿé«˜æ½®: {analysis['emotional_peak']}\n\n"
        
        content += "å…³é”®å°è¯:\n"
        for dialogue in analysis['key_dialogues']:
            content += f"  â€¢ {dialogue}\n"
        content += "\n"
        
        content += "å†…å®¹äº®ç‚¹:\n"
        for highlight in analysis['content_highlights']:
            content += f"  â€¢ {highlight}\n"
        content += "\n"
        
        content += f"å†…å®¹æ¦‚è¦: {analysis['content_summary']}\n"
        content += f"ä¸‹é›†è¡”æ¥: {analysis['next_episode_connection']}\n"
        content += "=" * 80 + "\n\n"
        
        total_duration += analysis['duration']
        if analysis.get('ai_analysis'):
            ai_count += 1
    
    # æ€»ç»“ç»Ÿè®¡
    avg_duration = total_duration / len(analyses) if analyses else 0
    ai_success_rate = ai_count / len(analyses) * 100 if analyses else 0
    
    content += f"ğŸ“Š AIæ™ºèƒ½åˆ†ææ€»ç»“ï¼š\n"
    content += f"â€¢ AIåˆ†ææˆåŠŸç‡: {ai_success_rate:.1f}% ({ai_count}/{len(analyses)})\n"
    content += f"â€¢ æ€»åˆ¶ä½œæ—¶é•¿: {total_duration:.1f} ç§’ ({total_duration/60:.1f} åˆ†é’Ÿ)\n"
    content += f"â€¢ å¹³å‡æ¯é›†æ—¶é•¿: {avg_duration:.1f} ç§’\n"
    content += f"â€¢ å‰§æƒ…ç±»å‹è¦†ç›–: {len(genre_stats)} ç§ç±»å‹\n"
    content += f"â€¢ åˆ¶ä½œæˆåŠŸç‡: {len(created_clips)/len(analyses)*100:.1f}%\n"
    content += f"â€¢ æŠ€æœ¯ç‰¹ç‚¹: è‡ªé€‚åº”å‰§æƒ…åˆ†æã€æ™ºèƒ½é”™è¯¯ä¿®æ­£ã€è·¨é›†è¿è´¯æ€§ä¿è¯\n"
    content += f"â€¢ é€‚ç”¨åœºæ™¯: å…¨è‡ªåŠ¨çŸ­è§†é¢‘åˆ¶ä½œã€æ™ºèƒ½å‰§æƒ…æå–ã€å¤šç±»å‹ç”µè§†å‰§åˆ†æ\n"
    
    try:
        with open('ai_intelligent_analysis_report.txt', 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"ğŸ“„ AIæ™ºèƒ½åˆ†ææŠ¥å‘Šå·²ä¿å­˜")
    except Exception as e:
        print(f"âš  ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")

if __name__ == "__main__":
    main()
