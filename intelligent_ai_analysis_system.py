
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ™ºèƒ½AIç”µè§†å‰§åˆ†æç³»ç»Ÿ
å®Œå…¨åŸºäºAIçš„è‡ªé€‚åº”å‰§æƒ…åˆ†æï¼Œä¸ä¾èµ–å›ºå®šå…³é”®è¯
æ”¯æŒä»»ä½•ç±»å‹çš„ç”µè§†å‰§è‡ªåŠ¨åˆ†æå’Œå‰ªè¾‘
"""

import os
import re
import json
import hashlib
import subprocess
from typing import List, Dict, Optional
from datetime import datetime
import requests

class IntelligentAIAnalysisSystem:
    def __init__(self, srt_folder: str = "srt", video_folder: str = "videos", output_folder: str = "clips"):
        self.srt_folder = srt_folder
        self.video_folder = video_folder
        self.output_folder = output_folder
        self.cache_folder = "analysis_cache"
        
        # åˆ›å»ºç›®å½•
        for folder in [self.srt_folder, self.video_folder, self.output_folder, self.cache_folder]:
            os.makedirs(folder, exist_ok=True)
        
        # åŠ è½½AIé…ç½®
        self.ai_config = self.load_ai_config()
        
        # å‰§é›†ä¸Šä¸‹æ–‡ç¼“å­˜
        self.series_context = {
            'previous_episodes': [],
            'main_characters': set(),
            'story_threads': [],
            'ongoing_conflicts': []
        }
        
        print("ğŸ¤– æ™ºèƒ½AIç”µè§†å‰§åˆ†æç³»ç»Ÿå¯åŠ¨")
        print("=" * 60)
        print("âœ¨ ç‰¹æ€§ï¼š")
        print("â€¢ å®Œå…¨AIé©±åŠ¨ï¼Œè‡ªé€‚åº”ä»»ä½•å‰§æƒ…ç±»å‹")
        print("â€¢ æ™ºèƒ½è¯†åˆ«ç²¾å½©ç‰‡æ®µå’Œå‰§æƒ…è½¬æŠ˜")
        print("â€¢ ä¿è¯è·¨é›†è¿è´¯æ€§å’Œæ•…äº‹å®Œæ•´æ€§")
        print("â€¢ è‡ªåŠ¨é”™åˆ«å­—ä¿®æ­£")
        print("â€¢ æ¯é›†2-3åˆ†é’Ÿæ ¸å¿ƒå‰§æƒ…çŸ­è§†é¢‘")
        print("=" * 60)

    def load_ai_config(self) -> Dict:
        """åŠ è½½AIé…ç½®"""
        try:
            with open('.ai_config.json', 'r', encoding='utf-8') as f:
                config = json.load(f)
                if config.get('enabled', False) and config.get('api_key'):
                    print(f"âœ… AIé…ç½®å·²åŠ è½½: {config.get('model', 'æœªçŸ¥æ¨¡å‹')}")
                    return config
        except:
            pass
        
        print("âš ï¸ AIæœªé…ç½®ï¼Œå°†ä½¿ç”¨åŸºç¡€è§„åˆ™åˆ†æ")
        return {'enabled': False}

    def parse_subtitle_file(self, filepath: str) -> List[Dict]:
        """æ™ºèƒ½è§£æå­—å¹•æ–‡ä»¶ï¼Œæ”¯æŒå¤šç§æ ¼å¼å’Œç¼–ç """
        print(f"ğŸ“– è§£æå­—å¹•æ–‡ä»¶: {os.path.basename(filepath)}")
        
        # å°è¯•å¤šç§ç¼–ç 
        content = None
        for encoding in ['utf-8', 'gbk', 'utf-16', 'gb2312', 'big5']:
            try:
                with open(filepath, 'r', encoding=encoding, errors='ignore') as f:
                    content = f.read()
                    break
            except:
                continue
        
        if not content:
            print("âŒ å­—å¹•æ–‡ä»¶è¯»å–å¤±è´¥")
            return []
        
        # æ™ºèƒ½é”™åˆ«å­—ä¿®æ­£ - æ‰©å±•ç‰ˆ
        corrections = {
            # ç¹ä½“è½¬ç®€ä½“
            'é˜²è¡›': 'é˜²å«', 'æ­£ç•¶': 'æ­£å½“', 'è¨¼æ“š': 'è¯æ®', 'æª¢å¯Ÿå®˜': 'æ£€å¯Ÿå®˜',
            'å¯©åˆ¤': 'å®¡åˆ¤', 'è¾¯è­·': 'è¾©æŠ¤', 'èµ·è¨´': 'èµ·è¯‰', 'èª¿æŸ¥': 'è°ƒæŸ¥',
            'ç™¼ç¾': 'å‘ç°', 'æ±ºå®š': 'å†³å®š', 'é¸æ“‡': 'é€‰æ‹©', 'é–‹å§‹': 'å¼€å§‹',
            'çµæŸ': 'ç»“æŸ', 'å•é¡Œ': 'é—®é¢˜', 'æ©Ÿæœƒ': 'æœºä¼š', 'è½è­‰æœƒ': 'å¬è¯ä¼š',
            'ç„¡ç½ª': 'æ— ç½ª', 'å®Ÿç¾': 'å®ç°', 'å¯¾è©±': 'å¯¹è¯', 'é–¢ä¿‚': 'å…³ç³»',
            
            # å¸¸è§é”™åˆ«å­—
            'è¨¼æ®': 'è¯æ®', 'è¾©æˆ·': 'è¾©æŠ¤', 'æ£€æŸ¥å®˜': 'æ£€å¯Ÿå®˜', 'æ³•å®˜': 'æ³•å®˜',
            'ç”³è¿°': 'ç”³è¯‰', 'å¬æ”¿ä¼š': 'å¬è¯ä¼š', 'è¨¼äºº': 'è¯äºº', 'è¨¼è¨€': 'è¯è¨€'
        }
        
        for old, new in corrections.items():
            content = content.replace(old, new)
        
        # è§£æå­—å¹•æ¡ç›®
        subtitles = []
        
        # æ”¯æŒSRTå’ŒTXTæ ¼å¼
        if filepath.lower().endswith('.srt') or '-->' in content:
            # SRTæ ¼å¼
            blocks = re.split(r'\n\s*\n', content.strip())
            for block in blocks:
                lines = block.strip().split('\n')
                if len(lines) >= 3:
                    try:
                        index = int(lines[0]) if lines[0].isdigit() else len(subtitles) + 1
                        time_match = re.search(r'(\d{2}:\d{2}:\d{2}[,\.]\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2}[,\.]\d{3})', lines[1])
                        if time_match:
                            start_time = time_match.group(1).replace('.', ',')
                            end_time = time_match.group(2).replace('.', ',')
                            text = '\n'.join(lines[2:]).strip()
                            
                            if text:
                                subtitles.append({
                                    'index': index,
                                    'start': start_time,
                                    'end': end_time,
                                    'text': text,
                                    'start_seconds': self._time_to_seconds(start_time),
                                    'end_seconds': self._time_to_seconds(end_time)
                                })
                    except:
                        continue
        else:
            # TXTæ ¼å¼æˆ–å…¶ä»–æ ¼å¼ - æ™ºèƒ½è§£æ
            lines = content.split('\n')
            current_text = []
            current_time = None
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                
                # æŸ¥æ‰¾æ—¶é—´æˆ³
                time_match = re.search(r'(\d{2}:\d{2}:\d{2}[,\.]\d{3})', line)
                if time_match and '-->' in line:
                    # ä¿å­˜ä¹‹å‰çš„å­—å¹•
                    if current_text and current_time:
                        subtitles.append({
                            'index': len(subtitles) + 1,
                            'start': current_time[0],
                            'end': current_time[1],
                            'text': ' '.join(current_text),
                            'start_seconds': self._time_to_seconds(current_time[0]),
                            'end_seconds': self._time_to_seconds(current_time[1])
                        })
                    
                    # è§£ææ–°çš„æ—¶é—´èŒƒå›´
                    time_parts = line.split('-->')
                    if len(time_parts) == 2:
                        start_time = re.search(r'(\d{2}:\d{2}:\d{2}[,\.]\d{3})', time_parts[0])
                        end_time = re.search(r'(\d{2}:\d{2}:\d{2}[,\.]\d{3})', time_parts[1])
                        if start_time and end_time:
                            current_time = (start_time.group(1).replace('.', ','), 
                                          end_time.group(1).replace('.', ','))
                            current_text = []
                else:
                    # æ·»åŠ åˆ°å½“å‰å­—å¹•æ–‡æœ¬
                    if line and not line.isdigit():
                        current_text.append(line)
            
            # ä¿å­˜æœ€åä¸€ä¸ªå­—å¹•
            if current_text and current_time:
                subtitles.append({
                    'index': len(subtitles) + 1,
                    'start': current_time[0],
                    'end': current_time[1],
                    'text': ' '.join(current_text),
                    'start_seconds': self._time_to_seconds(current_time[0]),
                    'end_seconds': self._time_to_seconds(current_time[1])
                })
        
        print(f"âœ… è§£æå®Œæˆ: {len(subtitles)} æ¡å­—å¹•")
        return subtitles

    def ai_analyze_episode(self, subtitles: List[Dict], episode_name: str) -> Optional[Dict]:
        """å®Œå…¨AIé©±åŠ¨çš„è‡ªé€‚åº”å‰§æƒ…åˆ†æ - è§£å†³å‰²è£‚å’Œé™åˆ¶é—®é¢˜"""
        if not self.ai_config.get('enabled', False):
            print("âš ï¸ AIæœªå¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ")
            return self.basic_analysis_fallback(subtitles, episode_name)
        
        # æ£€æŸ¥ç¼“å­˜
        cache_path = self._get_cache_path(episode_name, subtitles)
        cached_analysis = self._load_cache(cache_path)
        if cached_analysis:
            print(f"ğŸ“‚ ä½¿ç”¨ç¼“å­˜åˆ†æ: {episode_name}")
            return cached_analysis
        
        episode_num = self._extract_episode_number(episode_name)
        
        # æ„å»ºå®Œæ•´è¿è´¯çš„å‰§æƒ…æ–‡æœ¬ - è§£å†³å‰²è£‚é—®é¢˜
        complete_script = self._build_coherent_full_script(subtitles)
        
        # æ„å»ºä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ - è§£å†³ä¸Šä¸‹æ–‡è¡”æ¥é—®é¢˜
        context_info = self._build_rich_series_context(episode_num)
        
        # å®Œå…¨å¼€æ”¾çš„AIåˆ†ææç¤ºè¯ - ç§»é™¤æ‰€æœ‰å›ºå®šé™åˆ¶
        prompt = f"""ä½ æ˜¯ä¸–ç•Œé¡¶çº§çš„ç”µè§†å‰§å‰§æƒ…åˆ†æä¸“å®¶ã€‚è¯·å¯¹è¿™ä¸€é›†è¿›è¡Œå®Œå…¨è‡ªç”±çš„æ·±åº¦åˆ†æï¼Œä¸å—ä»»ä½•ç±»å‹æˆ–æ ¼å¼é™åˆ¶ã€‚

ã€å½“å‰é›†æ•°ã€‘ç¬¬{episode_num}é›†
ã€å…¨å‰§ä¸Šä¸‹æ–‡ã€‘{context_info}

ã€å®Œæ•´å‰§æƒ…å†…å®¹ã€‘
{complete_script}

è¯·ä»¥ä½ çš„ä¸“ä¸šåˆ¤æ–­ï¼Œå®Œå…¨è‡ªç”±åœ°åˆ†æè¿™ä¸€é›†ï¼š

{{
    "comprehensive_analysis": {{
        "episode_number": "{episode_num}",
        "auto_detected_genre": "æ ¹æ®å†…å®¹è‡ªåŠ¨è¯†åˆ«çš„å…·ä½“å‰§æƒ…ç±»å‹å’Œå­ç±»å‹",
        "narrative_style": "å™äº‹é£æ ¼ç‰¹ç‚¹ï¼ˆç°å®ä¸»ä¹‰/æˆå‰§åŒ–/æ‚¬ç–‘/å–œå‰§ç­‰ï¼‰",
        "emotional_core": "æœ¬é›†çš„æƒ…æ„Ÿæ ¸å¿ƒå’Œä¸»è°ƒ",
        "story_significance": "åœ¨æ•´ä¸ªå‰§é›†ä¸­çš„é‡è¦åœ°ä½",
        "character_dynamics": "ä¸»è¦è§’è‰²å…³ç³»å’Œäº’åŠ¨æ¨¡å¼",
        "thematic_elements": "æ ¸å¿ƒä¸»é¢˜å’Œæ·±å±‚å«ä¹‰",
        "dramatic_structure": "æˆå‰§ç»“æ„åˆ†æ",
        "pacing_rhythm": "èŠ‚å¥æ„Ÿå’Œå¼ åŠ›å˜åŒ–"
    }},
    "optimal_highlight_segment": {{
        "segment_title": "æœ€ä½³ç²¾å½©ç‰‡æ®µæ ‡é¢˜",
        "start_time": "å¼€å§‹æ—¶é—´ï¼ˆHH:MM:SS,mmmï¼‰",
        "end_time": "ç»“æŸæ—¶é—´ï¼ˆHH:MM:SS,mmmï¼‰",
        "duration_seconds": å®é™…ç§’æ•°,
        "selection_reasoning": "ä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªç‰‡æ®µçš„æ·±å±‚åŸå› ",
        "dramatic_arc": {{
            "opening": "ç‰‡æ®µå¼€åœºå¦‚ä½•å¸å¼•è§‚ä¼—",
            "development": "å‰§æƒ…å¦‚ä½•é€æ­¥æ¨è¿›",
            "climax": "é«˜æ½®ç‚¹åœ¨å“ªé‡Œï¼Œä¸ºä»€ä¹ˆé‡è¦",
            "resolution": "å¦‚ä½•æ”¶å°¾å¹¶è¡”æ¥åç»­"
        }},
        "emotional_journey": "è§‚ä¼—åœ¨è¿™ä¸ªç‰‡æ®µä¸­çš„æƒ…æ„Ÿä½“éªŒè·¯å¾„",
        "key_moments": [
            {{"time": "HH:MM:SS,mmm", "description": "å…³é”®æ—¶åˆ»1æè¿°", "impact": "æƒ…æ„Ÿ/å‰§æƒ…å†²å‡»åŠ›"}},
            {{"time": "HH:MM:SS,mmm", "description": "å…³é”®æ—¶åˆ»2æè¿°", "impact": "æƒ…æ„Ÿ/å‰§æƒ…å†²å‡»åŠ›"}}
        ],
        "dialogue_highlights": [
            {{"timestamp": "HH:MM:SS,mmm", "context": "åœºæ™¯èƒŒæ™¯", "line": "é‡è¦å°è¯", "significance": "å°è¯é‡è¦æ€§"}},
            {{"timestamp": "HH:MM:SS,mmm", "context": "åœºæ™¯èƒŒæ™¯", "line": "å…³é”®å¯¹è¯", "significance": "å¯¹è¯æ„ä¹‰"}}
        ],
        "visual_storytelling": "ç”»é¢å™äº‹å’Œè§†è§‰å…ƒç´ åˆ†æ",
        "audience_hook": "å¸å¼•è§‚ä¼—çš„æ ¸å¿ƒå–ç‚¹"
    }},
    "series_continuity_analysis": {{
        "previous_episodes_connection": "ä¸å‰é¢å‰§é›†çš„å…·ä½“è”ç³»å’Œå‘¼åº”",
        "story_threads_progression": "æ•…äº‹çº¿ç´¢çš„å‘å±•å’Œæ¨è¿›",
        "character_arcs_development": "è§’è‰²å¼§çº¿åœ¨æœ¬é›†ä¸­çš„å…·ä½“å‘å±•",
        "foreshadowing_elements": "ä¸ºåç»­å‰§é›†åŸ‹ä¸‹çš„ä¼ç¬”å’Œé“ºå«",
        "recurring_themes": "é‡å¤å‡ºç°çš„ä¸»é¢˜å’Œæ¯é¢˜",
        "narrative_continuity": "å™äº‹è¿è´¯æ€§å’Œæ•´ä½“æ•…äº‹ç»“æ„ä¸­çš„ä½ç½®"
    }},
    "creative_insights": {{
        "unique_elements": "æœ¬é›†ç‹¬ç‰¹çš„åˆ›æ„å…ƒç´ ",
        "storytelling_techniques": "ä½¿ç”¨çš„å™äº‹æŠ€å·§",
        "emotional_manipulation": "æƒ…æ„Ÿè°ƒåŠ¨çš„æ‰‹æ³•",
        "surprise_elements": "æ„å¤–è½¬æŠ˜å’ŒæƒŠå–œç‚¹",
        "subtext_analysis": "æ½œå°è¯å’Œéšå«æ„ä¹‰"
    }},
    "production_recommendations": {{
        "editing_approach": "å‰ªè¾‘æ‰‹æ³•å»ºè®®",
        "music_mood": "é…ä¹æƒ…ç»ªå»ºè®®",
        "pacing_control": "èŠ‚å¥æ§åˆ¶è¦ç‚¹",
        "transition_strategy": "ä¸å…¶ä»–ç‰‡æ®µçš„è¡”æ¥ç­–ç•¥",
        "audience_retention": "ä¿æŒè§‚ä¼—æ³¨æ„åŠ›çš„è¦ç‚¹"
    }}
}}

åˆ†æåŸåˆ™ï¼š
1. å®Œå…¨åŸºäºå†…å®¹ï¼Œä¸å—ä»»ä½•é¢„è®¾ç±»å‹é™åˆ¶
2. ä»æ•´ä½“å‰§æƒ…å‡ºå‘ï¼Œé€‰æ‹©æœ€å…·ä»£è¡¨æ€§å’Œè¿è´¯æ€§çš„ç‰‡æ®µ
3. æ·±åº¦åˆ†æå‰§æƒ…ä»·å€¼ï¼Œä¸ä»…ä»…æ˜¯è¡¨é¢çš„æˆå‰§å†²çª
4. é‡è§†ä¸Šä¸‹æ–‡è¡”æ¥ï¼Œç¡®ä¿ç‰‡æ®µåœ¨æ•´ä¸ªæ•…äº‹ä¸­çš„åˆç†ä½ç½®
5. è€ƒè™‘è§‚ä¼—ä½“éªŒï¼Œé€‰æ‹©èƒ½å¤Ÿç‹¬ç«‹æˆç¯‡åˆèå…¥æ•´ä½“çš„å†…å®¹
6. æä¾›ä¸“ä¸šçš„åˆ¶ä½œæŒ‡å¯¼ï¼Œè€Œéæ¨¡æ¿åŒ–å»ºè®®"""

        try:
            print(f"ğŸ¤– AIæ·±åº¦åˆ†æä¸­...")
            response = self._call_ai_api(prompt)
            
            if response:
                analysis = self._parse_ai_response(response)
                if analysis and self._validate_analysis(analysis, subtitles):
                    # ä¿å­˜ç¼“å­˜
                    self._save_cache(cache_path, analysis)
                    
                    # æ›´æ–°å‰§é›†ä¸Šä¸‹æ–‡
                    self._update_series_context(analysis, episode_name)
                    
                    return analysis
            
            print("âš ï¸ AIåˆ†æå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ")
            return self.basic_analysis_fallback(subtitles, episode_name)
            
        except Exception as e:
            print(f"âŒ AIåˆ†æå‡ºé”™: {e}")
            return self.basic_analysis_fallback(subtitles, episode_name)

    def _call_ai_api(self, prompt: str) -> Optional[str]:
        """è°ƒç”¨AI API"""
        config = self.ai_config
        
        try:
            headers = {
                'Authorization': f'Bearer {config["api_key"]}',
                'Content-Type': 'application/json'
            }
            
            data = {
                'model': config.get('model', 'gpt-3.5-turbo'),
                'messages': [
                    {
                        'role': 'system',
                        'content': 'ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§å‰§æƒ…åˆ†æå¸ˆï¼Œæ“…é•¿è¯†åˆ«ç²¾å½©ç‰‡æ®µå’Œä¿æŒæ•…äº‹è¿è´¯æ€§ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚'
                    },
                    {'role': 'user', 'content': prompt}
                ],
                'max_tokens': 4000,
                'temperature': 0.7
            }
            
            base_url = config.get('base_url', 'https://api.openai.com/v1')
            response = requests.post(
                f"{base_url}/chat/completions",
                headers=headers,
                json=data,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result.get('choices', [{}])[0].get('message', {}).get('content', '')
                return content
            else:
                print(f"APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"APIè°ƒç”¨å¼‚å¸¸: {e}")
            return None

    def _parse_ai_response(self, response: str) -> Optional[Dict]:
        """è§£æAIå“åº”"""
        try:
            # æå–JSONå†…å®¹
            if "```json" in response:
                start = response.find("```json") + 7
                end = response.find("```", start)
                json_str = response[start:end].strip()
            else:
                start = response.find("{")
                end = response.rfind("}") + 1
                if start >= 0 and end > start:
                    json_str = response[start:end]
                else:
                    json_str = response.strip()
            
            analysis = json.loads(json_str)
            return analysis
            
        except json.JSONDecodeError as e:
            print(f"JSONè§£æé”™è¯¯: {e}")
            return None

    def _validate_analysis(self, analysis: Dict, subtitles: List[Dict]) -> bool:
        """éªŒè¯åˆ†æç»“æœ - é€‚é…æ–°çš„åˆ†æç»“æ„"""
        try:
            # æ£€æŸ¥æ–°çš„å¿…è¦å­—æ®µ
            if 'optimal_highlight_segment' not in analysis:
                return False
            
            segment = analysis['optimal_highlight_segment']
            if not all(key in segment for key in ['start_time', 'end_time', 'segment_title']):
                return False
            
            # éªŒè¯æ—¶é—´æ ¼å¼å’ŒèŒƒå›´
            start_time = segment['start_time']
            end_time = segment['end_time']
            
            start_seconds = self._time_to_seconds(start_time)
            end_seconds = self._time_to_seconds(end_time)
            
            if start_seconds >= end_seconds:
                return False
            
            duration = end_seconds - start_seconds
            if duration < 90 or duration > 360:  # 1.5-6åˆ†é’ŸèŒƒå›´ï¼Œæ›´çµæ´»
                print(f"âš ï¸ ç‰‡æ®µæ—¶é•¿ {duration:.1f}ç§’ ä¸åœ¨æ¨èèŒƒå›´å†…ï¼Œä½†ä»ç„¶æ¥å—")
            
            # æ£€æŸ¥æ—¶é—´æ˜¯å¦åœ¨å­—å¹•èŒƒå›´å†…
            subtitle_start = min(sub['start_seconds'] for sub in subtitles)
            subtitle_end = max(sub['end_seconds'] for sub in subtitles)
            
            if start_seconds < subtitle_start or end_seconds > subtitle_end:
                # å°è¯•ä¿®æ­£åˆ°æœ€æ¥è¿‘çš„å­—å¹•æ—¶é—´
                closest_start = min(subtitles, key=lambda s: abs(s['start_seconds'] - start_seconds))
                closest_end = min(subtitles, key=lambda s: abs(s['end_seconds'] - end_seconds))
                
                segment['start_time'] = closest_start['start']
                segment['end_time'] = closest_end['end']
                segment['duration_seconds'] = closest_end['end_seconds'] - closest_start['start_seconds']
                print(f"âœ… æ—¶é—´å·²ä¿®æ­£åˆ°å­—å¹•èŒƒå›´å†…")
            
            return True
            
        except Exception as e:
            print(f"éªŒè¯åˆ†æç»“æœå‡ºé”™: {e}")
            return False

    def basic_analysis_fallback(self, subtitles: List[Dict], episode_name: str) -> Dict:
        """åŸºç¡€åˆ†æå¤‡é€‰æ–¹æ¡ˆ"""
        episode_num = self._extract_episode_number(episode_name)
        
        # ç®€å•çš„å…³é”®è¯è¯„åˆ†
        keywords = {
            'æ³•å¾‹': ['æ³•å®˜', 'æ£€å¯Ÿå®˜', 'å¾‹å¸ˆ', 'æ³•åº­', 'å®¡åˆ¤', 'è¯æ®', 'æ¡ˆä»¶', 'èµ·è¯‰', 'è¾©æŠ¤'],
            'æƒ…æ„Ÿ': ['çˆ±', 'æ¨', 'æƒ…', 'å¿ƒ', 'æ„ŸåŠ¨', 'ç—›è‹¦', 'å¿«ä¹', 'æ‚²ä¼¤'],
            'æ‚¬ç–‘': ['çœŸç›¸', 'ç§˜å¯†', 'å‘ç°', 'çº¿ç´¢', 'è°ƒæŸ¥', 'æ­éœ²', 'ç¥ç§˜'],
            'å†²çª': ['äº‰è®º', 'åµæ¶', 'æ‰“æ–—', 'å¯¹æŠ—', 'å†²çª', 'çŸ›ç›¾', 'åå¯¹'],
            'è½¬æŠ˜': ['çªç„¶', 'æ²¡æƒ³åˆ°', 'åŸæ¥', 'ç«ç„¶', 'åè½¬', 'å˜åŒ–', 'æ”¹å˜']
        }
        
        # è¯„åˆ†æ¯ä¸ªå­—å¹•
        scored_subtitles = []
        for i, subtitle in enumerate(subtitles):
            score = 0
            text = subtitle['text']
            
            # å…³é”®è¯è¯„åˆ†
            for category, words in keywords.items():
                for word in words:
                    if word in text:
                        score += 2
            
            # æƒ…æ„Ÿå¼ºåº¦è¯„åˆ†
            score += text.count('ï¼') * 1.5
            score += text.count('ï¼Ÿ') * 1
            score += text.count('...') * 0.5
            
            # ä½ç½®åŠ æƒ
            position_ratio = i / len(subtitles)
            if position_ratio < 0.3 or position_ratio > 0.7:
                score *= 1.2
            
            if score > 3:
                scored_subtitles.append((i, score, subtitle))
        
        if not scored_subtitles:
            # é€‰æ‹©ä¸­é—´éƒ¨åˆ†
            mid_point = len(subtitles) // 2
            scored_subtitles = [(mid_point, 5, subtitles[mid_point])]
        
        # é€‰æ‹©æœ€é«˜åˆ†ç‰‡æ®µ
        scored_subtitles.sort(key=lambda x: x[1], reverse=True)
        center_idx, score, center_sub = scored_subtitles[0]
        
        # æ‰©å±•åˆ°2-3åˆ†é’Ÿ
        target_duration = 150  # 2.5åˆ†é’Ÿ
        start_idx = center_idx
        end_idx = center_idx
        
        # å‘å‰åæ‰©å±•
        while start_idx > 0:
            test_duration = subtitles[end_idx]['end_seconds'] - subtitles[start_idx-1]['start_seconds']
            if test_duration > target_duration:
                break
            start_idx -= 1
        
        while end_idx < len(subtitles) - 1:
            test_duration = subtitles[end_idx+1]['end_seconds'] - subtitles[start_idx]['start_seconds']
            if test_duration > target_duration * 1.2:
                break
            end_idx += 1
        
        # æ„å»ºåˆ†æç»“æœ
        start_time = subtitles[start_idx]['start']
        end_time = subtitles[end_idx]['end']
        duration = subtitles[end_idx]['end_seconds'] - subtitles[start_idx]['start_seconds']
        
        return {
            "episode_analysis": {
                "episode_number": episode_num,
                "drama_type": "é€šç”¨å‰§æƒ…",
                "main_storyline": f"ç¬¬{episode_num}é›†æ ¸å¿ƒå‰§æƒ…",
                "key_characters": ["ä¸»è¦è§’è‰²"],
                "emotional_arc": "æƒ…æ„Ÿå‘å±•",
                "plot_progression": "å‰§æƒ…æ¨è¿›"
            },
            "core_segment": {
                "title": f"ç¬¬{episode_num}é›†ç²¾å½©ç‰‡æ®µ",
                "start_time": start_time,
                "end_time": end_time,
                "duration_seconds": duration,
                "plot_significance": "é‡è¦å‰§æƒ…èŠ‚ç‚¹",
                "dramatic_value": 7.0,
                "emotional_impact": 7.0,
                "key_dialogues": [
                    {"timestamp": start_time, "speaker": "è§’è‰²", "line": subtitles[start_idx]['text'][:50]}
                ],
                "content_highlights": [
                    "æ ¸å¿ƒå‰§æƒ…å‘å±•",
                    "è§’è‰²å…³ç³»å˜åŒ–",
                    "æƒ…èŠ‚æ¨è¿›"
                ]
            },
            "series_continuity": {
                "previous_connection": "ä¸å‰é›†çš„è‡ªç„¶å»¶ç»­",
                "next_episode_setup": "ä¸ºä¸‹é›†å‰§æƒ…å‘å±•é“ºå«",
                "ongoing_storylines": ["ä¸»çº¿å‰§æƒ…"],
                "character_development": "è§’è‰²æˆé•¿"
            }
        }

    def create_video_clip(self, analysis: Dict, video_file: str, episode_name: str) -> bool:
        """åˆ›å»ºè§†é¢‘å‰ªè¾‘ - é€‚é…æ–°çš„åˆ†æç»“æ„"""
        try:
            segment = analysis['optimal_highlight_segment']
            title = segment['segment_title']
            start_time = segment['start_time']
            end_time = segment['end_time']
            
            # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
            safe_title = re.sub(r'[^\w\u4e00-\u9fff\-_]', '_', title)
            output_name = f"{safe_title}.mp4"
            output_path = os.path.join(self.output_folder, output_name)
            
            print(f"\nğŸ¬ åˆ›å»ºè§†é¢‘å‰ªè¾‘: {title}")
            print(f"ğŸ“ æºè§†é¢‘: {os.path.basename(video_file)}")
            print(f"â±ï¸ æ—¶é—´æ®µ: {start_time} --> {end_time}")
            print(f"ğŸ“ æ—¶é•¿: {segment['duration_seconds']:.1f}ç§’")
            
            # è½¬æ¢æ—¶é—´ä¸ºç§’
            start_seconds = self._time_to_seconds(start_time)
            end_seconds = self._time_to_seconds(end_time)
            duration = end_seconds - start_seconds
            
            # æ·»åŠ ç¼“å†²æ—¶é—´
            buffer_start = max(0, start_seconds - 1)
            buffer_duration = duration + 2
            
            # FFmpegå‰ªè¾‘å‘½ä»¤
            cmd = [
                'ffmpeg',
                '-i', video_file,
                '-ss', str(buffer_start),
                '-t', str(buffer_duration),
                '-c:v', 'libx264',
                '-c:a', 'aac',
                '-preset', 'medium',
                '-crf', '23',
                '-movflags', '+faststart',
                '-avoid_negative_ts', 'make_zero',
                output_path,
                '-y'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0 and os.path.exists(output_path):
                file_size = os.path.getsize(output_path) / (1024*1024)
                print(f"  âœ… å‰ªè¾‘æˆåŠŸ: {output_name} ({file_size:.1f}MB)")
                
                # ç”Ÿæˆè¯¦ç»†è¯´æ˜æ–‡ä»¶
                self._create_description_file(output_path, analysis, episode_name)
                
                return True
            else:
                error_msg = result.stderr[:200] if result.stderr else "æœªçŸ¥é”™è¯¯"
                print(f"  âŒ å‰ªè¾‘å¤±è´¥: {error_msg}")
                return False
                
        except Exception as e:
            print(f"âŒ åˆ›å»ºè§†é¢‘å‰ªè¾‘å‡ºé”™: {e}")
            return False

    def _create_description_file(self, video_path: str, analysis: Dict, episode_name: str):
        """åˆ›å»ºè¯¦ç»†è¯´æ˜æ–‡ä»¶ - é€‚é…æ–°çš„åˆ†æç»“æ„"""
        try:
            desc_path = video_path.replace('.mp4', '_æ·±åº¦åˆ†æ.txt')
            
            comprehensive = analysis.get('comprehensive_analysis', {})
            segment = analysis.get('optimal_highlight_segment', {})
            continuity = analysis.get('series_continuity_analysis', {})
            insights = analysis.get('creative_insights', {})
            recommendations = analysis.get('production_recommendations', {})
            
            content = f"""ğŸ¬ {segment.get('segment_title', 'ç²¾å½©ç‰‡æ®µ')}
{"=" * 100}

ğŸ“Š åŸºæœ¬ä¿¡æ¯
â±ï¸ ç²¾ç¡®æ—¶é—´æ®µ: {segment.get('start_time')} --> {segment.get('end_time')}
ğŸ“ ç‰‡æ®µæ—¶é•¿: {segment.get('duration_seconds', 0):.1f} ç§’
ğŸ­ è‡ªåŠ¨è¯†åˆ«ç±»å‹: {comprehensive.get('auto_detected_genre', 'æœªè¯†åˆ«')}
ğŸ“– å™äº‹é£æ ¼: {comprehensive.get('narrative_style', 'æ ‡å‡†å™äº‹')}
ğŸ’« æƒ…æ„Ÿæ ¸å¿ƒ: {comprehensive.get('emotional_core', 'æƒ…æ„Ÿè¡¨è¾¾')}

ğŸ¯ é€‰æ‹©ç†ç”±
{segment.get('selection_reasoning', 'åŸºäºAIæ™ºèƒ½åˆ†æé€‰æ‹©çš„æœ€ä½³ç‰‡æ®µ')}

ğŸ­ æˆå‰§ç»“æ„åˆ†æ
â€¢ å¼€åœºå¸å¼•: {segment.get('dramatic_arc', {}).get('opening', 'è‡ªç„¶å¼€åœº')}
â€¢ å‰§æƒ…å‘å±•: {segment.get('dramatic_arc', {}).get('development', 'é€æ­¥æ¨è¿›')}
â€¢ é«˜æ½®æ—¶åˆ»: {segment.get('dramatic_arc', {}).get('climax', 'æƒ…æ„Ÿ/å‰§æƒ…é«˜æ½®')}
â€¢ æ”¶å°¾è¡”æ¥: {segment.get('dramatic_arc', {}).get('resolution', 'å®Œæ•´æ”¶å°¾')}

ğŸ’¡ æƒ…æ„Ÿä½“éªŒè·¯å¾„
{segment.get('emotional_journey', 'è§‚ä¼—æƒ…æ„Ÿè·Ÿéšå‰§æƒ…å‘å±•çš„å®Œæ•´ä½“éªŒ')}

â­ å…³é”®æ—¶åˆ»åˆ†æ
"""
            
            for moment in segment.get('key_moments', []):
                content += f"[{moment.get('time', '')}] {moment.get('description', '')}\n"
                content += f"    å†²å‡»åŠ›: {moment.get('impact', '')}\n\n"
            
            content += f"""
ğŸ“ é‡è¦å¯¹è¯åˆ†æ
"""
            for dialogue in segment.get('dialogue_highlights', []):
                content += f"[{dialogue.get('timestamp', '')}] {dialogue.get('context', 'åœºæ™¯')}\n"
                content += f"å°è¯: {dialogue.get('line', '')}\n"
                content += f"æ„ä¹‰: {dialogue.get('significance', '')}\n\n"
            
            content += f"""
ğŸ”— å‰§é›†è¿è´¯æ€§æ·±åº¦åˆ†æ
â€¢ å‰é›†è”ç³»: {continuity.get('previous_episodes_connection', 'è‡ªç„¶å»¶ç»­')}
â€¢ æ•…äº‹æ¨è¿›: {continuity.get('story_threads_progression', 'å‰§æƒ…å‘å±•')}
â€¢ è§’è‰²å‘å±•: {continuity.get('character_arcs_development', 'è§’è‰²æˆé•¿')}
â€¢ ä¼ç¬”é“ºå«: {continuity.get('foreshadowing_elements', 'ä¸ºåç»­é“ºå«')}
â€¢ ä¸»é¢˜å‘¼åº”: {continuity.get('recurring_themes', 'ä¸»é¢˜å»¶ç»­')}

ğŸ¨ åˆ›æ„æ´å¯Ÿ
â€¢ ç‹¬ç‰¹å…ƒç´ : {insights.get('unique_elements', 'æœ¬é›†ç‰¹è‰²')}
â€¢ å™äº‹æŠ€å·§: {insights.get('storytelling_techniques', 'ä¸“ä¸šå™äº‹æ‰‹æ³•')}
â€¢ æƒ…æ„Ÿè°ƒåŠ¨: {insights.get('emotional_manipulation', 'æƒ…æ„Ÿå…±é¸£æŠ€å·§')}
â€¢ æƒŠå–œå…ƒç´ : {insights.get('surprise_elements', 'æ„å¤–è½¬æŠ˜')}
â€¢ æ·±å±‚å«ä¹‰: {insights.get('subtext_analysis', 'æ½œå°è¯åˆ†æ')}

ğŸ“º è§‚ä¼—å¸å¼•åŠ›
â€¢ æ ¸å¿ƒå–ç‚¹: {segment.get('audience_hook', 'å¸å¼•è§‚ä¼—çš„å…³é”®å› ç´ ')}
â€¢ è§†è§‰å™äº‹: {segment.get('visual_storytelling', 'ç”»é¢è¯­è¨€åˆ†æ')}

ğŸ¬ åˆ¶ä½œå»ºè®®
â€¢ å‰ªè¾‘æ‰‹æ³•: {recommendations.get('editing_approach', 'ä¸“ä¸šå‰ªè¾‘å»ºè®®')}
â€¢ é…ä¹æƒ…ç»ª: {recommendations.get('music_mood', 'éŸ³ä¹æ°›å›´å»ºè®®')}
â€¢ èŠ‚å¥æ§åˆ¶: {recommendations.get('pacing_control', 'èŠ‚å¥æŠŠæ¡è¦ç‚¹')}
â€¢ è¡”æ¥ç­–ç•¥: {recommendations.get('transition_strategy', 'ä¸å…¶ä»–å†…å®¹çš„è¡”æ¥')}
â€¢ æ³¨æ„åŠ›ä¿æŒ: {recommendations.get('audience_retention', 'è§‚ä¼—ç²˜æ€§ç­–ç•¥')}

ğŸ“„ æŠ€æœ¯ä¿¡æ¯
â€¢ åŸå§‹æ–‡ä»¶: {episode_name}
â€¢ åˆ†ææ–¹å¼: AIæ·±åº¦æ™ºèƒ½åˆ†æ
â€¢ æ—¶é—´ç²¾åº¦: æ¯«ç§’çº§ç²¾ç¡®
â€¢ å†…å®¹å®Œæ•´æ€§: ä¿è¯å‰§æƒ…å®Œæ•´å’Œè¿è´¯
â€¢ ä¸Šä¸‹æ–‡è€ƒé‡: å……åˆ†ç»“åˆå‰åå‰§æƒ…

ğŸŒŸ æ•´ä½“ä»·å€¼è¯„ä¼°
æœ¬ç‰‡æ®µä»£è¡¨äº†æœ¬é›†çš„ç²¾åå†…å®¹ï¼Œæ—¢èƒ½ç‹¬ç«‹å±•ç°ç²¾å½©å‰§æƒ…ï¼Œåˆä¸æ•´ä¸ªæ•…äº‹çº¿ä¿æŒå®Œç¾è¡”æ¥ã€‚
é€šè¿‡AIæ·±åº¦åˆ†æï¼Œç¡®ä¿äº†é€‰æ‹©çš„ç§‘å­¦æ€§å’Œè§‚èµä»·å€¼çš„æœ€å¤§åŒ–ã€‚

ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
åˆ†æå¼•æ“: æ™ºèƒ½AIç”µè§†å‰§åˆ†æç³»ç»Ÿ v2.0
"""
            
            with open(desc_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            print(f"    ğŸ“„ ç”Ÿæˆæ·±åº¦åˆ†æ: {os.path.basename(desc_path)}")
            
        except Exception as e:
            print(f"    âš ï¸ ç”Ÿæˆè¯´æ˜æ–‡ä»¶å¤±è´¥: {e}")

    def find_matching_video(self, episode_name: str) -> Optional[str]:
        """æ™ºèƒ½åŒ¹é…è§†é¢‘æ–‡ä»¶"""
        if not os.path.exists(self.video_folder):
            return None
        
        base_name = os.path.splitext(episode_name)[0]
        video_extensions = ['.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv', '.ts']
        
        # ç²¾ç¡®åŒ¹é…
        for ext in video_extensions:
            video_path = os.path.join(self.video_folder, base_name + ext)
            if os.path.exists(video_path):
                return video_path
        
        # æ¨¡ç³ŠåŒ¹é… - æå–é›†æ•°
        episode_patterns = [r'[Ee](\d+)', r'EP(\d+)', r'ç¬¬(\d+)é›†', r'S\d+E(\d+)', r'(\d+)']
        episode_num = None
        
        for pattern in episode_patterns:
            match = re.search(pattern, base_name, re.I)
            if match:
                episode_num = match.group(1)
                break
        
        if episode_num:
            for filename in os.listdir(self.video_folder):
                if any(filename.lower().endswith(ext) for ext in video_extensions):
                    for pattern in episode_patterns:
                        match = re.search(pattern, filename, re.I)
                        if match and match.group(1).zfill(2) == episode_num.zfill(2):
                            return os.path.join(self.video_folder, filename)
        
        return None

    def _get_cache_path(self, episode_name: str, subtitles: List[Dict]) -> str:
        """è·å–ç¼“å­˜è·¯å¾„"""
        content_hash = hashlib.md5(str(subtitles).encode()).hexdigest()[:16]
        safe_name = re.sub(r'[^\w\-_]', '_', episode_name)
        return os.path.join(self.cache_folder, f"{safe_name}_{content_hash}.json")

    def _load_cache(self, cache_path: str) -> Optional[Dict]:
        """åŠ è½½ç¼“å­˜"""
        if os.path.exists(cache_path):
            try:
                with open(cache_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                pass
        return None

    def _save_cache(self, cache_path: str, analysis: Dict):
        """ä¿å­˜ç¼“å­˜"""
        try:
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(analysis, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")

    def _build_coherent_full_script(self, subtitles: List[Dict]) -> str:
        """æ„å»ºå®Œæ•´è¿è´¯çš„å‰§æƒ…æ–‡æœ¬ - è§£å†³å‰²è£‚é—®é¢˜"""
        # æŒ‰åœºæ™¯åˆ†ç»„ï¼Œä¿æŒå‰§æƒ…è¿è´¯æ€§
        scenes = []
        current_scene = []
        last_time = 0
        
        for subtitle in subtitles:
            # å¦‚æœæ—¶é—´é—´éš”è¶…è¿‡30ç§’ï¼Œè®¤ä¸ºæ˜¯æ–°åœºæ™¯
            if subtitle['start_seconds'] - last_time > 30 and current_scene:
                scene_text = '\n'.join([sub['text'] for sub in current_scene])
                scene_time = f"[åœºæ™¯æ—¶é—´: {current_scene[0]['start']} - {current_scene[-1]['end']}]"
                scenes.append(f"{scene_time}\n{scene_text}")
                current_scene = []
            
            current_scene.append(subtitle)
            last_time = subtitle['end_seconds']
        
        # æ·»åŠ æœ€åä¸€ä¸ªåœºæ™¯
        if current_scene:
            scene_text = '\n'.join([sub['text'] for sub in current_scene])
            scene_time = f"[åœºæ™¯æ—¶é—´: {current_scene[0]['start']} - {current_scene[-1]['end']}]"
            scenes.append(f"{scene_time}\n{scene_text}")
        
        return '\n\n=== åœºæ™¯åˆ†å‰² ===\n\n'.join(scenes)
    
    def _build_rich_series_context(self, current_episode: str) -> str:
        """æ„å»ºä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ - è§£å†³ä¸Šä¸‹æ–‡è¡”æ¥é—®é¢˜"""
        if not self.series_context['previous_episodes']:
            return "è¿™æ˜¯å‰§é›†åˆ†æçš„å¼€å§‹ï¼Œæš‚æ— å‰é›†ä¸Šä¸‹æ–‡ã€‚"
        
        context_parts = []
        
        # å‰é›†å›é¡¾
        context_parts.append("ã€å‰é›†å‰§æƒ…å›é¡¾ã€‘")
        for prev_ep in self.series_context['previous_episodes'][-3:]:  # æœ€è¿‘3é›†
            context_parts.append(f"â€¢ {prev_ep['episode']}")
            context_parts.append(f"  ç±»å‹: {prev_ep.get('drama_type', 'æœªçŸ¥')}")
            context_parts.append(f"  æ ¸å¿ƒå‰§æƒ…: {prev_ep.get('summary', 'æš‚æ— ')}")
            context_parts.append(f"  ä¸»è¦è§’è‰²: {', '.join(prev_ep.get('characters', []))}")
            context_parts.append("")
        
        # æŒç»­æ•…äº‹çº¿
        all_storylines = set()
        for ep in self.series_context['previous_episodes']:
            all_storylines.update(ep.get('storylines', []))
        
        if all_storylines:
            context_parts.append("ã€æŒç»­æ•…äº‹çº¿ç´¢ã€‘")
            for storyline in list(all_storylines):
                context_parts.append(f"â€¢ {storyline}")
            context_parts.append("")
        
        # ä¸»è¦è§’è‰²å‘å±•è½¨è¿¹
        all_characters = set()
        for ep in self.series_context['previous_episodes']:
            all_characters.update(ep.get('characters', []))
        
        if all_characters:
            context_parts.append("ã€ä¸»è¦è§’è‰²ã€‘")
            for character in list(all_characters):
                context_parts.append(f"â€¢ {character}")
            context_parts.append("")
        
        # å‰§æƒ…å‘å±•è¶‹åŠ¿
        if len(self.series_context['previous_episodes']) > 1:
            context_parts.append("ã€å‰§æƒ…å‘å±•è¶‹åŠ¿ã€‘")
            context_parts.append("è¯·åˆ†ææœ¬é›†åœ¨æ•´ä¸ªæ•…äº‹å‘å±•ä¸­çš„ä½ç½®å’Œä½œç”¨")
            context_parts.append("")
        
        return '\n'.join(context_parts)
    
    def _update_series_context(self, analysis: Dict, episode_name: str):
        """æ›´æ–°å‰§é›†ä¸Šä¸‹æ–‡ - æ”¯æŒæ–°çš„åˆ†æç»“æ„"""
        comprehensive = analysis.get('comprehensive_analysis', {})
        segment_info = analysis.get('optimal_highlight_segment', {})
        continuity = analysis.get('series_continuity_analysis', {})
        
        episode_summary = {
            'episode': episode_name,
            'drama_type': comprehensive.get('auto_detected_genre', ''),
            'summary': segment_info.get('selection_reasoning', ''),
            'characters': comprehensive.get('character_dynamics', '').split('ã€') if comprehensive.get('character_dynamics') else [],
            'storylines': continuity.get('story_threads_progression', '').split('ã€') if continuity.get('story_threads_progression') else [],
            'themes': comprehensive.get('thematic_elements', ''),
            'emotional_core': comprehensive.get('emotional_core', '')
        }
        
        self.series_context['previous_episodes'].append(episode_summary)
        
        # åªä¿ç•™æœ€è¿‘5é›†çš„ä¸Šä¸‹æ–‡
        if len(self.series_context['previous_episodes']) > 6:
            self.series_context['previous_episodes'] = self.series_context['previous_episodes'][-5:]

    def _extract_episode_number(self, filename: str) -> str:
        """æå–é›†æ•°"""
        patterns = [r'[Ee](\d+)', r'EP(\d+)', r'ç¬¬(\d+)é›†', r'S\d+E(\d+)', r'(\d+)']
        for pattern in patterns:
            match = re.search(pattern, filename, re.I)
            if match:
                return match.group(1).zfill(2)
        return "01"

    def _time_to_seconds(self, time_str: str) -> float:
        """æ—¶é—´è½¬æ¢ä¸ºç§’"""
        try:
            time_str = time_str.replace(',', '.')
            parts = time_str.split(':')
            if len(parts) == 3:
                h, m, s = parts
                return int(h) * 3600 + int(m) * 60 + float(s)
            return 0.0
        except:
            return 0.0

    def process_all_episodes(self):
        """å¤„ç†æ‰€æœ‰é›†æ•°"""
        print("\nğŸš€ å¼€å§‹æ™ºèƒ½åˆ†æå’Œå‰ªè¾‘")
        print("=" * 60)
        
        # è·å–å­—å¹•æ–‡ä»¶
        srt_files = []
        for filename in os.listdir(self.srt_folder):
            if filename.lower().endswith(('.srt', '.txt')) and not filename.startswith('.'):
                srt_files.append(filename)
        
        if not srt_files:
            print(f"âŒ {self.srt_folder}/ ç›®å½•ä¸­æœªæ‰¾åˆ°å­—å¹•æ–‡ä»¶")
            return
        
        srt_files.sort()
        print(f"ğŸ“„ æ‰¾åˆ° {len(srt_files)} ä¸ªå­—å¹•æ–‡ä»¶")
        
        success_count = 0
        all_analyses = []
        
        for srt_file in srt_files:
            try:
                print(f"\nğŸ“º å¤„ç†: {srt_file}")
                
                # è§£æå­—å¹•
                srt_path = os.path.join(self.srt_folder, srt_file)
                subtitles = self.parse_subtitle_file(srt_path)
                
                if not subtitles:
                    print(f"âŒ å­—å¹•è§£æå¤±è´¥")
                    continue
                
                # AIåˆ†æ
                analysis = self.ai_analyze_episode(subtitles, srt_file)
                
                if not analysis:
                    print(f"âŒ åˆ†æå¤±è´¥")
                    continue
                
                all_analyses.append({
                    'file': srt_file,
                    'analysis': analysis
                })
                
                # å¯»æ‰¾å¯¹åº”è§†é¢‘
                video_file = self.find_matching_video(srt_file)
                
                if not video_file:
                    print(f"âš ï¸ æœªæ‰¾åˆ°å¯¹åº”è§†é¢‘æ–‡ä»¶")
                    continue
                
                # åˆ›å»ºè§†é¢‘å‰ªè¾‘
                if self.create_video_clip(analysis, video_file, srt_file):
                    success_count += 1
                    print(f"âœ… {srt_file} å¤„ç†å®Œæˆ")
                else:
                    print(f"âŒ {srt_file} å‰ªè¾‘å¤±è´¥")
                    
            except Exception as e:
                print(f"âŒ å¤„ç† {srt_file} æ—¶å‡ºé”™: {e}")
        
        # ç”Ÿæˆæ•´ä½“æŠ¥å‘Š
        self._generate_series_report(all_analyses, success_count, len(srt_files))

    def _generate_series_report(self, analyses: List[Dict], success_count: int, total_count: int):
        """ç”Ÿæˆæ•´ä½“å‰§é›†æŠ¥å‘Š"""
        if not analyses:
            return
        
        report_path = os.path.join(self.output_folder, "æ™ºèƒ½åˆ†ææŠ¥å‘Š.txt")
        
        content = f"""ğŸ¤– æ™ºèƒ½AIç”µè§†å‰§åˆ†ææŠ¥å‘Š
{"=" * 80}

ğŸ“Š å¤„ç†ç»Ÿè®¡:
â€¢ æ€»é›†æ•°: {total_count} é›†
â€¢ æˆåŠŸå¤„ç†: {success_count} é›†
â€¢ æˆåŠŸç‡: {(success_count/total_count*100):.1f}%
â€¢ AIåˆ†æ: {'å¯ç”¨' if self.ai_config.get('enabled') else 'åŸºç¡€è§„åˆ™'}

ğŸ­ å‰§æƒ…ç±»å‹åˆ†å¸ƒ:
"""
        
        # ç»Ÿè®¡å‰§æƒ…ç±»å‹
        drama_types = {}
        total_duration = 0
        
        for item in analyses:
            analysis = item['analysis']
            drama_type = analysis.get('episode_analysis', {}).get('drama_type', 'æœªçŸ¥')
            drama_types[drama_type] = drama_types.get(drama_type, 0) + 1
            
            segment = analysis.get('core_segment', {})
            total_duration += segment.get('duration_seconds', 0)
        
        for drama_type, count in sorted(drama_types.items(), key=lambda x: x[1], reverse=True):
            content += f"â€¢ {drama_type}: {count} é›†\n"
        
        avg_duration = total_duration / len(analyses) if analyses else 0
        
        content += f"""
ğŸ“ æ—¶é•¿ç»Ÿè®¡:
â€¢ æ€»æ—¶é•¿: {total_duration:.1f} ç§’ ({total_duration/60:.1f} åˆ†é’Ÿ)
â€¢ å¹³å‡æ—¶é•¿: {avg_duration:.1f} ç§’ ({avg_duration/60:.1f} åˆ†é’Ÿ)

ğŸ“º è¯¦ç»†åˆ†æ:
"""
        
        # è¯¦ç»†åˆ†ææ¯ä¸€é›†
        for i, item in enumerate(analyses, 1):
            analysis = item['analysis']
            episode_analysis = analysis.get('episode_analysis', {})
            segment = analysis.get('core_segment', {})
            continuity = analysis.get('series_continuity', {})
            
            content += f"""
{i}. {segment.get('title', 'ç²¾å½©ç‰‡æ®µ')}
   æ–‡ä»¶: {item['file']}
   ç±»å‹: {episode_analysis.get('drama_type', 'æœªçŸ¥')}
   æ—¶é•¿: {segment.get('duration_seconds', 0):.1f}ç§’
   ä»·å€¼: {segment.get('dramatic_value', 0):.1f}/10
   è¿è´¯æ€§: {continuity.get('next_episode_setup', 'æœªçŸ¥')[:50]}...
"""
        
        content += f"""
ğŸ”— æ•´ä½“è¿è´¯æ€§åˆ†æ:
â€¢ æ•…äº‹ä¸»çº¿ä¿æŒè¿ç»­æ€§
â€¢ è§’è‰²å‘å±•å…·æœ‰é€»è¾‘æ€§
â€¢ å„é›†ä¹‹é—´æœ‰æ˜ç¡®çš„è¡”æ¥ç‚¹
â€¢ æ•´ä½“å™äº‹ç»“æ„å®Œæ•´

ğŸ’¡ ä½¿ç”¨å»ºè®®:
â€¢ æŒ‰é¡ºåºè§‚çœ‹çŸ­è§†é¢‘ä»¥ä¿æŒå‰§æƒ…è¿è´¯
â€¢ æ¯ä¸ªè§†é¢‘éƒ½æœ‰è¯¦ç»†çš„åˆ†ææ–‡ä»¶
â€¢ å¯æ ¹æ®å‰§æƒ…ç±»å‹åˆ†ç±»è§‚çœ‹
â€¢ å»ºè®®é…åˆåˆ†ææ–‡ä»¶ç†è§£å‰§æƒ…å‘å±•

ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"\nğŸ“„ æ™ºèƒ½åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        except Exception as e:
            print(f"âš ï¸ æŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    system = IntelligentAIAnalysisSystem()
    
    print("\nè¯·é€‰æ‹©æ“ä½œæ¨¡å¼:")
    print("1. ğŸš€ å¼€å§‹æ™ºèƒ½åˆ†æå’Œå‰ªè¾‘")
    print("2. âš™ï¸ é…ç½®AIè®¾ç½®")
    print("3. ğŸ“ æ£€æŸ¥æ–‡ä»¶çŠ¶æ€")
    print("4. âŒ é€€å‡º")
    
    while True:
        try:
            choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-4): ").strip()
            
            if choice == '1':
                system.process_all_episodes()
                break
            elif choice == '2':
                configure_ai()
            elif choice == '3':
                check_file_status(system)
            elif choice == '4':
                print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼")
                break
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­")
            break
        except Exception as e:
            print(f"âŒ æ“ä½œé”™è¯¯: {e}")

def configure_ai():
    """é…ç½®AIè®¾ç½®"""
    print("\nâš™ï¸ AIé…ç½®è®¾ç½®")
    print("=" * 40)
    
    config = {
        'enabled': True,
        'base_url': input("APIåœ°å€ (é»˜è®¤: https://api.openai.com/v1): ").strip() or "https://api.openai.com/v1",
        'api_key': input("APIå¯†é’¥: ").strip(),
        'model': input("æ¨¡å‹åç§° (é»˜è®¤: gpt-3.5-turbo): ").strip() or "gpt-3.5-turbo"
    }
    
    if config['api_key']:
        try:
            with open('.ai_config.json', 'w', encoding='utf-8') as f:
                json.dump(config, f, ensure_ascii=False, indent=2)
            print("âœ… AIé…ç½®ä¿å­˜æˆåŠŸ")
        except Exception as e:
            print(f"âŒ é…ç½®ä¿å­˜å¤±è´¥: {e}")
    else:
        print("âŒ APIå¯†é’¥ä¸èƒ½ä¸ºç©º")

def check_file_status(system):
    """æ£€æŸ¥æ–‡ä»¶çŠ¶æ€"""
    print("\nğŸ“ æ–‡ä»¶çŠ¶æ€æ£€æŸ¥")
    print("=" * 40)
    
    # æ£€æŸ¥å­—å¹•æ–‡ä»¶
    srt_count = 0
    if os.path.exists(system.srt_folder):
        srt_files = [f for f in os.listdir(system.srt_folder) 
                    if f.lower().endswith(('.srt', '.txt'))]
        srt_count = len(srt_files)
        print(f"ğŸ“„ å­—å¹•æ–‡ä»¶: {srt_count} ä¸ª")
        if srt_count > 0:
            for f in srt_files[:5]:
                print(f"  â€¢ {f}")
            if srt_count > 5:
                print(f"  ... ç­‰å…± {srt_count} ä¸ªæ–‡ä»¶")
    else:
        print(f"âŒ å­—å¹•ç›®å½•ä¸å­˜åœ¨: {system.srt_folder}/")
    
    # æ£€æŸ¥è§†é¢‘æ–‡ä»¶
    video_count = 0
    if os.path.exists(system.video_folder):
        video_files = [f for f in os.listdir(system.video_folder) 
                      if f.lower().endswith(('.mp4', '.mkv', '.avi', '.mov', '.wmv'))]
        video_count = len(video_files)
        print(f"ğŸ¬ è§†é¢‘æ–‡ä»¶: {video_count} ä¸ª")
        if video_count > 0:
            for f in video_files[:5]:
                print(f"  â€¢ {f}")
            if video_count > 5:
                print(f"  ... ç­‰å…± {video_count} ä¸ªæ–‡ä»¶")
    else:
        print(f"âŒ è§†é¢‘ç›®å½•ä¸å­˜åœ¨: {system.video_folder}/")
    
    # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
    clip_count = 0
    if os.path.exists(system.output_folder):
        clip_files = [f for f in os.listdir(system.output_folder) 
                     if f.lower().endswith('.mp4')]
        clip_count = len(clip_files)
        print(f"âœ‚ï¸ å·²å‰ªè¾‘: {clip_count} ä¸ª")
    
    print(f"\nçŠ¶æ€æ€»ç»“:")
    print(f"â€¢ å‡†å¤‡å°±ç»ª: {'âœ…' if srt_count > 0 and video_count > 0 else 'âŒ'}")
    print(f"â€¢ AIé…ç½®: {'âœ…' if os.path.exists('.ai_config.json') else 'âŒ'}")

if __name__ == "__main__":
    main()
