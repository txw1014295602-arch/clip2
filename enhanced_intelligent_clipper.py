
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å¢å¼ºç‰ˆæ™ºèƒ½ç”µè§†å‰§å‰ªè¾‘ç³»ç»Ÿ
è§£å†³æ‰€æœ‰é—®é¢˜çš„å®Œæ•´æ–¹æ¡ˆï¼š
1. å®Œå…¨æ™ºèƒ½åŒ–ï¼Œä¸é™åˆ¶å‰§æƒ…ç±»å‹
2. å®Œæ•´ä¸Šä¸‹æ–‡åˆ†æï¼Œé¿å…å‰²è£‚
3. æ¯é›†å¤šä¸ªè¿è´¯çŸ­è§†é¢‘
4. AIåˆ¤æ–­å®Œæ•´å‰ªè¾‘å†…å®¹
5. è‡ªåŠ¨ç”Ÿæˆè§†é¢‘å’Œæ—ç™½
6. ä¿è¯å‰§æƒ…è¿è´¯æ€§
7. ç¼“å­˜æœºåˆ¶é¿å…é‡å¤è°ƒç”¨API
8. ä¸€è‡´æ€§ä¿è¯
"""

import os
import re
import json
import subprocess
import hashlib
from typing import List, Dict, Optional, Tuple
from datetime import datetime
import requests

class EnhancedIntelligentClipper:
    def __init__(self, video_folder: str = "videos", srt_folder: str = "srt", output_folder: str = "clips"):
        self.video_folder = video_folder
        self.srt_folder = srt_folder
        self.output_folder = output_folder
        self.cache_folder = "analysis_cache"
        
        # åˆ›å»ºç›®å½•
        for folder in [self.video_folder, self.srt_folder, self.output_folder, self.cache_folder]:
            if not os.path.exists(folder):
                os.makedirs(folder)
                print(f"âœ“ åˆ›å»ºç›®å½•: {folder}/")
        
        # åŠ è½½AIé…ç½®
        self.ai_config = self.load_ai_config()
        
        # å…¨å‰§åˆ†æç¼“å­˜
        self.series_analysis = None
        
    def load_ai_config(self) -> Dict:
        """åŠ è½½AIé…ç½®"""
        try:
            with open('.ai_config.json', 'r', encoding='utf-8') as f:
                config = json.load(f)
                if config.get('enabled', False) and config.get('api_key'):
                    print(f"âœ… AIé…ç½®å·²åŠ è½½: {config.get('provider', 'æœªçŸ¥')}")
                    return config
        except:
            pass
        
        return {'enabled': False}

    def parse_complete_episode(self, filepath: str) -> Dict:
        """è§£æå®Œæ•´é›†æ•°çš„å­—å¹•ï¼Œä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§"""
        print(f"ğŸ“– è§£æå®Œæ•´å­—å¹•: {filepath}")
        
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
        except:
            try:
                with open(filepath, 'r', encoding='gbk', errors='ignore') as f:
                    content = f.read()
            except:
                print(f"âŒ æ— æ³•è¯»å–æ–‡ä»¶: {filepath}")
                return {}
        
        # æ™ºèƒ½é”™åˆ«å­—ä¿®æ­£
        corrections = {
            'é˜²è¡›': 'é˜²å«', 'æ­£ç•¶': 'æ­£å½“', 'è¨¼æ“š': 'è¯æ®', 'æª¢å¯Ÿå®˜': 'æ£€å¯Ÿå®˜',
            'ç™¼ç¾': 'å‘ç°', 'æ±ºå®š': 'å†³å®š', 'é¸æ“‡': 'é€‰æ‹©', 'é–‹å§‹': 'å¼€å§‹',
            'çµæŸ': 'ç»“æŸ', 'å•é¡Œ': 'é—®é¢˜', 'æ©Ÿæœƒ': 'æœºä¼š', 'è½è­‰æœƒ': 'å¬è¯ä¼š',
            'èª¿æŸ¥': 'è°ƒæŸ¥', 'èµ·è¨´': 'èµ·è¯‰', 'å¯¾è©±': 'å¯¹è¯', 'é–¢ä¿‚': 'å…³ç³»'
        }
        
        for old, new in corrections.items():
            content = content.replace(old, new)
        
        # è§£æå­—å¹•
        subtitles = []
        blocks = re.split(r'\n\s*\n', content.strip())
        
        for block in blocks:
            lines = block.strip().split('\n')
            if len(lines) >= 3:
                try:
                    index = int(lines[0]) if lines[0].isdigit() else len(subtitles) + 1
                    time_match = re.search(r'(\d{2}:\d{2}:\d{2}[,\.]\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2}[,\.]\d{3})', lines[1])
                    if time_match:
                        start_time = time_match.group(1).replace('.', ',')
                        end_time = time_match.group(2).replace('.', ',')
                        text = '\n'.join(lines[2:]).strip()
                        
                        if text:
                            subtitles.append({
                                'index': index,
                                'start': start_time,
                                'end': end_time,
                                'text': text
                            })
                except (ValueError, IndexError):
                    continue
        
        # æ„å»ºå®Œæ•´å‰§æƒ…æ–‡æœ¬ï¼ˆåˆ†æ®µå¤„ç†ï¼Œä¿æŒä¸Šä¸‹æ–‡ï¼‰
        full_text_segments = []
        current_segment = []
        
        for i, sub in enumerate(subtitles):
            current_segment.append(sub['text'])
            
            # æ¯30å¥ä½œä¸ºä¸€ä¸ªæ®µè½
            if len(current_segment) >= 30 or i == len(subtitles) - 1:
                segment_text = ' '.join(current_segment)
                full_text_segments.append({
                    'start_index': i - len(current_segment) + 1,
                    'end_index': i,
                    'text': segment_text,
                    'start_time': subtitles[i - len(current_segment) + 1]['start'] if current_segment else '00:00:00,000',
                    'end_time': subtitles[i]['end']
                })
                current_segment = []
        
        episode_data = {
            'filename': os.path.basename(filepath),
            'subtitles': subtitles,
            'full_text_segments': full_text_segments,
            'total_duration': self.time_to_seconds(subtitles[-1]['end']) if subtitles else 0
        }
        
        print(f"âœ“ è§£æå®Œæˆ: {len(subtitles)} æ¡å­—å¹•, {len(full_text_segments)} ä¸ªæ–‡æœ¬æ®µè½")
        return episode_data

    def get_analysis_cache_path(self, episode_data: Dict) -> str:
        """è·å–åˆ†æç¼“å­˜è·¯å¾„"""
        # ä½¿ç”¨æ–‡ä»¶å†…å®¹hashä½œä¸ºç¼“å­˜key
        content_hash = hashlib.md5(str(episode_data['subtitles']).encode()).hexdigest()[:16]
        filename = episode_data['filename'].replace('.', '_')
        return os.path.join(self.cache_folder, f"{filename}_{content_hash}.json")

    def load_analysis_cache(self, episode_data: Dict) -> Optional[Dict]:
        """åŠ è½½åˆ†æç¼“å­˜"""
        cache_path = self.get_analysis_cache_path(episode_data)
        if os.path.exists(cache_path):
            try:
                with open(cache_path, 'r', encoding='utf-8') as f:
                    cached_analysis = json.load(f)
                    print(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜åˆ†æ: {os.path.basename(cache_path)}")
                    return cached_analysis
            except:
                pass
        return None

    def save_analysis_cache(self, episode_data: Dict, analysis: Dict):
        """ä¿å­˜åˆ†æç¼“å­˜"""
        cache_path = self.get_analysis_cache_path(episode_data)
        try:
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(analysis, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ ä¿å­˜åˆ†æç¼“å­˜: {os.path.basename(cache_path)}")
        except Exception as e:
            print(f"âš  ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")

    def ai_analyze_episode_complete(self, episode_data: Dict, series_context: str = "") -> Dict:
        """AIå®Œæ•´åˆ†æå•é›†ï¼ŒåŒ…å«å¤šä¸ªç²¾å½©ç‰‡æ®µ"""
        # æ£€æŸ¥ç¼“å­˜
        cached_analysis = self.load_analysis_cache(episode_data)
        if cached_analysis:
            return cached_analysis
        
        if not self.ai_config.get('enabled', False):
            print("âš  AIæœªå¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ")
            return self.basic_analysis_fallback(episode_data)
        
        filename = episode_data['filename']
        episode_num = self.extract_episode_number(filename)
        
        # æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡
        full_context = self.build_episode_context(episode_data, series_context)
        
        prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§å‰ªè¾‘å¸ˆï¼Œéœ€è¦ä¸ºè¿™ä¸€é›†åˆ›å»ºå¤šä¸ª2-3åˆ†é’Ÿçš„ç²¾å½©çŸ­è§†é¢‘ã€‚

ã€é›†æ•°ä¿¡æ¯ã€‘ç¬¬{episode_num}é›†
ã€å‰§é›†èƒŒæ™¯ã€‘{series_context}

ã€å®Œæ•´å‰§æƒ…å†…å®¹ã€‘
{full_context}

è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

1. å‰§æƒ…ç±»å‹è¯†åˆ«ï¼šè‡ªåŠ¨è¯†åˆ«è¿™æ˜¯ä»€ä¹ˆç±»å‹çš„ç”µè§†å‰§ï¼ˆæ³•å¾‹ã€çˆ±æƒ…ã€æ‚¬ç–‘ã€å¤è£…ã€ç°ä»£ã€çŠ¯ç½ªç­‰ï¼‰

2. ç²¾å½©ç‰‡æ®µè¯†åˆ«ï¼šæ‰¾å‡º3-5ä¸ªæœ€ç²¾å½©çš„ç‰‡æ®µï¼Œæ¯ä¸ª2-3åˆ†é’Ÿï¼Œè¦æ±‚ï¼š
   - åŒ…å«å®Œæ•´çš„å¯¹è¯åœºæ™¯
   - æœ‰æ˜ç¡®çš„æˆå‰§å†²çªæˆ–æƒ…æ„Ÿé«˜æ½®
   - èƒ½ç‹¬ç«‹æˆä¸ºä¸€ä¸ªçŸ­è§†é¢‘
   - ä¿è¯ä¸€å¥è¯è¯´å®Œï¼Œä¸è¦æˆªæ–­å¯¹è¯

3. å‰§æƒ…è¿è´¯æ€§ï¼šç¡®ä¿è¿™äº›ç‰‡æ®µèƒ½è¿è´¯åœ°è®²è¿°æœ¬é›†çš„æ ¸å¿ƒæ•…äº‹

4. æ—ç™½ç”Ÿæˆï¼šä¸ºæ¯ä¸ªç‰‡æ®µç”Ÿæˆä¸“ä¸šçš„æ—ç™½è§£è¯´ï¼Œè§£é‡Šç²¾å½©ä¹‹å¤„

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
{{
    "episode_analysis": {{
        "episode_number": {episode_num},
        "genre": "å‰§æƒ…ç±»å‹",
        "main_theme": "æœ¬é›†ä¸»è¦ä¸»é¢˜",
        "story_progression": "åœ¨æ•´ä½“å‰§æƒ…ä¸­çš„ä½œç”¨",
        "emotional_arc": "æƒ…æ„Ÿå‘å±•å¼§çº¿"
    }},
    "highlight_segments": [
        {{
            "segment_id": 1,
            "title": "ç‰‡æ®µæ ‡é¢˜",
            "start_time": "å¼€å§‹æ—¶é—´æˆ³",
            "end_time": "ç»“æŸæ—¶é—´æˆ³", 
            "duration_seconds": æŒç»­ç§’æ•°,
            "description": "ç‰‡æ®µå†…å®¹æè¿°",
            "dramatic_value": "æˆå‰§ä»·å€¼ï¼ˆ0-10åˆ†ï¼‰",
            "key_dialogues": ["å…³é”®å¯¹è¯1", "å…³é”®å¯¹è¯2"],
            "plot_significance": "å‰§æƒ…é‡è¦æ€§",
            "emotional_impact": "æƒ…æ„Ÿå†²å‡»ç‚¹",
            "narration": {{
                "opening": "å¼€åœºæ—ç™½",
                "process": "è¿‡ç¨‹è§£è¯´", 
                "climax": "é«˜æ½®è§£è¯´",
                "conclusion": "ç»“å°¾æ€»ç»“"
            }},
            "connection_to_next": "ä¸ä¸‹ä¸ªç‰‡æ®µçš„è¿æ¥"
        }}
    ],
    "episode_summary": {{
        "core_conflicts": ["æ ¸å¿ƒå†²çªç‚¹1", "æ ¸å¿ƒå†²çªç‚¹2"],
        "character_development": "è§’è‰²å‘å±•",
        "plot_twists": ["å‰§æƒ…è½¬æŠ˜ç‚¹"],
        "setup_for_next_episode": "ä¸ºä¸‹é›†çš„é“ºå«"
    }},
    "overall_coherence": "æ•´é›†è¿è´¯æ€§è¯´æ˜"
}}"""

        try:
            response = self.call_ai_api(prompt)
            if response:
                analysis = self.parse_ai_analysis(response)
                if analysis:
                    # ä¿å­˜ç¼“å­˜
                    self.save_analysis_cache(episode_data, analysis)
                    return analysis
        except Exception as e:
            print(f"âš  AIåˆ†æå¤±è´¥: {e}")
        
        # å¤±è´¥æ—¶ä½¿ç”¨åŸºç¡€åˆ†æ
        basic_analysis = self.basic_analysis_fallback(episode_data)
        self.save_analysis_cache(episode_data, basic_analysis)
        return basic_analysis

    def build_episode_context(self, episode_data: Dict, series_context: str) -> str:
        """æ„å»ºå®Œæ•´çš„å‰§é›†ä¸Šä¸‹æ–‡"""
        # å–å‰80%çš„å­—å¹•å†…å®¹ä½œä¸ºå®Œæ•´ä¸Šä¸‹æ–‡
        subtitles = episode_data['subtitles']
        context_end = int(len(subtitles) * 0.8)
        
        context_parts = []
        for i in range(0, context_end, 50):  # æ¯50å¥åˆ†ä¸€æ®µ
            segment_texts = [sub['text'] for sub in subtitles[i:i+50]]
            context_parts.append(' '.join(segment_texts))
        
        return '\n\n'.join(context_parts)

    def basic_analysis_fallback(self, episode_data: Dict) -> Dict:
        """åŸºç¡€åˆ†æå¤‡é€‰æ–¹æ¡ˆ"""
        filename = episode_data['filename']
        episode_num = self.extract_episode_number(filename)
        subtitles = episode_data['subtitles']
        
        # åŸºç¡€åˆ†æ®µé€»è¾‘
        total_duration = episode_data['total_duration']
        segment_count = min(4, max(2, int(total_duration / 180)))  # 2-4ä¸ªç‰‡æ®µ
        
        segments = []
        segment_length = len(subtitles) // segment_count
        
        for i in range(segment_count):
            start_idx = i * segment_length
            end_idx = min((i + 1) * segment_length, len(subtitles) - 1)
            
            start_time = subtitles[start_idx]['start']
            end_time = subtitles[end_idx]['end']
            duration = self.time_to_seconds(end_time) - self.time_to_seconds(start_time)
            
            segments.append({
                "segment_id": i + 1,
                "title": f"ç¬¬{episode_num}é›† ç²¾å½©ç‰‡æ®µ{i + 1}",
                "start_time": start_time,
                "end_time": end_time,
                "duration_seconds": duration,
                "description": f"æœ¬é›†ç¬¬{i + 1}æ®µç²¾å½©å†…å®¹",
                "dramatic_value": 7.0,
                "key_dialogues": [subtitles[start_idx + j]['text'] for j in range(min(3, end_idx - start_idx))],
                "plot_significance": "å‰§æƒ…æ¨è¿›",
                "emotional_impact": "æƒ…æ„Ÿå‘å±•",
                "narration": {
                    "opening": "åœ¨è¿™ä¸ªç‰‡æ®µä¸­",
                    "process": "æˆ‘ä»¬çœ‹åˆ°å‰§æƒ…çš„å‘å±•",
                    "climax": "è¾¾åˆ°äº†ä¸€ä¸ªå°é«˜æ½®",
                    "conclusion": "ä¸ºåç»­å‰§æƒ…åšé“ºå«"
                },
                "connection_to_next": "æ‰¿ä¸Šå¯ä¸‹"
            })
        
        return {
            "episode_analysis": {
                "episode_number": episode_num,
                "genre": "general",
                "main_theme": f"ç¬¬{episode_num}é›†ä¸»è¦å†…å®¹",
                "story_progression": "å‰§æƒ…å‘å±•",
                "emotional_arc": "æƒ…æ„Ÿæ¨è¿›"
            },
            "highlight_segments": segments,
            "episode_summary": {
                "core_conflicts": ["ä¸»è¦å†²çª"],
                "character_development": "è§’è‰²å‘å±•",
                "plot_twists": ["æƒ…èŠ‚è½¬æŠ˜"],
                "setup_for_next_episode": "ä¸‹é›†é¢„å‘Š"
            },
            "overall_coherence": "æœ¬é›†å†…å®¹è¿è´¯"
        }

    def call_ai_api(self, prompt: str) -> Optional[str]:
        """è°ƒç”¨AI APIï¼Œå¸¦é‡è¯•æœºåˆ¶"""
        max_retries = 3
        
        for attempt in range(max_retries):
            try:
                config = self.ai_config
                
                headers = {
                    'Authorization': f'Bearer {config["api_key"]}',
                    'Content-Type': 'application/json'
                }
                
                data = {
                    'model': config.get('model', 'claude-3-5-sonnet-20240620'),
                    'messages': [
                        {
                            'role': 'system', 
                            'content': 'ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§å‰ªè¾‘å¸ˆå’Œå‰§æƒ…åˆ†æå¸ˆï¼Œæ“…é•¿è¯†åˆ«ç²¾å½©ç‰‡æ®µå’Œä¿æŒå‰§æƒ…è¿è´¯æ€§ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚'
                        },
                        {'role': 'user', 'content': prompt}
                    ],
                    'max_tokens': 4000,
                    'temperature': 0.7
                }
                
                response = requests.post(
                    f"{config.get('base_url', 'https://www.chataiapi.com/v1')}/chat/completions",
                    headers=headers,
                    json=data,
                    timeout=60
                )
                
                if response.status_code == 200:
                    result = response.json()
                    content = result.get('choices', [{}])[0].get('message', {}).get('content', '')
                    return content
                else:
                    print(f"âš  APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {response.status_code}")
                    if attempt < max_retries - 1:
                        import time
                        time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                    
            except Exception as e:
                print(f"âš  APIè°ƒç”¨å¼‚å¸¸ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    import time
                    time.sleep(2 ** attempt)
        
        return None

    def parse_ai_analysis(self, response_text: str) -> Optional[Dict]:
        """è§£æAIåˆ†æç»“æœ"""
        try:
            # æå–JSON
            if "```json" in response_text:
                json_start = response_text.find("```json") + 7
                json_end = response_text.find("```", json_start)
                response_text = response_text[json_start:json_end]
            elif "{" in response_text:
                json_start = response_text.find("{")
                json_end = response_text.rfind("}") + 1
                response_text = response_text[json_start:json_end]
            
            analysis = json.loads(response_text)
            
            # éªŒè¯å¿…è¦å­—æ®µ
            if 'highlight_segments' in analysis and 'episode_analysis' in analysis:
                return analysis
            else:
                print("âš  AIåˆ†æç»“æœç¼ºå°‘å¿…è¦å­—æ®µ")
                return None
                
        except json.JSONDecodeError as e:
            print(f"âš  AIåˆ†æç»“æœJSONè§£æå¤±è´¥: {e}")
            return None

    def create_video_clip(self, episode_data: Dict, segment: Dict, video_file: str) -> bool:
        """åˆ›å»ºå•ä¸ªè§†é¢‘ç‰‡æ®µï¼Œä¿è¯ä¸€è‡´æ€§"""
        try:
            segment_id = segment['segment_id']
            title = segment['title']
            start_time = segment['start_time']
            end_time = segment['end_time']
            
            # ç”Ÿæˆä¸€è‡´çš„è¾“å‡ºæ–‡ä»¶å
            safe_title = re.sub(r'[^\w\u4e00-\u9fff\-_]', '_', title)
            output_filename = f"{safe_title}_seg{segment_id}.mp4"
            output_path = os.path.join(self.output_folder, output_filename)
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
                print(f"  âœ“ è§†é¢‘å·²å­˜åœ¨: {output_filename}")
                return True
            
            print(f"  ğŸ¬ å‰ªè¾‘ç‰‡æ®µ{segment_id}: {title}")
            print(f"     æ—¶é—´: {start_time} --> {end_time}")
            
            # è®¡ç®—æ—¶é—´å‚æ•°
            start_seconds = self.time_to_seconds(start_time)
            end_seconds = self.time_to_seconds(end_time)
            duration = end_seconds - start_seconds
            
            if duration <= 0:
                print(f"  âŒ æ— æ•ˆæ—¶é—´æ®µ")
                return False
            
            # æ·»åŠ ç¼“å†²æ—¶é—´ç¡®ä¿å¯¹è¯å®Œæ•´
            buffer_start = max(0, start_seconds - 2)
            buffer_duration = duration + 4
            
            # æ„å»ºFFmpegå‘½ä»¤
            cmd = [
                'ffmpeg',
                '-i', video_file,
                '-ss', str(buffer_start),
                '-t', str(buffer_duration),
                '-c:v', 'libx264',
                '-c:a', 'aac',
                '-preset', 'medium',
                '-crf', '23',
                '-movflags', '+faststart',
                '-avoid_negative_ts', 'make_zero',
                output_path,
                '-y'
            ]
            
            # æ‰§è¡Œå‰ªè¾‘
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0 and os.path.exists(output_path):
                file_size = os.path.getsize(output_path) / (1024*1024)
                print(f"    âœ… æˆåŠŸ: {output_filename} ({file_size:.1f}MB)")
                
                # ç”Ÿæˆæ—ç™½æ–‡ä»¶
                self.create_narration_file(output_path, segment)
                
                return True
            else:
                print(f"    âŒ å¤±è´¥: {result.stderr[:100] if result.stderr else 'æœªçŸ¥é”™è¯¯'}")
                return False
                
        except Exception as e:
            print(f"    âŒ å‰ªè¾‘å¼‚å¸¸: {e}")
            return False

    def create_narration_file(self, video_path: str, segment: Dict):
        """åˆ›å»ºæ—ç™½æ–‡ä»¶"""
        try:
            narration_path = video_path.replace('.mp4', '_æ—ç™½.txt')
            
            narration = segment.get('narration', {})
            
            content = f"""ğŸ¬ {segment['title']}
{"=" * 50}

â±ï¸ æ—¶é•¿: {segment['duration_seconds']:.1f} ç§’
ğŸ¯ æˆå‰§ä»·å€¼: {segment['dramatic_value']}/10
ğŸ“ å‰§æƒ…æ„ä¹‰: {segment['plot_significance']}
ğŸ’¥ æƒ…æ„Ÿå†²å‡»: {segment['emotional_impact']}

ğŸ™ï¸ æ—ç™½è§£è¯´:
ã€å¼€åœºã€‘{narration.get('opening', '')}
ã€è¿‡ç¨‹ã€‘{narration.get('process', '')}
ã€é«˜æ½®ã€‘{narration.get('climax', '')}
ã€ç»“å°¾ã€‘{narration.get('conclusion', '')}

ğŸ’¬ å…³é”®å¯¹è¯:
"""
            
            for dialogue in segment.get('key_dialogues', []):
                content += f"â€¢ {dialogue}\n"
            
            content += f"""
ğŸ“– å†…å®¹æè¿°:
{segment['description']}

ğŸ”— ä¸ä¸‹æ®µè¿æ¥:
{segment.get('connection_to_next', 'è‡ªç„¶è¿‡æ¸¡')}
"""
            
            with open(narration_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            print(f"    ğŸ“„ æ—ç™½æ–‡ä»¶: {os.path.basename(narration_path)}")
            
        except Exception as e:
            print(f"    âš  æ—ç™½ç”Ÿæˆå¤±è´¥: {e}")

    def find_matching_video(self, subtitle_filename: str) -> Optional[str]:
        """æ™ºèƒ½åŒ¹é…è§†é¢‘æ–‡ä»¶"""
        base_name = os.path.splitext(subtitle_filename)[0]
        
        # å°è¯•ç²¾ç¡®åŒ¹é…
        video_extensions = ['.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv', '.ts']
        for ext in video_extensions:
            video_path = os.path.join(self.video_folder, base_name + ext)
            if os.path.exists(video_path):
                return video_path
        
        # æ¨¡ç³ŠåŒ¹é…
        if os.path.exists(self.video_folder):
            for filename in os.listdir(self.video_folder):
                if any(filename.lower().endswith(ext) for ext in video_extensions):
                    file_base = os.path.splitext(filename)[0]
                    if any(part in file_base.lower() for part in base_name.lower().split('_') if len(part) > 2):
                        return os.path.join(self.video_folder, filename)
        
        return None

    def extract_episode_number(self, filename: str) -> str:
        """æå–é›†æ•°"""
        patterns = [r'[Ee](\d+)', r'EP(\d+)', r'ç¬¬(\d+)é›†', r'S\d+E(\d+)']
        for pattern in patterns:
            match = re.search(pattern, filename, re.I)
            if match:
                return match.group(1).zfill(2)
        return "00"

    def time_to_seconds(self, time_str: str) -> float:
        """æ—¶é—´è½¬æ¢ä¸ºç§’"""
        try:
            time_str = time_str.replace('.', ',')
            h, m, s_ms = time_str.split(':')
            s, ms = s_ms.split(',')
            return int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000
        except:
            return 0

    def process_single_episode(self, subtitle_file: str) -> bool:
        """å¤„ç†å•é›†å®Œæ•´æµç¨‹"""
        print(f"\nğŸ“º å¤„ç†é›†æ•°: {subtitle_file}")
        
        # 1. è§£æå­—å¹•
        subtitle_path = os.path.join(self.srt_folder, subtitle_file)
        episode_data = self.parse_complete_episode(subtitle_path)
        
        if not episode_data:
            print(f"âŒ å­—å¹•è§£æå¤±è´¥")
            return False
        
        # 2. AIåˆ†æ (å¸¦ç¼“å­˜)
        print(f"ğŸ§  AIåˆ†æå‰§æƒ…...")
        analysis = self.ai_analyze_episode_complete(episode_data, self.get_series_context())
        
        if not analysis:
            print(f"âŒ å‰§æƒ…åˆ†æå¤±è´¥")
            return False
        
        # 3. æ‰¾åˆ°è§†é¢‘æ–‡ä»¶
        video_file = self.find_matching_video(subtitle_file)
        if not video_file:
            print(f"âŒ æœªæ‰¾åˆ°å¯¹åº”è§†é¢‘æ–‡ä»¶")
            return False
        
        print(f"ğŸ“ è§†é¢‘æ–‡ä»¶: {os.path.basename(video_file)}")
        
        # 4. å‰ªè¾‘æ‰€æœ‰ç‰‡æ®µ
        segments = analysis.get('highlight_segments', [])
        successful_clips = []
        
        for segment in segments:
            if self.create_video_clip(episode_data, segment, video_file):
                successful_clips.append(segment)
        
        # 5. ç”Ÿæˆé›†æ•°æ€»ç»“
        self.create_episode_summary(subtitle_file, analysis, successful_clips)
        
        print(f"âœ… {subtitle_file} å¤„ç†å®Œæˆ: {len(successful_clips)}/{len(segments)} ä¸ªç‰‡æ®µæˆåŠŸ")
        return len(successful_clips) > 0

    def get_series_context(self) -> str:
        """è·å–æ•´ä¸ªå‰§é›†çš„ä¸Šä¸‹æ–‡"""
        if not self.series_analysis:
            # ç®€å•çš„å‰§é›†èƒŒæ™¯
            return "è¿™æ˜¯ä¸€éƒ¨ç”µè§†å‰§ï¼ŒåŒ…å«å¤šä¸ªç›¸äº’å…³è”çš„å‰§æƒ…çº¿ã€‚"
        return self.series_analysis

    def create_episode_summary(self, subtitle_file: str, analysis: Dict, successful_clips: List[Dict]):
        """åˆ›å»ºé›†æ•°æ€»ç»“"""
        try:
            episode_analysis = analysis.get('episode_analysis', {})
            episode_summary = analysis.get('episode_summary', {})
            
            summary_path = os.path.join(self.output_folder, f"{os.path.splitext(subtitle_file)[0]}_æ€»ç»“.txt")
            
            content = f"""ğŸ“º {subtitle_file} - å‰ªè¾‘æ€»ç»“
{"=" * 60}

ğŸ“Š åŸºæœ¬ä¿¡æ¯:
â€¢ é›†æ•°: ç¬¬{episode_analysis.get('episode_number', '?')}é›†
â€¢ ç±»å‹: {episode_analysis.get('genre', 'æœªçŸ¥')}
â€¢ ä¸»é¢˜: {episode_analysis.get('main_theme', 'å‰§æƒ…å‘å±•')}
â€¢ æƒ…æ„Ÿå¼§çº¿: {episode_analysis.get('emotional_arc', 'æƒ…æ„Ÿæ¨è¿›')}

ğŸ¬ å‰ªè¾‘æˆæœ:
â€¢ æˆåŠŸç‰‡æ®µ: {len(successful_clips)} ä¸ª
â€¢ æ€»æ—¶é•¿: {sum(clip['duration_seconds'] for clip in successful_clips):.1f} ç§’

ğŸ“ å‰§æƒ…è¦ç‚¹:
â€¢ æ ¸å¿ƒå†²çª: {', '.join(episode_summary.get('core_conflicts', []))}
â€¢ è§’è‰²å‘å±•: {episode_summary.get('character_development', 'è§’è‰²æˆé•¿')}
â€¢ å‰§æƒ…è½¬æŠ˜: {', '.join(episode_summary.get('plot_twists', []))}
â€¢ ä¸‹é›†é“ºå«: {episode_summary.get('setup_for_next_episode', 'å¾…ç»­')}

ğŸ”— è¿è´¯æ€§è¯´æ˜:
{analysis.get('overall_coherence', 'æœ¬é›†å‰§æƒ…è¿è´¯å®Œæ•´')}

ğŸ¯ ç‰‡æ®µè¯¦æƒ…:
"""
            
            for i, clip in enumerate(successful_clips, 1):
                content += f"""
{i}. {clip['title']}
   æ—¶é—´: {clip['start_time']} - {clip['end_time']} ({clip['duration_seconds']:.1f}ç§’)
   ä»·å€¼: {clip['dramatic_value']}/10
   æ„ä¹‰: {clip['plot_significance']}
   å†²å‡»: {clip['emotional_impact']}
"""
            
            with open(summary_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            print(f"ğŸ“„ æ€»ç»“æ–‡ä»¶: {os.path.basename(summary_path)}")
            
        except Exception as e:
            print(f"âš  æ€»ç»“ç”Ÿæˆå¤±è´¥: {e}")

    def process_all_episodes(self):
        """å¤„ç†æ‰€æœ‰é›†æ•°"""
        print("ğŸš€ å¢å¼ºç‰ˆæ™ºèƒ½å‰ªè¾‘ç³»ç»Ÿå¯åŠ¨")
        print("=" * 60)
        
        # æ£€æŸ¥ç›®å½•
        if not os.path.exists(self.srt_folder):
            print(f"âŒ å­—å¹•ç›®å½•ä¸å­˜åœ¨: {self.srt_folder}")
            return
        
        if not os.path.exists(self.video_folder):
            print(f"âŒ è§†é¢‘ç›®å½•ä¸å­˜åœ¨: {self.video_folder}")
            return
        
        # è·å–å­—å¹•æ–‡ä»¶
        subtitle_files = [f for f in os.listdir(self.srt_folder) 
                         if f.endswith(('.srt', '.txt')) and not f.startswith('.')]
        subtitle_files.sort()
        
        if not subtitle_files:
            print(f"âŒ æœªæ‰¾åˆ°å­—å¹•æ–‡ä»¶")
            return
        
        print(f"ğŸ“ æ‰¾åˆ° {len(subtitle_files)} ä¸ªå­—å¹•æ–‡ä»¶")
        print(f"ğŸ¬ è§†é¢‘ç›®å½•: {self.video_folder}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_folder}")
        print(f"ğŸ’¾ ç¼“å­˜ç›®å½•: {self.cache_folder}")
        
        if self.ai_config.get('enabled'):
            print(f"ğŸ¤– AIåˆ†æ: å¯ç”¨ ({self.ai_config.get('provider', 'æœªçŸ¥')})")
        else:
            print(f"ğŸ“ AIåˆ†æ: æœªå¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€è§„åˆ™")
        
        # å¤„ç†æ¯ä¸€é›†
        total_success = 0
        total_clips = 0
        
        for subtitle_file in subtitle_files:
            try:
                success = self.process_single_episode(subtitle_file)
                if success:
                    total_success += 1
                
                # ç»Ÿè®¡æœ¬é›†ç‰‡æ®µæ•°
                episode_clips = [f for f in os.listdir(self.output_folder) 
                               if f.startswith(os.path.splitext(subtitle_file)[0]) and f.endswith('.mp4')]
                total_clips += len(episode_clips)
                
            except Exception as e:
                print(f"âŒ å¤„ç† {subtitle_file} æ—¶å‡ºé”™: {e}")
        
        # æœ€ç»ˆæŠ¥å‘Š
        self.create_final_report(total_success, len(subtitle_files), total_clips)

    def create_final_report(self, success_count: int, total_episodes: int, total_clips: int):
        """åˆ›å»ºæœ€ç»ˆæŠ¥å‘Š"""
        try:
            report_path = os.path.join(self.output_folder, "å‰ªè¾‘æŠ¥å‘Š.txt")
            
            content = f"""ğŸ¬ å¢å¼ºç‰ˆæ™ºèƒ½å‰ªè¾‘ç³»ç»Ÿ - æœ€ç»ˆæŠ¥å‘Š
{"=" * 60}

ğŸ“Š å¤„ç†ç»Ÿè®¡:
â€¢ æ€»é›†æ•°: {total_episodes} é›†
â€¢ æˆåŠŸå¤„ç†: {success_count} é›†
â€¢ æˆåŠŸç‡: {(success_count/total_episodes*100):.1f}%
â€¢ ç”Ÿæˆç‰‡æ®µ: {total_clips} ä¸ª

ğŸ¤– ç³»ç»Ÿé…ç½®:
â€¢ AIåˆ†æ: {'å¯ç”¨' if self.ai_config.get('enabled') else 'æœªå¯ç”¨'}
â€¢ ç¼“å­˜æœºåˆ¶: å¯ç”¨ (é¿å…é‡å¤APIè°ƒç”¨)
â€¢ ä¸€è‡´æ€§ä¿è¯: å¯ç”¨ (ç›¸åŒè¾“å…¥äº§ç”Ÿç›¸åŒè¾“å‡º)

ğŸ“ è¾“å‡ºæ–‡ä»¶:
â€¢ è§†é¢‘ç‰‡æ®µ: {self.output_folder}/*.mp4
â€¢ æ—ç™½è§£è¯´: {self.output_folder}/*_æ—ç™½.txt  
â€¢ é›†æ•°æ€»ç»“: {self.output_folder}/*_æ€»ç»“.txt
â€¢ åˆ†æç¼“å­˜: {self.cache_folder}/*.json

âœ¨ ä¸»è¦ç‰¹ç‚¹:
1. ğŸ§  å®Œå…¨æ™ºèƒ½åŒ– - ä¸é™åˆ¶å‰§æƒ…ç±»å‹ï¼ŒAIè‡ªåŠ¨è¯†åˆ«
2. ğŸ“– å®Œæ•´ä¸Šä¸‹æ–‡ - åŸºäºæ•´é›†åˆ†æï¼Œé¿å…ç‰‡æ®µå‰²è£‚
3. ğŸ¯ å¤šç‰‡æ®µå‰ªè¾‘ - æ¯é›†3-5ä¸ªç²¾å½©çŸ­è§†é¢‘
4. ğŸ™ï¸ ä¸“ä¸šæ—ç™½ - AIç”Ÿæˆå‰§æƒ…è§£è¯´å’Œåˆ†æ
5. ğŸ”— ä¿è¯è¿è´¯ - ç‰‡æ®µé—´å‰§æƒ…é€»è¾‘è¿è´¯
6. ğŸ’¾ æ™ºèƒ½ç¼“å­˜ - é¿å…é‡å¤APIè°ƒç”¨
7. âš–ï¸ ä¸€è‡´æ€§ä¿è¯ - å¤šæ¬¡è¿è¡Œç»“æœä¸€è‡´
8. ğŸ¬ å®Œæ•´å¯¹è¯ - ç¡®ä¿å¥å­å®Œæ•´ï¼Œä¸æˆªæ–­

ğŸ“ ä½¿ç”¨å»ºè®®:
â€¢ å°†å­—å¹•æ–‡ä»¶æ”¾åœ¨ {self.srt_folder}/ ç›®å½•
â€¢ å°†è§†é¢‘æ–‡ä»¶æ”¾åœ¨ {self.video_folder}/ ç›®å½•  
â€¢ æ–‡ä»¶åä¿æŒå¯¹åº”å…³ç³»ï¼ˆå¦‚ EP01.srt å¯¹åº” EP01.mp4ï¼‰
â€¢ AIåˆ†æç»“æœä¼šç¼“å­˜ï¼Œé¿å…é‡å¤è°ƒç”¨API
â€¢ å¯å¤šæ¬¡è¿è¡ŒåŒä¸€æ–‡ä»¶ï¼Œç»“æœä¿æŒä¸€è‡´

ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
            
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            print(f"\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
            print(f"âœ… æˆåŠŸå¤„ç†: {success_count}/{total_episodes} é›†")
            print(f"ğŸ¬ ç”Ÿæˆç‰‡æ®µ: {total_clips} ä¸ª")
            print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_path}")
            
        except Exception as e:
            print(f"âš  æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    clipper = EnhancedIntelligentClipper()
    clipper.process_all_episodes()

if __name__ == "__main__":
    main()
