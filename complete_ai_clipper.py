
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å®Œæ•´AIæ™ºèƒ½å‰ªè¾‘ç³»ç»Ÿ
è§£å†³æ‰€æœ‰éœ€æ±‚ï¼š
1. æ¯é›†å¤šä¸ªç²¾å½©çŸ­è§†é¢‘ï¼ŒAIåˆ¤æ–­å®Œæ•´å†…å®¹
2. å®é™…å‰ªè¾‘ç”Ÿæˆè§†é¢‘æ–‡ä»¶
3. videos/å’Œsrt/ç›®å½•ç»“æ„
4. ç”Ÿæˆæ—ç™½è§£è¯´æ–‡ä»¶
"""

import os
import re
import json
import subprocess
import hashlib
from typing import List, Dict, Optional
from datetime import datetime

class CompleteAIClipper:
    def __init__(self):
        self.srt_folder = "srt"
        self.video_folder = "videos"  
        self.output_folder = "ai_clips"
        self.cache_folder = "analysis_cache"
        
        # åˆ›å»ºç›®å½•
        for folder in [self.srt_folder, self.video_folder, self.output_folder, self.cache_folder]:
            os.makedirs(folder, exist_ok=True)
        
        # åŠ è½½AIé…ç½®
        self.ai_config = self.load_ai_config()
        
        # å‰§é›†ä¸Šä¸‹æ–‡
        self.series_context = []
        
        print("ğŸ¤– å®Œæ•´AIæ™ºèƒ½å‰ªè¾‘ç³»ç»Ÿå¯åŠ¨")
        print("=" * 60)
        print("âœ¨ åŠŸèƒ½ç‰¹æ€§ï¼š")
        print("â€¢ æ¯é›†å¤šä¸ªç²¾å½©çŸ­è§†é¢‘ï¼ŒAIæ™ºèƒ½åˆ¤æ–­å†…å®¹")
        print("â€¢ å®é™…å‰ªè¾‘ç”Ÿæˆè§†é¢‘æ–‡ä»¶")
        print("â€¢ æ ‡å‡†ç›®å½•ç»“æ„ï¼švideos/ + srt/")
        print("â€¢ è‡ªåŠ¨ç”Ÿæˆä¸“ä¸šæ—ç™½è§£è¯´")
        print("â€¢ å®Œæ•´å‰§æƒ…è¿è´¯æ€§ä¿è¯")
        print("=" * 60)

    def load_ai_config(self) -> Dict:
        """åŠ è½½AIé…ç½®"""
        try:
            with open('.ai_config.json', 'r', encoding='utf-8') as f:
                config = json.load(f)
                if config.get('enabled', False) and config.get('api_key'):
                    print(f"âœ… AIé…ç½®å·²åŠ è½½: {config.get('model', 'æœªçŸ¥æ¨¡å‹')}")
                    return config
        except:
            pass
        
        print("âš ï¸ AIæœªé…ç½®ï¼Œå°†ä½¿ç”¨åŸºç¡€è§„åˆ™åˆ†æ")
        return {'enabled': False}

    def parse_subtitle_file(self, filepath: str) -> List[Dict]:
        """æ™ºèƒ½è§£æå­—å¹•æ–‡ä»¶"""
        print(f"ğŸ“– è§£æå­—å¹•: {os.path.basename(filepath)}")
        
        # å°è¯•å¤šç§ç¼–ç 
        content = None
        for encoding in ['utf-8', 'gbk', 'utf-16', 'gb2312']:
            try:
                with open(filepath, 'r', encoding=encoding, errors='ignore') as f:
                    content = f.read()
                    break
            except:
                continue
        
        if not content:
            print("âŒ å­—å¹•æ–‡ä»¶è¯»å–å¤±è´¥")
            return []
        
        # æ™ºèƒ½é”™åˆ«å­—ä¿®æ­£
        corrections = {
            'é˜²è¡›': 'é˜²å«', 'æ­£ç•¶': 'æ­£å½“', 'è¨¼æ“š': 'è¯æ®', 'æª¢å¯Ÿå®˜': 'æ£€å¯Ÿå®˜',
            'å¯©åˆ¤': 'å®¡åˆ¤', 'è¾¯è­·': 'è¾©æŠ¤', 'èµ·è¨´': 'èµ·è¯‰', 'èª¿æŸ¥': 'è°ƒæŸ¥'
        }
        
        for old, new in corrections.items():
            content = content.replace(old, new)
        
        # è§£æå­—å¹•æ¡ç›®
        subtitles = []
        
        # æ”¯æŒSRTæ ¼å¼
        if '-->' in content:
            blocks = re.split(r'\n\s*\n', content.strip())
            for block in blocks:
                lines = block.strip().split('\n')
                if len(lines) >= 3:
                    try:
                        index = int(lines[0]) if lines[0].isdigit() else len(subtitles) + 1
                        time_match = re.search(r'(\d{2}:\d{2}:\d{2}[,\.]\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2}[,\.]\d{3})', lines[1])
                        if time_match:
                            start_time = time_match.group(1).replace('.', ',')
                            end_time = time_match.group(2).replace('.', ',')
                            text = '\n'.join(lines[2:]).strip()
                            
                            if text:
                                subtitles.append({
                                    'index': index,
                                    'start': start_time,
                                    'end': end_time,
                                    'text': text,
                                    'start_seconds': self._time_to_seconds(start_time),
                                    'end_seconds': self._time_to_seconds(end_time)
                                })
                    except:
                        continue
        
        print(f"âœ… è§£æå®Œæˆ: {len(subtitles)} æ¡å­—å¹•")
        return subtitles

    def ai_analyze_episode(self, subtitles: List[Dict], episode_name: str) -> Optional[Dict]:
        """AIåˆ†æä¸€é›†ï¼Œç”Ÿæˆå¤šä¸ªç²¾å½©ç‰‡æ®µ"""
        if not self.ai_config.get('enabled', False):
            print("âš ï¸ AIæœªå¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ")
            return self.basic_analysis_fallback(subtitles, episode_name)
        
        # æ£€æŸ¥ç¼“å­˜
        cache_path = self._get_cache_path(episode_name, subtitles)
        cached_analysis = self._load_cache(cache_path)
        if cached_analysis:
            print(f"ğŸ“‚ ä½¿ç”¨ç¼“å­˜åˆ†æ: {episode_name}")
            return cached_analysis
        
        episode_num = self._extract_episode_number(episode_name)
        
        # æ„å»ºå®Œæ•´å‰§æƒ…æ–‡æœ¬
        full_script = self._build_full_script(subtitles)
        
        # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
        context_info = self._build_context(episode_num)
        
        # AIåˆ†ææç¤ºè¯
        prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§å‰§æƒ…åˆ†æå¸ˆã€‚è¯·åˆ†æè¿™ä¸€é›†å¹¶ä¸ºçŸ­è§†é¢‘å‰ªè¾‘æä¾›å»ºè®®ã€‚

ã€å½“å‰é›†æ•°ã€‘ç¬¬{episode_num}é›†
ã€å‰§é›†ä¸Šä¸‹æ–‡ã€‘{context_info}

ã€å®Œæ•´å‰§æƒ…å†…å®¹ã€‘
{full_script}

è¯·åˆ†æè¿™ä¸€é›†å¹¶ç”Ÿæˆå¤šä¸ªç²¾å½©çŸ­è§†é¢‘ç‰‡æ®µï¼Œæ¯ä¸ªç‰‡æ®µ1-3åˆ†é’Ÿã€‚

è¦æ±‚ï¼š
1. æ¯ä¸ªç‰‡æ®µè¦æœ‰å®Œæ•´çš„å‰§æƒ…ç»“æ„ï¼ˆå¼€å§‹-å‘å±•-é«˜æ½®-ç»“å°¾ï¼‰
2. é€‰æ‹©æœ€å…·å¸å¼•åŠ›å’Œä»£è¡¨æ€§çš„å†…å®¹
3. ä¿è¯ç‰‡æ®µä¹‹é—´çš„è¿è´¯æ€§
4. æ¯ä¸ªç‰‡æ®µéƒ½è¦èƒ½ç‹¬ç«‹æˆç¯‡ï¼ŒåŒæ—¶èå…¥æ•´ä½“æ•…äº‹

è¯·è¿”å›JSONæ ¼å¼ï¼š
{{
    "episode_analysis": {{
        "episode_number": "{episode_num}",
        "drama_genre": "è‡ªåŠ¨è¯†åˆ«çš„å‰§æƒ…ç±»å‹",
        "main_theme": "æœ¬é›†ä¸»è¦ä¸»é¢˜",
        "key_characters": ["ä¸»è¦è§’è‰²åˆ—è¡¨"],
        "story_significance": "åœ¨æ•´ä¸ªå‰§é›†ä¸­çš„é‡è¦æ€§"
    }},
    "highlight_segments": [
        {{
            "segment_id": 1,
            "title": "ç‰‡æ®µæ ‡é¢˜",
            "start_time": "HH:MM:SS,mmm",
            "end_time": "HH:MM:SS,mmm",
            "duration_seconds": å®é™…ç§’æ•°,
            "segment_type": "å‰§æƒ…ç±»å‹(å†²çª/æƒ…æ„Ÿ/æ‚¬ç–‘/è½¬æŠ˜ç­‰)",
            "selection_reason": "é€‰æ‹©è¿™ä¸ªç‰‡æ®µçš„åŸå› ",
            "story_completeness": "å‰§æƒ…å®Œæ•´æ€§è¯´æ˜",
            "key_dialogues": [
                {{"timestamp": "HH:MM:SS,mmm", "speaker": "è§’è‰²", "line": "é‡è¦å°è¯", "significance": "å°è¯é‡è¦æ€§"}}
            ],
            "emotional_arc": "æƒ…æ„Ÿå‘å±•è½¨è¿¹",
            "visual_highlights": "è§†è§‰äº®ç‚¹",
            "audience_hook": "å¸å¼•è§‚ä¼—çš„è¦ç‚¹"
        }}
    ],
    "episode_continuity": {{
        "previous_connection": "ä¸å‰é›†çš„è”ç³»",
        "next_episode_setup": "ä¸ºä¸‹é›†çš„é“ºå«",
        "story_threads": ["æŒç»­çš„æ•…äº‹çº¿ç´¢"]
    }},
    "narration_suggestions": {{
        "overall_tone": "æ•´ä½“æ—ç™½é£æ ¼",
        "key_points_to_explain": ["éœ€è¦è§£é‡Šçš„å…³é”®ç‚¹"],
        "emotional_guidance": "æƒ…æ„Ÿå¼•å¯¼å»ºè®®"
    }}
}}

åˆ†æåŸåˆ™ï¼š
- ä¼˜å…ˆé€‰æ‹©æˆå‰§å†²çªå¼ºçƒˆçš„ç‰‡æ®µ
- ç¡®ä¿æ¯ä¸ªç‰‡æ®µæœ‰å®Œæ•´çš„æ•…äº‹å¼§çº¿
- é‡è§†è§’è‰²å‘å±•å’Œæƒ…æ„Ÿå˜åŒ–
- è€ƒè™‘è§†è§‰æ•ˆæœå’Œå¯¹è¯è´¨é‡
- ä¿æŒä¸æ•´ä½“å‰§æƒ…çš„è¿è´¯æ€§"""

        try:
            print(f"ğŸ¤– AIæ·±åº¦åˆ†æä¸­...")
            response = self._call_ai_api(prompt)
            
            if response:
                analysis = self._parse_ai_response(response)
                if analysis and self._validate_analysis(analysis, subtitles):
                    # ä¿å­˜ç¼“å­˜
                    self._save_cache(cache_path, analysis)
                    
                    # æ›´æ–°å‰§é›†ä¸Šä¸‹æ–‡
                    self._update_series_context(analysis, episode_name)
                    
                    return analysis
            
            print("âš ï¸ AIåˆ†æå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ")
            return self.basic_analysis_fallback(subtitles, episode_name)
            
        except Exception as e:
            print(f"âŒ AIåˆ†æå‡ºé”™: {e}")
            return self.basic_analysis_fallback(subtitles, episode_name)

    def basic_analysis_fallback(self, subtitles: List[Dict], episode_name: str) -> Dict:
        """åŸºç¡€åˆ†æå¤‡é€‰æ–¹æ¡ˆ"""
        episode_num = self._extract_episode_number(episode_name)
        
        # æ™ºèƒ½ç‰‡æ®µè¯†åˆ«
        segments = self._identify_segments(subtitles)
        
        return {
            "episode_analysis": {
                "episode_number": episode_num,
                "drama_genre": "é€šç”¨å‰§æƒ…",
                "main_theme": f"ç¬¬{episode_num}é›†æ ¸å¿ƒå‰§æƒ…",
                "key_characters": ["ä¸»è¦è§’è‰²"],
                "story_significance": "é‡è¦å‰§æƒ…å‘å±•"
            },
            "highlight_segments": segments,
            "episode_continuity": {
                "previous_connection": "ä¸å‰é›†çš„è‡ªç„¶å»¶ç»­",
                "next_episode_setup": "ä¸ºä¸‹é›†å‰§æƒ…å‘å±•é“ºå«",
                "story_threads": ["ä¸»çº¿å‰§æƒ…"]
            },
            "narration_suggestions": {
                "overall_tone": "ä¸“ä¸šè§£è¯´",
                "key_points_to_explain": ["æ ¸å¿ƒå‰§æƒ…", "è§’è‰²å…³ç³»"],
                "emotional_guidance": "æƒ…æ„Ÿå…±é¸£å¼•å¯¼"
            }
        }

    def _identify_segments(self, subtitles: List[Dict]) -> List[Dict]:
        """æ™ºèƒ½è¯†åˆ«ç²¾å½©ç‰‡æ®µ"""
        segments = []
        
        # å…³é”®è¯è¯„åˆ†
        keywords = {
            'å†²çª': ['äº‰è®º', 'åµæ¶', 'æ‰“æ–—', 'å¯¹æŠ—', 'å†²çª', 'çŸ›ç›¾'],
            'æƒ…æ„Ÿ': ['çˆ±', 'æ¨', 'æƒ…', 'å¿ƒ', 'æ„ŸåŠ¨', 'ç—›è‹¦'],
            'æ‚¬ç–‘': ['çœŸç›¸', 'ç§˜å¯†', 'å‘ç°', 'çº¿ç´¢', 'è°ƒæŸ¥'],
            'è½¬æŠ˜': ['çªç„¶', 'æ²¡æƒ³åˆ°', 'åŸæ¥', 'ç«Ÿç„¶', 'åè½¬']
        }
        
        # è¯„åˆ†æ¯ä¸ªå­—å¹•
        scored_subtitles = []
        for i, subtitle in enumerate(subtitles):
            score = 0
            text = subtitle['text']
            
            # å…³é”®è¯è¯„åˆ†
            for category, words in keywords.items():
                for word in words:
                    if word in text:
                        score += 2
            
            # æƒ…æ„Ÿå¼ºåº¦è¯„åˆ†
            score += text.count('ï¼') * 1.5
            score += text.count('ï¼Ÿ') * 1
            
            if score > 3:
                scored_subtitles.append((i, score, subtitle))
        
        # èšç±»æˆç‰‡æ®µ
        if scored_subtitles:
            scored_subtitles.sort(key=lambda x: x[1], reverse=True)
            
            # é€‰æ‹©å‰3ä¸ªé«˜åˆ†åŒºåŸŸ
            for i, (center_idx, score, center_sub) in enumerate(scored_subtitles[:3]):
                # æ‰©å±•åˆ°åˆé€‚é•¿åº¦
                start_idx = max(0, center_idx - 20)
                end_idx = min(len(subtitles) - 1, center_idx + 20)
                
                # ç¡®ä¿æœ€å°‘60ç§’
                while end_idx < len(subtitles) - 1:
                    duration = subtitles[end_idx]['end_seconds'] - subtitles[start_idx]['start_seconds']
                    if duration >= 60:
                        break
                    end_idx += 1
                
                duration = subtitles[end_idx]['end_seconds'] - subtitles[start_idx]['start_seconds']
                
                segments.append({
                    "segment_id": i + 1,
                    "title": f"ç²¾å½©ç‰‡æ®µ{i + 1}",
                    "start_time": subtitles[start_idx]['start'],
                    "end_time": subtitles[end_idx]['end'],
                    "duration_seconds": duration,
                    "segment_type": "æ ¸å¿ƒå‰§æƒ…",
                    "selection_reason": f"åŸºäºå…³é”®è¯è¯„åˆ†({score:.1f})é€‰æ‹©",
                    "story_completeness": "åŒ…å«å®Œæ•´å¯¹è¯å’Œæƒ…èŠ‚å‘å±•",
                    "key_dialogues": [
                        {"timestamp": center_sub['start'], "speaker": "è§’è‰²", "line": center_sub['text'][:50], "significance": "æ ¸å¿ƒå¯¹è¯"}
                    ],
                    "emotional_arc": "æƒ…æ„Ÿå‘å±•",
                    "visual_highlights": "ç²¾å½©ç”»é¢",
                    "audience_hook": "å¸å¼•è§‚ä¼—çš„å…³é”®å†…å®¹"
                })
        
        return segments

    def create_episode_clips(self, analysis: Dict, video_file: str, episode_name: str) -> List[str]:
        """ä¸ºä¸€é›†åˆ›å»ºå¤šä¸ªçŸ­è§†é¢‘"""
        created_clips = []
        
        episode_num = analysis['episode_analysis']['episode_number']
        segments = analysis['highlight_segments']
        
        print(f"\nğŸ¬ å¼€å§‹å‰ªè¾‘ç¬¬{episode_num}é›†")
        print(f"ğŸ“ æºè§†é¢‘: {os.path.basename(video_file)}")
        print(f"ğŸ“Š è®¡åˆ’åˆ›å»º {len(segments)} ä¸ªç‰‡æ®µ")
        
        for segment in segments:
            clip_file = self._create_single_clip(segment, video_file, episode_num, analysis)
            if clip_file:
                created_clips.append(clip_file)
                
                # ç”Ÿæˆæ—ç™½æ–‡ä»¶
                self._generate_narration_file(segment, clip_file, analysis)
        
        print(f"âœ… ç¬¬{episode_num}é›†å®Œæˆï¼Œåˆ›å»ºäº† {len(created_clips)} ä¸ªçŸ­è§†é¢‘")
        return created_clips

    def _create_single_clip(self, segment: Dict, video_file: str, episode_num: str, analysis: Dict) -> Optional[str]:
        """åˆ›å»ºå•ä¸ªçŸ­è§†é¢‘ç‰‡æ®µ"""
        try:
            segment_id = segment['segment_id']
            title = segment['title']
            start_time = segment['start_time']
            end_time = segment['end_time']
            
            # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
            safe_title = re.sub(r'[^\w\u4e00-\u9fff\-_]', '_', title)
            output_name = f"E{episode_num}_{segment_id:02d}_{safe_title}.mp4"
            output_path = os.path.join(self.output_folder, output_name)
            
            print(f"  ğŸ¬ åˆ›å»ºç‰‡æ®µ{segment_id}: {title}")
            print(f"  â±ï¸ æ—¶é—´: {start_time} --> {end_time}")
            print(f"  ğŸ“ æ—¶é•¿: {segment['duration_seconds']:.1f}ç§’")
            
            # è½¬æ¢æ—¶é—´ä¸ºç§’
            start_seconds = self._time_to_seconds(start_time)
            end_seconds = self._time_to_seconds(end_time)
            duration = end_seconds - start_seconds
            
            # æ·»åŠ ç¼“å†²æ—¶é—´ç¡®ä¿å®Œæ•´æ€§
            buffer_start = max(0, start_seconds - 1)
            buffer_duration = duration + 2
            
            # FFmpegå‰ªè¾‘å‘½ä»¤
            cmd = [
                'ffmpeg',
                '-i', video_file,
                '-ss', str(buffer_start),
                '-t', str(buffer_duration),
                '-c:v', 'libx264',
                '-c:a', 'aac',
                '-preset', 'medium',
                '-crf', '23',
                '-movflags', '+faststart',
                '-avoid_negative_ts', 'make_zero',
                output_path,
                '-y'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0 and os.path.exists(output_path):
                file_size = os.path.getsize(output_path) / (1024*1024)
                print(f"    âœ… åˆ›å»ºæˆåŠŸ: {output_name} ({file_size:.1f}MB)")
                
                # æ·»åŠ ä¸“ä¸šæ ‡é¢˜
                self._add_title_overlay(output_path, segment, analysis)
                
                # ç”Ÿæˆè¯¦ç»†è¯´æ˜æ–‡ä»¶
                self._create_clip_description(output_path, segment, analysis, episode_num)
                
                return output_path
            else:
                error_msg = result.stderr[:200] if result.stderr else "æœªçŸ¥é”™è¯¯"
                print(f"    âŒ å‰ªè¾‘å¤±è´¥: {error_msg}")
                return None
                
        except Exception as e:
            print(f"âŒ åˆ›å»ºç‰‡æ®µå‡ºé”™: {e}")
            return None

    def _generate_narration_file(self, segment: Dict, clip_file: str, analysis: Dict):
        """ç”Ÿæˆæ—ç™½è§£è¯´æ–‡ä»¶"""
        try:
            narration_path = clip_file.replace('.mp4', '_æ—ç™½.txt')
            
            # åŸºäºAIåˆ†æç”Ÿæˆä¸“ä¸šæ—ç™½
            narration_data = analysis.get('narration_suggestions', {})
            
            # æ„å»ºæ—ç™½å†…å®¹
            opening = f"æ¥ä¸‹æ¥æˆ‘ä»¬çœ‹åˆ°çš„æ˜¯{segment['title']}ã€‚"
            
            process = f"{segment['selection_reason']}ï¼Œ"
            if segment.get('emotional_arc'):
                process += f"è¿™ä¸ªç‰‡æ®µå±•ç°äº†{segment['emotional_arc']}ã€‚"
            
            highlight = f"æœ€ç²¾å½©çš„éƒ¨åˆ†æ˜¯{segment.get('audience_hook', 'å‰§æƒ…é«˜æ½®')}ï¼Œ"
            if segment.get('key_dialogues'):
                key_dialogue = segment['key_dialogues'][0]
                highlight += f"ç‰¹åˆ«æ˜¯è¿™å¥è¯ï¼š'{key_dialogue['line']}'ã€‚"
            
            ending = f"è¿™ä¸ªç‰‡æ®µ{segment.get('story_completeness', 'å±•ç°äº†å®Œæ•´çš„æ•…äº‹å‘å±•')}ã€‚"
            
            full_narration = f"{opening} {process} {highlight} {ending}"
            
            # ç”Ÿæˆæ—ç™½æ–‡ä»¶
            content = f"""ğŸ™ï¸ çŸ­è§†é¢‘æ—ç™½è§£è¯´
{"=" * 50}

ğŸ“º ç‰‡æ®µä¿¡æ¯:
â€¢ æ ‡é¢˜: {segment['title']}
â€¢ æ—¶é•¿: {segment['duration_seconds']:.1f} ç§’
â€¢ ç±»å‹: {segment['segment_type']}

ğŸ¯ æ—ç™½å†…å®¹:

ã€å¼€åœºç™½ (0-3ç§’)ã€‘
{opening}

ã€è¿‡ç¨‹è§£è¯´ (3-8ç§’)ã€‘
{process}

ã€äº®ç‚¹å¼ºè°ƒ (8-11ç§’)ã€‘
{highlight}

ã€ç»“å°¾æ€»ç»“ (11-12ç§’)ã€‘
{ending}

ã€å®Œæ•´æ—ç™½ã€‘
{full_narration}

ğŸ¨ è§£è¯´è¦ç‚¹:
â€¢ æ•´ä½“é£æ ¼: {narration_data.get('overall_tone', 'ä¸“ä¸šè§£è¯´')}
â€¢ æƒ…æ„Ÿå¼•å¯¼: {narration_data.get('emotional_guidance', 'å¼•èµ·è§‚ä¼—å…±é¸£')}
â€¢ å…³é”®ç‚¹: {', '.join(narration_data.get('key_points_to_explain', ['å‰§æƒ…å‘å±•']))}

ğŸ“ ä½¿ç”¨è¯´æ˜:
â€¢ å¯é…åˆAIè¯­éŸ³åˆæˆå·¥å…·ç”ŸæˆéŸ³é¢‘
â€¢ å»ºè®®è¯­é€Ÿ: æ¯åˆ†é’Ÿ160-180å­—
â€¢ è¯­è°ƒ: æ ¹æ®ç‰‡æ®µæƒ…æ„Ÿè°ƒæ•´
â€¢ åœé¡¿: åœ¨å…³é”®ä¿¡æ¯åé€‚å½“åœé¡¿

ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
            
            with open(narration_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            print(f"    ğŸ™ï¸ æ—ç™½æ–‡ä»¶: {os.path.basename(narration_path)}")
            
        except Exception as e:
            print(f"    âš ï¸ æ—ç™½ç”Ÿæˆå¤±è´¥: {e}")

    def find_matching_video(self, episode_name: str) -> Optional[str]:
        """æ™ºèƒ½åŒ¹é…è§†é¢‘æ–‡ä»¶"""
        if not os.path.exists(self.video_folder):
            return None
        
        base_name = os.path.splitext(episode_name)[0]
        video_extensions = ['.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv', '.ts']
        
        # ç²¾ç¡®åŒ¹é…
        for ext in video_extensions:
            video_path = os.path.join(self.video_folder, base_name + ext)
            if os.path.exists(video_path):
                return video_path
        
        # æå–é›†æ•°æ¨¡ç³ŠåŒ¹é…
        episode_patterns = [r'[Ee](\d+)', r'EP(\d+)', r'ç¬¬(\d+)é›†', r'S\d+E(\d+)']
        episode_num = None
        
        for pattern in episode_patterns:
            match = re.search(pattern, base_name, re.I)
            if match:
                episode_num = match.group(1)
                break
        
        if episode_num:
            for filename in os.listdir(self.video_folder):
                if any(filename.lower().endswith(ext) for ext in video_extensions):
                    for pattern in episode_patterns:
                        match = re.search(pattern, filename, re.I)
                        if match and match.group(1).zfill(2) == episode_num.zfill(2):
                            return os.path.join(self.video_folder, filename)
        
        return None

    def process_all_episodes(self):
        """å¤„ç†æ‰€æœ‰é›†æ•°"""
        print("\nğŸš€ å¼€å§‹å®Œæ•´æ™ºèƒ½å‰ªè¾‘")
        print("=" * 60)
        
        # è·å–å­—å¹•æ–‡ä»¶
        srt_files = []
        for filename in os.listdir(self.srt_folder):
            if filename.lower().endswith(('.srt', '.txt')) and not filename.startswith('.'):
                srt_files.append(filename)
        
        if not srt_files:
            print(f"âŒ {self.srt_folder}/ ç›®å½•ä¸­æœªæ‰¾åˆ°å­—å¹•æ–‡ä»¶")
            return
        
        srt_files.sort()
        print(f"ğŸ“„ æ‰¾åˆ° {len(srt_files)} ä¸ªå­—å¹•æ–‡ä»¶")
        
        # æ£€æŸ¥è§†é¢‘ç›®å½•
        video_files = []
        if os.path.exists(self.video_folder):
            video_files = [f for f in os.listdir(self.video_folder) 
                          if f.lower().endswith(('.mp4', '.mkv', '.avi', '.mov', '.wmv'))]
        
        if not video_files:
            print(f"âŒ {self.video_folder}/ ç›®å½•ä¸­æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
            return
        
        print(f"ğŸ¬ æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
        
        total_clips = 0
        all_episodes = []
        
        for srt_file in srt_files:
            try:
                print(f"\nğŸ“º å¤„ç†: {srt_file}")
                
                # è§£æå­—å¹•
                srt_path = os.path.join(self.srt_folder, srt_file)
                subtitles = self.parse_subtitle_file(srt_path)
                
                if not subtitles:
                    print(f"âŒ å­—å¹•è§£æå¤±è´¥")
                    continue
                
                # AIåˆ†æ
                analysis = self.ai_analyze_episode(subtitles, srt_file)
                
                if not analysis:
                    print(f"âŒ åˆ†æå¤±è´¥")
                    continue
                
                # å¯»æ‰¾å¯¹åº”è§†é¢‘
                video_file = self.find_matching_video(srt_file)
                
                if not video_file:
                    print(f"âš ï¸ æœªæ‰¾åˆ°å¯¹åº”è§†é¢‘æ–‡ä»¶")
                    continue
                
                # åˆ›å»ºå¤šä¸ªçŸ­è§†é¢‘
                episode_clips = self.create_episode_clips(analysis, video_file, srt_file)
                
                if episode_clips:
                    total_clips += len(episode_clips)
                    all_episodes.append({
                        'file': srt_file,
                        'analysis': analysis,
                        'clips': episode_clips
                    })
                    print(f"âœ… {srt_file} å¤„ç†å®Œæˆï¼Œåˆ›å»º {len(episode_clips)} ä¸ªçŸ­è§†é¢‘")
                else:
                    print(f"âŒ {srt_file} å‰ªè¾‘å¤±è´¥")
                    
            except Exception as e:
                print(f"âŒ å¤„ç† {srt_file} æ—¶å‡ºé”™: {e}")
        
        # ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
        self._generate_final_report(all_episodes, total_clips, len(srt_files))

    # è¾…åŠ©æ–¹æ³•
    def _call_ai_api(self, prompt: str) -> Optional[str]:
        """è°ƒç”¨AI API"""
        try:
            import requests
            
            headers = {
                'Authorization': f'Bearer {self.ai_config["api_key"]}',
                'Content-Type': 'application/json'
            }
            
            data = {
                'model': self.ai_config.get('model', 'gpt-3.5-turbo'),
                'messages': [
                    {'role': 'system', 'content': 'ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§å‰§æƒ…åˆ†æå¸ˆï¼Œæ“…é•¿è¯†åˆ«ç²¾å½©ç‰‡æ®µã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚'},
                    {'role': 'user', 'content': prompt}
                ],
                'max_tokens': 3000,
                'temperature': 0.7
            }
            
            base_url = self.ai_config.get('base_url', 'https://api.openai.com/v1')
            response = requests.post(
                f"{base_url}/chat/completions",
                headers=headers,
                json=data,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result.get('choices', [{}])[0].get('message', {}).get('content', '')
                return content
            else:
                print(f"APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"APIè°ƒç”¨å¼‚å¸¸: {e}")
            return None

    def _parse_ai_response(self, response: str) -> Optional[Dict]:
        """è§£æAIå“åº”"""
        try:
            if "```json" in response:
                start = response.find("```json") + 7
                end = response.find("```", start)
                json_str = response[start:end].strip()
            else:
                start = response.find("{")
                end = response.rfind("}") + 1
                if start >= 0 and end > start:
                    json_str = response[start:end]
                else:
                    json_str = response.strip()
            
            analysis = json.loads(json_str)
            return analysis
            
        except json.JSONDecodeError as e:
            print(f"JSONè§£æé”™è¯¯: {e}")
            return None

    def _validate_analysis(self, analysis: Dict, subtitles: List[Dict]) -> bool:
        """éªŒè¯åˆ†æç»“æœ"""
        try:
            if 'highlight_segments' not in analysis:
                return False
            
            segments = analysis['highlight_segments']
            if not segments:
                return False
            
            # éªŒè¯æ¯ä¸ªç‰‡æ®µ
            subtitle_start = min(sub['start_seconds'] for sub in subtitles)
            subtitle_end = max(sub['end_seconds'] for sub in subtitles)
            
            for segment in segments:
                if not all(key in segment for key in ['start_time', 'end_time', 'title']):
                    return False
                
                start_seconds = self._time_to_seconds(segment['start_time'])
                end_seconds = self._time_to_seconds(segment['end_time'])
                
                if start_seconds >= end_seconds:
                    return False
                
                # ä¿®æ­£è¶…å‡ºèŒƒå›´çš„æ—¶é—´
                if start_seconds < subtitle_start or end_seconds > subtitle_end:
                    closest_start = min(subtitles, key=lambda s: abs(s['start_seconds'] - start_seconds))
                    closest_end = min(subtitles, key=lambda s: abs(s['end_seconds'] - end_seconds))
                    
                    segment['start_time'] = closest_start['start']
                    segment['end_time'] = closest_end['end']
                    segment['duration_seconds'] = closest_end['end_seconds'] - closest_start['start_seconds']
            
            return True
            
        except Exception as e:
            print(f"éªŒè¯åˆ†æç»“æœå‡ºé”™: {e}")
            return False

    def _time_to_seconds(self, time_str: str) -> float:
        """æ—¶é—´è½¬æ¢ä¸ºç§’"""
        try:
            time_str = time_str.replace(',', '.')
            parts = time_str.split(':')
            if len(parts) == 3:
                h, m, s = parts
                return int(h) * 3600 + int(m) * 60 + float(s)
            return 0.0
        except:
            return 0.0

    def _extract_episode_number(self, filename: str) -> str:
        """æå–é›†æ•°"""
        patterns = [r'[Ee](\d+)', r'EP(\d+)', r'ç¬¬(\d+)é›†', r'S\d+E(\d+)', r'(\d+)']
        for pattern in patterns:
            match = re.search(pattern, filename, re.I)
            if match:
                return match.group(1).zfill(2)
        return "01"

    def _build_full_script(self, subtitles: List[Dict]) -> str:
        """æ„å»ºå®Œæ•´å‰§æƒ…æ–‡æœ¬"""
        scenes = []
        current_scene = []
        last_time = 0
        
        for subtitle in subtitles:
            if subtitle['start_seconds'] - last_time > 30 and current_scene:
                scene_text = '\n'.join([sub['text'] for sub in current_scene])
                scenes.append(f"[{current_scene[0]['start']} - {current_scene[-1]['end']}]\n{scene_text}")
                current_scene = []
            
            current_scene.append(subtitle)
            last_time = subtitle['end_seconds']
        
        if current_scene:
            scene_text = '\n'.join([sub['text'] for sub in current_scene])
            scenes.append(f"[{current_scene[0]['start']} - {current_scene[-1]['end']}]\n{scene_text}")
        
        return '\n\n=== åœºæ™¯åˆ†å‰² ===\n\n'.join(scenes)

    def _build_context(self, current_episode: str) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯"""
        if not self.series_context:
            return "è¿™æ˜¯å‰§é›†åˆ†æçš„å¼€å§‹ï¼Œæš‚æ— å‰é›†ä¸Šä¸‹æ–‡ã€‚"
        
        context_parts = []
        context_parts.append("ã€å‰é›†å‰§æƒ…å›é¡¾ã€‘")
        
        for prev_ep in self.series_context[-2:]:  # æœ€è¿‘2é›†
            context_parts.append(f"â€¢ {prev_ep['episode']}: {prev_ep.get('main_theme', 'æœªçŸ¥')}")
        
        return '\n'.join(context_parts)

    def _update_series_context(self, analysis: Dict, episode_name: str):
        """æ›´æ–°å‰§é›†ä¸Šä¸‹æ–‡"""
        episode_summary = {
            'episode': episode_name,
            'main_theme': analysis.get('episode_analysis', {}).get('main_theme', ''),
            'key_characters': analysis.get('episode_analysis', {}).get('key_characters', [])
        }
        
        self.series_context.append(episode_summary)
        
        # åªä¿ç•™æœ€è¿‘3é›†çš„ä¸Šä¸‹æ–‡
        if len(self.series_context) > 3:
            self.series_context = self.series_context[-3:]

    def _get_cache_path(self, episode_name: str, subtitles: List[Dict]) -> str:
        """è·å–ç¼“å­˜è·¯å¾„"""
        content_hash = hashlib.md5(str(subtitles).encode()).hexdigest()[:16]
        safe_name = re.sub(r'[^\w\-_]', '_', episode_name)
        return os.path.join(self.cache_folder, f"{safe_name}_{content_hash}.json")

    def _load_cache(self, cache_path: str) -> Optional[Dict]:
        """åŠ è½½ç¼“å­˜"""
        if os.path.exists(cache_path):
            try:
                with open(cache_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                pass
        return None

    def _save_cache(self, cache_path: str, analysis: Dict):
        """ä¿å­˜ç¼“å­˜"""
        try:
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(analysis, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")

    def _add_title_overlay(self, video_path: str, segment: Dict, analysis: Dict):
        """æ·»åŠ æ ‡é¢˜å å±‚"""
        try:
            temp_path = video_path.replace('.mp4', '_temp.mp4')
            
            title = segment['title']
            segment_type = segment.get('segment_type', '')
            
            # æ¸…ç†æ–‡æœ¬
            clean_title = title.replace("'", "").replace('"', '')[:40]
            clean_type = segment_type.replace("'", "").replace('"', '')[:20]
            
            # æ·»åŠ æ ‡é¢˜æ»¤é•œ
            filter_text = (
                f"drawtext=text='{clean_title}':fontsize=24:fontcolor=white:"
                f"x=(w-text_w)/2:y=50:box=1:boxcolor=black@0.7:boxborderw=5:"
                f"enable='between(t,0,3)',"
                f"drawtext=text='{clean_type}':fontsize=18:fontcolor=yellow:"
                f"x=(w-text_w)/2:y=90:box=1:boxcolor=black@0.6:boxborderw=4:"
                f"enable='between(t,1,3)'"
            )
            
            cmd = [
                'ffmpeg',
                '-i', video_path,
                '-vf', filter_text,
                '-c:a', 'copy',
                '-c:v', 'libx264',
                '-preset', 'fast',
                temp_path,
                '-y'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
            
            if result.returncode == 0:
                os.replace(temp_path, video_path)
                print(f"    âœ“ æ·»åŠ æ ‡é¢˜å®Œæˆ")
            else:
                if os.path.exists(temp_path):
                    os.remove(temp_path)
                
        except Exception as e:
            print(f"    âš  æ·»åŠ æ ‡é¢˜å¤±è´¥: {e}")

    def _create_clip_description(self, video_path: str, segment: Dict, analysis: Dict, episode_num: str):
        """åˆ›å»ºç‰‡æ®µè¯´æ˜æ–‡ä»¶"""
        try:
            desc_path = video_path.replace('.mp4', '_è¯´æ˜.txt')
            
            content = f"""ğŸ“º {segment['title']}
{"=" * 60}

ğŸ“Š åŸºæœ¬ä¿¡æ¯:
â€¢ é›†æ•°: ç¬¬{episode_num}é›†
â€¢ ç‰‡æ®µ: {segment['segment_id']}/{len(analysis['highlight_segments'])}
â€¢ æ—¶é—´: {segment['start_time']} --> {segment['end_time']}
â€¢ æ—¶é•¿: {segment['duration_seconds']:.1f} ç§’
â€¢ ç±»å‹: {segment['segment_type']}

ğŸ¯ é€‰æ‹©ç†ç”±:
{segment['selection_reason']}

ğŸ“ æ•…äº‹å®Œæ•´æ€§:
{segment['story_completeness']}

ğŸ’« æƒ…æ„Ÿå¼§çº¿:
{segment.get('emotional_arc', 'æƒ…æ„Ÿå‘å±•è½¨è¿¹')}

ğŸ¬ è§†è§‰äº®ç‚¹:
{segment.get('visual_highlights', 'ç²¾å½©ç”»é¢')}

ğŸ¯ è§‚ä¼—å¸å¼•ç‚¹:
{segment.get('audience_hook', 'æ ¸å¿ƒå¸å¼•å†…å®¹')}

ğŸ—£ï¸ é‡è¦å¯¹è¯:
"""
            
            for dialogue in segment.get('key_dialogues', []):
                content += f"[{dialogue['timestamp']}] {dialogue['speaker']}: {dialogue['line']}\n"
                content += f"é‡è¦æ€§: {dialogue['significance']}\n\n"
            
            content += f"""
ğŸ”— å‰§é›†è¿è´¯æ€§:
â€¢ å‰é›†è”ç³»: {analysis.get('episode_continuity', {}).get('previous_connection', 'è‡ªç„¶å»¶ç»­')}
â€¢ ä¸‹é›†é“ºå«: {analysis.get('episode_continuity', {}).get('next_episode_setup', 'å‰§æƒ…å‘å±•')}

ğŸ“± çŸ­è§†é¢‘ä¼˜åŒ–å»ºè®®:
â€¢ é€‚åˆå¹³å°: æŠ–éŸ³ã€å¿«æ‰‹ã€Bç«™ç­‰
â€¢ è§‚çœ‹ä½“éªŒ: ç‹¬ç«‹å®Œæ•´ï¼Œæ— éœ€å‰ç½®çŸ¥è¯†
â€¢ ä¼ æ’­ä»·å€¼: é«˜è´¨é‡å‰§æƒ…å†…å®¹ï¼Œæ˜“å¼•èµ·å…±é¸£

ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
            
            with open(desc_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            print(f"    ğŸ“„ è¯´æ˜æ–‡ä»¶: {os.path.basename(desc_path)}")
            
        except Exception as e:
            print(f"    âš ï¸ è¯´æ˜æ–‡ä»¶ç”Ÿæˆå¤±è´¥: {e}")

    def _generate_final_report(self, all_episodes: List[Dict], total_clips: int, total_episodes: int):
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        if not all_episodes:
            return
        
        report_path = os.path.join(self.output_folder, "å®Œæ•´å‰ªè¾‘æŠ¥å‘Š.txt")
        
        content = f"""ğŸ¤– å®Œæ•´AIæ™ºèƒ½å‰ªè¾‘æŠ¥å‘Š
{"=" * 80}

ğŸ“Š æ•´ä½“ç»Ÿè®¡:
â€¢ å¤„ç†é›†æ•°: {len(all_episodes)}/{total_episodes} é›†
â€¢ æˆåŠŸç‡: {(len(all_episodes)/total_episodes*100):.1f}%
â€¢ åˆ›å»ºçŸ­è§†é¢‘: {total_clips} ä¸ª
â€¢ AIåˆ†æ: {'å¯ç”¨' if self.ai_config.get('enabled') else 'åŸºç¡€è§„åˆ™'}

ğŸ“º æ¯é›†è¯¦æƒ…:
"""
        
        total_duration = 0
        
        for i, episode in enumerate(all_episodes, 1):
            analysis = episode['analysis']
            clips = episode['clips']
            
            episode_num = analysis['episode_analysis']['episode_number']
            drama_genre = analysis['episode_analysis'].get('drama_genre', 'é€šç”¨å‰§æƒ…')
            segments = analysis['highlight_segments']
            
            episode_duration = sum(seg['duration_seconds'] for seg in segments)
            total_duration += episode_duration
            
            content += f"""
{i}. ç¬¬{episode_num}é›† - {drama_genre}
   åŸæ–‡ä»¶: {episode['file']}
   ç‰‡æ®µæ•°: {len(segments)} ä¸ª
   æ€»æ—¶é•¿: {episode_duration:.1f} ç§’ ({episode_duration/60:.1f} åˆ†é’Ÿ)
   è§†é¢‘æ–‡ä»¶: {len(clips)} ä¸ª
   
   ç‰‡æ®µè¯¦æƒ…:
"""
            for seg in segments:
                content += f"   â€¢ {seg['title']} ({seg['duration_seconds']:.1f}s) - {seg['segment_type']}\n"
        
        avg_clips_per_episode = total_clips / len(all_episodes) if all_episodes else 0
        avg_duration = total_duration / total_clips if total_clips else 0
        
        content += f"""
ğŸ“ˆ è´¨é‡åˆ†æ:
â€¢ å¹³å‡æ¯é›†ç‰‡æ®µæ•°: {avg_clips_per_episode:.1f} ä¸ª
â€¢ å¹³å‡ç‰‡æ®µæ—¶é•¿: {avg_duration:.1f} ç§’ ({avg_duration/60:.1f} åˆ†é’Ÿ)
â€¢ æ€»å‰ªè¾‘æ—¶é•¿: {total_duration:.1f} ç§’ ({total_duration/60:.1f} åˆ†é’Ÿ)

ğŸ“ è¾“å‡ºæ–‡ä»¶ç»“æ„:
{self.output_folder}/
â”œâ”€â”€ E01_01_ç‰‡æ®µæ ‡é¢˜.mp4          # è§†é¢‘æ–‡ä»¶
â”œâ”€â”€ E01_01_ç‰‡æ®µæ ‡é¢˜_è¯´æ˜.txt      # è¯¦ç»†è¯´æ˜
â”œâ”€â”€ E01_01_ç‰‡æ®µæ ‡é¢˜_æ—ç™½.txt      # æ—ç™½è§£è¯´
â””â”€â”€ ...

ğŸ’¡ ä½¿ç”¨å»ºè®®:
â€¢ æ‰€æœ‰çŸ­è§†é¢‘éƒ½æœ‰ç‹¬ç«‹çš„æ—ç™½è§£è¯´æ–‡ä»¶
â€¢ è¯´æ˜æ–‡ä»¶åŒ…å«è¯¦ç»†çš„å‰§æƒ…åˆ†æå’Œåˆ¶ä½œä¿¡æ¯
â€¢ å»ºè®®æŒ‰é›†æ•°é¡ºåºå‘å¸ƒï¼Œä¿æŒå‰§æƒ…è¿è´¯æ€§
â€¢ å¯æ ¹æ®å¹³å°ç‰¹ç‚¹é€‰æ‹©åˆé€‚çš„ç‰‡æ®µç±»å‹å‘å¸ƒ

ğŸ¯ æˆåŠŸç‰¹ç‚¹:
â€¢ âœ… æ¯é›†å¤šä¸ªç²¾å½©çŸ­è§†é¢‘ï¼ŒAIæ™ºèƒ½åˆ¤æ–­å†…å®¹
â€¢ âœ… å®é™…å‰ªè¾‘ç”Ÿæˆå®Œæ•´è§†é¢‘æ–‡ä»¶
â€¢ âœ… è§„èŒƒçš„videos/å’Œsrt/ç›®å½•ç»“æ„
â€¢ âœ… ä¸“ä¸šæ—ç™½è§£è¯´æ–‡ä»¶
â€¢ âœ… è·¨é›†å‰§æƒ…è¿è´¯æ€§ä¿è¯

ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ç³»ç»Ÿç‰ˆæœ¬: å®Œæ•´AIæ™ºèƒ½å‰ªè¾‘ç³»ç»Ÿ v2.0
"""
        
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"\nğŸ“„ å®Œæ•´å‰ªè¾‘æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        except Exception as e:
            print(f"âš ï¸ æŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    clipper = CompleteAIClipper()
    
    print("\nè¯·é€‰æ‹©æ“ä½œ:")
    print("1. ğŸš€ å¼€å§‹å®Œæ•´æ™ºèƒ½å‰ªè¾‘")
    print("2. âš™ï¸ é…ç½®AIè®¾ç½®")
    print("3. ğŸ“ æ£€æŸ¥æ–‡ä»¶çŠ¶æ€")
    print("4. âŒ é€€å‡º")
    
    while True:
        try:
            choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-4): ").strip()
            
            if choice == '1':
                clipper.process_all_episodes()
                break
            elif choice == '2':
                configure_ai()
            elif choice == '3':
                check_file_status(clipper)
            elif choice == '4':
                print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼")
                break
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­")
            break
        except Exception as e:
            print(f"âŒ æ“ä½œé”™è¯¯: {e}")


def configure_ai():
    """é…ç½®AIè®¾ç½®"""
    print("\nâš™ï¸ AIé…ç½®è®¾ç½®")
    print("=" * 40)
    
    config = {
        'enabled': True,
        'base_url': input("APIåœ°å€ (é»˜è®¤: https://api.openai.com/v1): ").strip() or "https://api.openai.com/v1",
        'api_key': input("APIå¯†é’¥: ").strip(),
        'model': input("æ¨¡å‹åç§° (é»˜è®¤: gpt-3.5-turbo): ").strip() or "gpt-3.5-turbo"
    }
    
    if config['api_key']:
        try:
            with open('.ai_config.json', 'w', encoding='utf-8') as f:
                json.dump(config, f, ensure_ascii=False, indent=2)
            print("âœ… AIé…ç½®ä¿å­˜æˆåŠŸ")
        except Exception as e:
            print(f"âŒ é…ç½®ä¿å­˜å¤±è´¥: {e}")
    else:
        print("âŒ APIå¯†é’¥ä¸èƒ½ä¸ºç©º")


def check_file_status(clipper):
    """æ£€æŸ¥æ–‡ä»¶çŠ¶æ€"""
    print("\nğŸ“ æ–‡ä»¶çŠ¶æ€æ£€æŸ¥")
    print("=" * 40)
    
    # æ£€æŸ¥å­—å¹•æ–‡ä»¶
    srt_count = 0
    if os.path.exists(clipper.srt_folder):
        srt_files = [f for f in os.listdir(clipper.srt_folder) 
                    if f.lower().endswith(('.srt', '.txt'))]
        srt_count = len(srt_files)
        print(f"ğŸ“„ å­—å¹•æ–‡ä»¶: {srt_count} ä¸ª")
        for f in srt_files[:3]:
            print(f"  â€¢ {f}")
        if srt_count > 3:
            print(f"  ... ç­‰å…± {srt_count} ä¸ª")
    else:
        print(f"âŒ å­—å¹•ç›®å½•ä¸å­˜åœ¨: {clipper.srt_folder}/")
    
    # æ£€æŸ¥è§†é¢‘æ–‡ä»¶
    video_count = 0
    if os.path.exists(clipper.video_folder):
        video_files = [f for f in os.listdir(clipper.video_folder) 
                      if f.lower().endswith(('.mp4', '.mkv', '.avi', '.mov', '.wmv'))]
        video_count = len(video_files)
        print(f"ğŸ¬ è§†é¢‘æ–‡ä»¶: {video_count} ä¸ª")
        for f in video_files[:3]:
            print(f"  â€¢ {f}")
        if video_count > 3:
            print(f"  ... ç­‰å…± {video_count} ä¸ª")
    else:
        print(f"âŒ è§†é¢‘ç›®å½•ä¸å­˜åœ¨: {clipper.video_folder}/")
    
    print(f"\nçŠ¶æ€æ€»ç»“:")
    print(f"â€¢ å‡†å¤‡å°±ç»ª: {'âœ…' if srt_count > 0 and video_count > 0 else 'âŒ'}")
    print(f"â€¢ AIé…ç½®: {'âœ…' if os.path.exists('.ai_config.json') else 'âŒ'}")


if __name__ == "__main__":
    main()
