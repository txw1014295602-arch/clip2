#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç”µå½±å­—å¹•AIåˆ†æå‰ªè¾‘ç³»ç»Ÿ
ä¸“é—¨ç”¨äºï¼š
1. AIåˆ†æç”µå½±å­—å¹•æ–‡ä»¶
2. æ™ºèƒ½è¯†åˆ«ç²¾å½©ç‰‡æ®µå’Œå‰§æƒ…ç‚¹
3. ç”Ÿæˆç¬¬ä¸€äººç§°å™è¿°å­—å¹•
4. è¾“å‡ºå®Œæ•´å‰ªè¾‘æ–¹æ¡ˆ
"""

import os
import re
import json
import requests
import hashlib
from typing import List, Dict, Optional
from datetime import datetime
import subprocess
import time

class MovieAIClipper:
    def __init__(self):
        # åˆ›å»ºå¿…è¦ç›®å½•
        self.srt_folder = "movie_srt"
        self.output_folder = "movie_clips"
        self.analysis_folder = "movie_analysis"
        self.cache_folder = "ai_cache"

        for folder in [self.srt_folder, self.output_folder, self.analysis_folder, self.cache_folder]:
            os.makedirs(folder, exist_ok=True)

        # åŠ è½½AIé…ç½®
        self.ai_config = self.load_ai_config()

        # å‰§æƒ…ç‚¹ç±»å‹å®šä¹‰
        self.plot_types = {
            'å…³é”®å†²çª': {
                'keywords': ['å†²çª', 'äº‰æ‰§', 'å¯¹æŠ—', 'æˆ˜æ–—', 'çŸ›ç›¾', 'äº‰è®º', 'æ•Œå¯¹', 'åæŠ—', 'å¯¹ç«‹'],
                'weight': 10,
                'target_duration': 180
            },
            'äººç‰©è½¬æŠ˜': {
                'keywords': ['å†³å®š', 'æ”¹å˜', 'é€‰æ‹©', 'è½¬å˜', 'è§‰æ‚Ÿ', 'æ˜ç™½', 'æ„è¯†åˆ°', 'æˆé•¿', 'èœ•å˜'],
                'weight': 9,
                'target_duration': 150
            },
            'çº¿ç´¢æ­éœ²': {
                'keywords': ['å‘ç°', 'æ­éœ²', 'çœŸç›¸', 'ç§˜å¯†', 'çº¿ç´¢', 'è¯æ®', 'æš´éœ²', 'æ­å¼€', 'æŸ¥æ˜'],
                'weight': 8,
                'target_duration': 160
            },
            'æƒ…æ„Ÿé«˜æ½®': {
                'keywords': ['çˆ±æƒ…', 'å‹æƒ…', 'äº²æƒ…', 'èƒŒå›', 'ç‰ºç‰²', 'æ•‘èµ', 'æ„ŸåŠ¨', 'å¿ƒç—›', 'æ¸©æš–'],
                'weight': 7,
                'target_duration': 140
            },
            'åŠ¨ä½œåœºé¢': {
                'keywords': ['è¿½é€', 'æ‰“æ–—', 'é€ƒè·‘', 'è¥æ•‘', 'çˆ†ç‚¸', 'æªæˆ˜', 'é£è½¦', 'ç‰¹æŠ€', 'å±é™©'],
                'weight': 6,
                'target_duration': 120
            }
        }

        print("ğŸ¬ ç”µå½±å­—å¹•AIåˆ†æå‰ªè¾‘ç³»ç»Ÿå·²å¯åŠ¨")
        print(f"ğŸ“ å­—å¹•ç›®å½•: {self.srt_folder}/")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_folder}/")
        print(f"ğŸ¤– AIçŠ¶æ€: {'å·²å¯ç”¨' if self.ai_config.get('enabled') else 'æœªé…ç½®'}")

    def load_ai_config(self) -> Dict:
        """åŠ è½½AIé…ç½®"""
        try:
            with open('.ai_config.json', 'r', encoding='utf-8') as f:
                config = json.load(f)
                if config.get('enabled', False) and config.get('api_key'):
                    return config
        except:
            pass

        print("âš ï¸ AIæœªé…ç½®ï¼Œè¯·å…ˆé…ç½®AI API")
        return {'enabled': False}

    def parse_srt_file(self, filepath: str) -> List[Dict]:
        """è§£æSRTå­—å¹•æ–‡ä»¶å¹¶ä¿®æ­£é”™è¯¯"""
        print(f"ğŸ“– è§£æå­—å¹•æ–‡ä»¶: {os.path.basename(filepath)}")

        try:
            # å°è¯•å¤šç§ç¼–ç 
            content = None
            for encoding in ['utf-8', 'gbk', 'utf-16', 'gb2312']:
                try:
                    with open(filepath, 'r', encoding=encoding, errors='ignore') as f:
                        content = f.read()
                    break
                except:
                    continue

            if not content:
                raise Exception("æ— æ³•è¯»å–æ–‡ä»¶")

            # æ™ºèƒ½é”™è¯¯ä¿®æ­£
            content = self.fix_subtitle_errors(content)

            # è§£æå­—å¹•æ¡ç›®
            subtitles = []
            blocks = re.split(r'\n\s*\n', content.strip())

            for block in blocks:
                lines = block.strip().split('\n')
                if len(lines) >= 3:
                    try:
                        index = int(lines[0])
                        time_match = re.match(r'(\d{2}:\d{2}:\d{2}[,\.]\d{3}) --> (\d{2}:\d{2}:\d{2}[,\.]\d{3})', lines[1])

                        if time_match:
                            start_time = time_match.group(1).replace('.', ',')
                            end_time = time_match.group(2).replace('.', ',')
                            text = '\n'.join(lines[2:]).strip()

                            if text:
                                subtitles.append({
                                    'index': index,
                                    'start_time': start_time,
                                    'end_time': end_time,
                                    'text': text,
                                    'duration': self.time_to_seconds(end_time) - self.time_to_seconds(start_time)
                                })
                    except (ValueError, IndexError):
                        continue

            print(f"âœ… æˆåŠŸè§£æ {len(subtitles)} æ¡å­—å¹•")
            return subtitles

        except Exception as e:
            print(f"âŒ è§£æå¤±è´¥: {e}")
            return []

    def fix_subtitle_errors(self, content: str) -> str:
        """æ™ºèƒ½ä¿®æ­£å­—å¹•é”™è¯¯"""
        # å¸¸è§é”™è¯¯ä¿®æ­£è¯å…¸ - ä¸“é—¨ä¿®æ­£ç¹ä½“å­—å’Œé”™åˆ«å­—
        corrections = {
            # ç¹ä½“å­—ä¿®æ­£
            'é˜²è¡›': 'é˜²å«',
            'æ­£ç•¶': 'æ­£å½“', 
            'è¨¼æ“š': 'è¯æ®',
            'æª¢å¯Ÿå®˜': 'æ£€å¯Ÿå®˜',
            'å¯©åˆ¤': 'å®¡åˆ¤',
            'è¾¯è­·': 'è¾©æŠ¤',
            'èµ·è¨´': 'èµ·è¯‰',
            'èª¿æŸ¥': 'è°ƒæŸ¥',
            'ç™¼ç¾': 'å‘ç°',
            'æ±ºå®š': 'å†³å®š',
            'é¸æ“‡': 'é€‰æ‹©',
            'å•é¡Œ': 'é—®é¢˜',
            'æ©Ÿæœƒ': 'æœºä¼š',
            'é–‹å§‹': 'å¼€å§‹',
            'çµæŸ': 'ç»“æŸ',
            'è¨¼äºº': 'è¯äºº',
            'è¨¼è¨€': 'è¯è¨€',
            'å¯¦ç¾': 'å®ç°',
            'å¯¾è©±': 'å¯¹è¯',
            'é–¢ä¿‚': 'å…³ç³»',
            'å®Ÿéš›': 'å®é™…',
            'å¤‰åŒ–': 'å˜åŒ–',

            # æ ‡ç‚¹ç¬¦å·ä¿®æ­£
            'ã€‚ã€‚ã€‚': '...',
            'ï¼ï¼': 'ï¼',
            'ï¼Ÿï¼Ÿ': 'ï¼Ÿ',

            # å¸¸è§é”™åˆ«å­—
            'çš„è¯': 'çš„è¯',
            'è¿™æ ·': 'è¿™æ ·',
            'é‚£æ ·': 'é‚£æ ·',
            'ä»€ä¹ˆ': 'ä»€ä¹ˆ',
            'æ€ä¹ˆ': 'æ€ä¹ˆ',
            'ä¸ºä»€ä¹ˆ': 'ä¸ºä»€ä¹ˆ',

            # è¯­æ°”è¯ä¿®æ­£
            'å•Šå•Š': 'å•Š',
            'å‘ƒå‘ƒ': 'å‘ƒ',
            'å—¯å—¯': 'å—¯',

            # ç©ºæ ¼ä¿®æ­£
            ' ï¼Œ': 'ï¼Œ',
            ' ã€‚': 'ã€‚',
            ' ï¼': 'ï¼',
            ' ï¼Ÿ': 'ï¼Ÿ',
        }

        for old, new in corrections.items():
            content = content.replace(old, new)

        return content

    def ai_analyze_movie(self, subtitles: List[Dict], movie_title: str = "") -> Dict:
        """AIå…¨é¢åˆ†æç”µå½±å†…å®¹ - å¢å¼ºç‰ˆï¼Œè§£å†³APIç¨³å®šæ€§é—®é¢˜"""
        if not self.ai_config.get('enabled'):
            print("âŒ AIæœªå¯ç”¨ï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
            return {}

        # ç”Ÿæˆæ›´ç¨³å®šçš„ç¼“å­˜é”® - é—®é¢˜10ï¼šåŸºäºç”µå½±æ ‡é¢˜å’Œå†…å®¹å“ˆå¸Œ
        content_for_hash = f"{movie_title}_{len(subtitles)}"
        if subtitles:
            content_for_hash += f"_{subtitles[0]['text'][:50]}_{subtitles[-1]['text'][:50]}"
        cache_key = hashlib.md5(content_for_hash.encode()).hexdigest()[:16]
        cache_path = os.path.join(self.cache_folder, f"analysis_{movie_title}_{cache_key}.json")

        # é—®é¢˜10ï¼šæ£€æŸ¥å·²ä¿å­˜çš„AIåˆ†æç»“æœ
        if os.path.exists(cache_path):
            try:
                with open(cache_path, 'r', encoding='utf-8') as f:
                    cached_analysis = json.load(f)
                    # éªŒè¯ç¼“å­˜æ•°æ®å®Œæ•´æ€§
                    if (cached_analysis.get('movie_analysis') and 
                        cached_analysis.get('highlight_clips') and
                        len(cached_analysis.get('highlight_clips', [])) > 0):
                        print(f"ğŸ’¾ ä½¿ç”¨å·²ä¿å­˜çš„AIåˆ†æç»“æœ: {os.path.basename(cache_path)}")
                        print(f"ğŸ“Š ç¼“å­˜åŒ…å« {len(cached_analysis.get('highlight_clips', []))} ä¸ªç‰‡æ®µåˆ†æ")
                        return cached_analysis
                    else:
                        print("âš ï¸ ç¼“å­˜æ•°æ®ä¸å®Œæ•´ï¼Œé‡æ–°åˆ†æ")
            except Exception as e:
                print(f"âš ï¸ ç¼“å­˜è¯»å–å¤±è´¥: {e}")

        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä¸´æ—¶åˆ†ææ–‡ä»¶ï¼ˆé˜²æ­¢APIè°ƒç”¨ä¸­æ–­ï¼‰
        temp_cache_path = cache_path.replace('.json', '_temp.json')
        if os.path.exists(temp_cache_path):
            try:
                with open(temp_cache_path, 'r', encoding='utf-8') as f:
                    temp_analysis = json.load(f)
                    if temp_analysis.get('status') == 'completed':
                        # å°†ä¸´æ—¶æ–‡ä»¶è½¬ä¸ºæ­£å¼ç¼“å­˜
                        os.rename(temp_cache_path, cache_path)
                        print("ğŸ’¾ æ¢å¤è¢«ä¸­æ–­çš„AIåˆ†æç»“æœ")
                        return temp_analysis.get('analysis', {})

            except Exception as e:
                print(f"âš ï¸ ç¼“å­˜è¯»å–å¤±è´¥: {e}")

        print("ğŸ¤– AIæ­£åœ¨åˆ†æç”µå½±å†…å®¹...")

        # æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡
        full_content = self.build_movie_context(subtitles)

        prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„ç”µå½±åˆ†æå¸ˆå’Œå‰ªè¾‘å¸ˆï¼Œéœ€è¦å¯¹è¿™éƒ¨ç”µå½±è¿›è¡Œå…¨é¢åˆ†æå¹¶åˆ¶å®šå‰ªè¾‘æ–¹æ¡ˆã€‚

ã€ç”µå½±æ ‡é¢˜ã€‘{movie_title}

ã€å®Œæ•´å­—å¹•å†…å®¹ã€‘
{full_content}

è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

1. ç”µå½±åŸºæœ¬åˆ†æï¼š
   - ç”µå½±ç±»å‹ï¼ˆåŠ¨ä½œã€çˆ±æƒ…ã€æ‚¬ç–‘ã€ç§‘å¹»ã€å–œå‰§ç­‰ï¼‰
   - ä¸»è¦è§’è‰²è¯†åˆ«
   - æ ¸å¿ƒä¸»é¢˜
   - æ•…äº‹ç»“æ„åˆ†æ

2. ç²¾å½©ç‰‡æ®µè¯†åˆ«ï¼š
   æ‰¾å‡º5-8ä¸ªæœ€ç²¾å½©çš„ç‰‡æ®µï¼Œæ¯ä¸ª2-3åˆ†é’Ÿï¼Œè¦æ±‚ï¼š
   - åŒ…å«å®Œæ•´çš„æ•…äº‹æƒ…èŠ‚
   - æœ‰æ˜ç¡®çš„æˆå‰§å†²çªæˆ–æƒ…æ„Ÿé«˜æ½®
   - èƒ½ç‹¬ç«‹æˆä¸ºä¸€ä¸ªçŸ­è§†é¢‘
   - æ¶µç›–ä¸åŒç±»å‹çš„å‰§æƒ…ç‚¹

3. å‰§æƒ…ç‚¹åˆ†ç±»ï¼š
   å°†æ¯ä¸ªç‰‡æ®µæŒ‰ä»¥ä¸‹ç±»å‹åˆ†ç±»ï¼š
   - å…³é”®å†²çªï¼šä¸»è¦çŸ›ç›¾å’Œå¯¹æŠ—åœºé¢
   - äººç‰©è½¬æŠ˜ï¼šè§’è‰²æˆé•¿å’Œè½¬å˜æ—¶åˆ»
   - çº¿ç´¢æ­éœ²ï¼šé‡è¦ä¿¡æ¯å’ŒçœŸç›¸æ­ç¤º
   - æƒ…æ„Ÿé«˜æ½®ï¼šæ„Ÿäººæˆ–éœ‡æ’¼çš„æƒ…æ„Ÿåœºé¢
   - åŠ¨ä½œåœºé¢ï¼šæ¿€çƒˆçš„åŠ¨ä½œå’Œè¿½é€æˆ

4. ç¬¬ä¸€äººç§°å™è¿°ç”Ÿæˆï¼š
   ä¸ºæ¯ä¸ªç‰‡æ®µç”Ÿæˆè¯¦ç»†çš„ç¬¬ä¸€äººç§°å™è¿°ï¼Œè¦æ±‚ï¼š
   - ä»¥"æˆ‘"çš„è§†è§’æè¿°æ­£åœ¨å‘ç”Ÿçš„äº‹æƒ…
   - è¯¦ç»†è§£é‡Šå‰§æƒ…å‘å±•å’Œäººç‰©åŠ¨æœº
   - è¯­è¨€ç”ŸåŠ¨æœ‰è¶£ï¼Œå¸å¼•è§‚ä¼—
   - æ—¶é•¿æ§åˆ¶åœ¨ç‰‡æ®µæ—¶é—´å†…

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
{{
    "movie_analysis": {{
        "title": "{movie_title}",
        "genre": "ç”µå½±ç±»å‹",
        "main_characters": ["ä¸»è¦è§’è‰²1", "ä¸»è¦è§’è‰²2"],
        "core_theme": "æ ¸å¿ƒä¸»é¢˜",
        "story_structure": "æ•…äº‹ç»“æ„åˆ†æ",
        "total_duration": "æ€»æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰"
    }},
    "highlight_clips": [
        {{
            "clip_id": 1,
            "title": "ç‰‡æ®µæ ‡é¢˜",
            "plot_type": "å‰§æƒ…ç‚¹ç±»å‹",
            "start_time": "å¼€å§‹æ—¶é—´",
            "end_time": "ç»“æŸæ—¶é—´",
            "duration_seconds": æŒç»­ç§’æ•°,
            "story_summary": "å‰§æƒ…æ‘˜è¦",
            "dramatic_value": "æˆå‰§ä»·å€¼ï¼ˆ1-10åˆ†ï¼‰",
            "first_person_narration": {{
                "opening": "å¼€åœºç¬¬ä¸€äººç§°å™è¿°",
                "development": "å‘å±•è¿‡ç¨‹å™è¿°",
                "climax": "é«˜æ½®éƒ¨åˆ†å™è¿°",
                "conclusion": "ç»“å°¾å™è¿°",
                "full_narration": "å®Œæ•´ç¬¬ä¸€äººç§°å™è¿°"
            }},
            "key_moments": ["å…³é”®æ—¶åˆ»1", "å…³é”®æ—¶åˆ»2"],
            "emotional_impact": "æƒ…æ„Ÿå†²å‡»æè¿°",
            "connection_reason": "é€‰æ‹©æ­¤ç‰‡æ®µçš„åŸå› "
        }}
    ],
    "storyline_summary": "å®Œæ•´æ•…äº‹çº¿æ€»ç»“",
    "editing_notes": "å‰ªè¾‘åˆ¶ä½œè¯´æ˜"
}}"""

        # åˆ›å»ºä¸´æ—¶åˆ†ææ–‡ä»¶ï¼Œæ ‡è®°åˆ†æå¼€å§‹
        temp_cache_path = cache_path.replace('.json', '_temp.json')
        temp_data = {
            'status': 'analyzing',
            'movie_title': movie_title,
            'start_time': datetime.now().isoformat(),
            'cache_key': cache_key
        }

        try:
            with open(temp_cache_path, 'w', encoding='utf-8') as f:
                json.dump(temp_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ æ— æ³•åˆ›å»ºä¸´æ—¶æ–‡ä»¶: {e}")

        # é—®é¢˜10ï¼šå¢å¼ºçš„APIè°ƒç”¨é‡è¯•æœºåˆ¶
        max_retries = 3
        for attempt in range(max_retries):
            try:
                print(f"ğŸ¤– AIåˆ†æä¸­... (å°è¯• {attempt + 1}/{max_retries})")
                response = self.call_ai_api(prompt)

                if response:
                    analysis = self.parse_ai_response(response)
                    if analysis and analysis.get('highlight_clips'):
                        # é—®é¢˜10ï¼šç«‹å³ä¿å­˜æˆåŠŸçš„åˆ†æç»“æœ
                        analysis['analysis_metadata'] = {
                            'movie_title': movie_title,
                            'analysis_time': datetime.now().isoformat(),
                            'cache_key': cache_key,
                            'subtitle_count': len(subtitles),
                            'api_attempt': attempt + 1
                        }

                        # ä¿å­˜åˆ°æ­£å¼ç¼“å­˜æ–‡ä»¶
                        with open(cache_path, 'w', encoding='utf-8') as f:
                            json.dump(analysis, f, ensure_ascii=False, indent=2)

                        # æ›´æ–°ä¸´æ—¶æ–‡ä»¶çŠ¶æ€
                        temp_data.update({
                            'status': 'completed',
                            'analysis': analysis,
                            'completion_time': datetime.now().isoformat()
                        })

                        with open(temp_cache_path, 'w', encoding='utf-8') as f:
                            json.dump(temp_data, f, ensure_ascii=False, indent=2)

                        print(f"âœ… AIåˆ†æå®Œæˆå¹¶ä¿å­˜: {len(analysis.get('highlight_clips', []))} ä¸ªç‰‡æ®µ")
                        print(f"ğŸ’¾ åˆ†æç»“æœå·²ç¼“å­˜: {os.path.basename(cache_path)}")
                        return analysis
                    else:
                        print(f"âš ï¸ å°è¯• {attempt + 1} - AIå“åº”è§£æå¤±è´¥")
                else:
                    print(f"âš ï¸ å°è¯• {attempt + 1} - AIå“åº”ä¸ºç©º")

                # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…åé‡è¯•
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 2  # é€’å¢ç­‰å¾…æ—¶é—´
                    print(f"â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)

            except Exception as e:
                print(f"âŒ å°è¯• {attempt + 1} å‡ºé”™: {e}")
                if attempt < max_retries - 1:
                    time.sleep(2)

        # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥
        temp_data.update({
            'status': 'failed',
            'failure_time': datetime.now().isoformat(),
            'error': 'All API attempts failed'
        })

        try:
            with open(temp_cache_path, 'w', encoding='utf-8') as f:
                json.dump(temp_data, f, ensure_ascii=False, indent=2)
        except:
            pass

        print("âŒ AIåˆ†æå½»åº•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIé…ç½®")
        return {}

    def build_movie_context(self, subtitles: List[Dict]) -> str:
        """æ„å»ºç”µå½±å®Œæ•´ä¸Šä¸‹æ–‡"""
        # å–å…³é”®éƒ¨åˆ†å†…å®¹ï¼Œé¿å…è¶…å‡ºAPIé™åˆ¶
        total_subs = len(subtitles)

        # å–å¼€å¤´ã€ä¸­é—´ã€ç»“å°¾çš„é‡è¦å†…å®¹
        key_parts = []

        # å¼€å¤´ï¼ˆå‰15%ï¼‰
        start_end = int(total_subs * 0.15)
        start_content = ' '.join([sub['text'] for sub in subtitles[:start_end]])
        key_parts.append(f"ã€å¼€å¤´éƒ¨åˆ†ã€‘\n{start_content}")

        # ä¸­é—´å…³é”®éƒ¨åˆ†ï¼ˆ35%-65%ï¼‰
        middle_start = int(total_subs * 0.35)
        middle_end = int(total_subs * 0.65)
        middle_content = ' '.join([sub['text'] for sub in subtitles[middle_start:middle_end]])
        key_parts.append(f"ã€ä¸­é—´éƒ¨åˆ†ã€‘\n{middle_content}")

        # ç»“å°¾ï¼ˆå15%ï¼‰
        end_start = int(total_subs * 0.85)
        end_content = ' '.join([sub['text'] for sub in subtitles[end_start:]])
        key_parts.append(f"ã€ç»“å°¾éƒ¨åˆ†ã€‘\n{end_content}")

        return '\n\n'.join(key_parts)

    def call_ai_api(self, prompt: str) -> Optional[str]:
        """è°ƒç”¨AI API"""
        try:
            config = self.ai_config

            headers = {
                'Authorization': f'Bearer {config["api_key"]}',
                'Content-Type': 'application/json'
            }

            data = {
                'model': config.get('model', 'gpt-3.5-turbo'),
                'messages': [
                    {
                        'role': 'system',
                        'content': 'ä½ æ˜¯ä¸“ä¸šçš„ç”µå½±åˆ†æå¸ˆå’Œå‰ªè¾‘å¸ˆï¼Œæ“…é•¿è¯†åˆ«ç²¾å½©ç‰‡æ®µå’Œç”Ÿæˆç¬¬ä¸€äººç§°å™è¿°ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚'
                    },
                    {'role': 'user', 'content': prompt}
                ],
                'max_tokens': 4000,
                'temperature': 0.7
            }

            url = config.get('base_url', 'https://api.openai.com/v1') + '/chat/completions'

            response = requests.post(url, headers=headers, json=data, timeout=60)

            if response.status_code == 200:
                result = response.json()
                return result.get('choices', [{}])[0].get('message', {}).get('content', '')
            else:
                print(f"âš ï¸ APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                return None

        except Exception as e:
            print(f"âš ï¸ APIè°ƒç”¨å¼‚å¸¸: {e}")
            return None

    def parse_ai_response(self, response_text: str) -> Optional[Dict]:
        """è§£æAIå“åº”"""
        try:
            # æå–JSON
            if "```json" in response_text:
                json_start = response_text.find("```json") + 7
                json_end = response_text.find("```", json_start)
                response_text = response_text[json_start:json_end]
            elif "{" in response_text:
                json_start = response_text.find("{")
                json_end = response_text.rfind("}") + 1
                response_text = response_text[json_start:json_end]

            analysis = json.loads(response_text)

            # éªŒè¯å¿…è¦å­—æ®µ
            if 'highlight_clips' in analysis and 'movie_analysis' in analysis:
                return analysis
            else:
                print("âš ï¸ AIåˆ†æç»“æœç¼ºå°‘å¿…è¦å­—æ®µ")
                return None

        except json.JSONDecodeError as e:
            print(f"âš ï¸ AIåˆ†æç»“æœJSONè§£æå¤±è´¥: {e}")
            return None

    def create_video_clips(self, analysis: Dict, movie_title: str) -> List[str]:
        """åˆ›å»ºè§†é¢‘ç‰‡æ®µ - æ— å£°è§†é¢‘ï¼Œé…ç¬¬ä¸€äººç§°å™è¿°"""
        if not analysis:
            print("âŒ AIåˆ†æå¤±è´¥ï¼Œæ— æ³•åˆ›å»ºè§†é¢‘ç‰‡æ®µ")
            return []

        # æŸ¥æ‰¾å¯¹åº”çš„è§†é¢‘æ–‡ä»¶
        video_file = self.find_movie_video_file(movie_title)
        if not video_file:
            print(f"âŒ æœªæ‰¾åˆ°å¯¹åº”çš„è§†é¢‘æ–‡ä»¶: {movie_title}")
            return []

        clips = analysis.get('highlight_clips', [])
        created_clips = []

        for i, clip in enumerate(clips, 1):
            clip_filename = f"{movie_title}_ç‰‡æ®µ{i:02d}_{clip.get('plot_type', 'ç²¾å½©ç‰‡æ®µ')}.mp4"
            clip_path = os.path.join(self.output_folder, clip_filename)

            if self.create_single_video_clip(video_file, clip, clip_path):
                created_clips.append(clip_path)
                # ç”Ÿæˆç¬¬ä¸€äººç§°å™è¿°å­—å¹•æ–‡ä»¶
                self.create_narration_subtitle(clip, clip_path)

        return created_clips

    def find_movie_video_file(self, movie_title: str) -> Optional[str]:
        """æŸ¥æ‰¾å¯¹åº”çš„ç”µå½±è§†é¢‘æ–‡ä»¶"""
        video_folder = "movie_videos"
        os.makedirs(video_folder, exist_ok=True)

        if not os.path.exists(video_folder):
            return None

        video_extensions = ['.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv']

        # ç²¾ç¡®åŒ¹é…
        for ext in video_extensions:
            video_path = os.path.join(video_folder, movie_title + ext)
            if os.path.exists(video_path):
                return video_path

        # æ¨¡ç³ŠåŒ¹é…
        for filename in os.listdir(video_folder):
            if any(filename.lower().endswith(ext) for ext in video_extensions):
                if movie_title.lower() in filename.lower() or filename.lower() in movie_title.lower():
                    return os.path.join(video_folder, filename)

        return None

    def create_single_video_clip(self, video_file: str, clip: Dict, output_path: str) -> bool:
        """åˆ›å»ºå•ä¸ªè§†é¢‘ç‰‡æ®µ - é—®é¢˜11ï¼šä¿è¯å‰ªè¾‘ä¸€è‡´æ€§ï¼Œé—®é¢˜9ï¼šæ”¯æŒç¬¬ä¸€äººç§°å™è¿°åŒæ­¥"""

        # é—®é¢˜11ï¼šç”Ÿæˆä¸€è‡´æ€§æ ¡éªŒç 
        clip_hash = hashlib.md5(str(clip).encode()).hexdigest()[:12]
        consistency_file = output_path.replace('.mp4', f'_consistency_{clip_hash}.json')

        # æ£€æŸ¥æ˜¯å¦å·²æœ‰ä¸€è‡´çš„å‰ªè¾‘ç»“æœ
        if os.path.exists(output_path) and os.path.exists(consistency_file):
            try:
                with open(consistency_file, 'r', encoding='utf-8') as f:
                    consistency_data = json.load(f)

                if (consistency_data.get('clip_hash') == clip_hash and
                    consistency_data.get('video_file') == os.path.basename(video_file) and
                    os.path.getsize(output_path) > 1024):

                    file_size = os.path.getsize(output_path) / (1024*1024)
                    print(f"    âœ… ä½¿ç”¨ä¸€è‡´çš„å‰ªè¾‘ç»“æœ: {os.path.basename(output_path)} ({file_size:.1f}MB)")
                    return True
            except:
                # å¦‚æœä¸€è‡´æ€§æ–‡ä»¶æŸåï¼Œé‡æ–°å‰ªè¾‘
                pass

        try:
            start_time = clip.get('start_time', '00:00:00,000')
            end_time = clip.get('end_time', '00:00:00,000')

            start_seconds = self.time_to_seconds(start_time)
            end_seconds = self.time_to_seconds(end_time)
            duration = end_seconds - start_seconds

            if duration <= 0:
                print(f"  âŒ æ— æ•ˆæ—¶é—´æ®µ: {start_time} -> {end_time}")
                return False

            print(f"  ğŸ¬ åˆ›å»ºç‰‡æ®µ: {clip.get('title', 'æœªçŸ¥ç‰‡æ®µ')}")
            print(f"     æ—¶é—´: {start_time} --> {end_time} ({duration:.1f}ç§’)")

            # é—®é¢˜9ï¼šç²¾ç¡®çš„æ—¶é—´åŒæ­¥ï¼Œä¸æ·»åŠ ç¼“å†²æ—¶é—´ï¼Œç¡®ä¿ä¸ç¬¬ä¸€äººç§°å™è¿°å®Œç¾å¯¹åº”
            precise_start = start_seconds
            precise_duration = duration

            print(f"     ğŸ¯ ç²¾ç¡®åŒæ­¥: å¼€å§‹={precise_start:.3f}ç§’, æ—¶é•¿={precise_duration:.3f}ç§’")

            # é—®é¢˜9ï¼šç§»é™¤éŸ³é¢‘ï¼Œä¸ºç¬¬ä¸€äººç§°å™è¿°åšå‡†å¤‡ï¼Œç¡®ä¿æ—¶é—´ç²¾ç¡®åŒ¹é…
            cmd = [
                'ffmpeg',
                '-i', video_file,
                '-ss', f"{precise_start:.3f}",  # ç²¾ç¡®åˆ°æ¯«ç§’
                '-t', f"{precise_duration:.3f}",  # ç²¾ç¡®æ—¶é•¿
                '-an',  # ç§»é™¤åŸå§‹éŸ³é¢‘
                '-c:v', 'libx264',
                '-preset', 'medium',
                '-crf', '23',
                '-r', '25',  # å›ºå®šå¸§ç‡ç¡®ä¿ä¸€è‡´æ€§
                '-movflags', '+faststart',
                '-avoid_negative_ts', 'make_zero',
                '-map_metadata', '-1',  # ç§»é™¤å…ƒæ•°æ®ç¡®ä¿ä¸€è‡´æ€§
                output_path,
                '-y'
            ]

            # é—®é¢˜11ï¼šæ‰§è¡Œå‰ªè¾‘ï¼Œå¢åŠ è¶…æ—¶å’Œé”™è¯¯å¤„ç†
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300, encoding='utf-8', errors='replace')

            if result.returncode == 0 and os.path.exists(output_path) and os.path.getsize(output_path) > 1024:
                file_size = os.path.getsize(output_path) / (1024*1024)
                print(f"    âœ… åˆ›å»ºæˆåŠŸ: {os.path.basename(output_path)} ({file_size:.1f}MB, ç²¾ç¡®åŒæ­¥)")

                # é—®é¢˜11ï¼šä¿å­˜ä¸€è‡´æ€§ä¿¡æ¯
                consistency_data = {
                    'clip_hash': clip_hash,
                    'video_file': os.path.basename(video_file),
                    'start_time': start_time,
                    'end_time': end_time,
                    'duration': duration,
                    'precise_start': precise_start,
                    'precise_duration': precise_duration,
                    'file_size': os.path.getsize(output_path),
                    'creation_time': datetime.now().isoformat(),
                    'ffmpeg_success': True
                }

                with open(consistency_file, 'w', encoding='utf-8') as f:
                    json.dump(consistency_data, f, ensure_ascii=False, indent=2)

                return True
            else:
                error_msg = result.stderr[:200] if result.stderr else 'æœªçŸ¥é”™è¯¯'
                print(f"    âŒ åˆ›å»ºå¤±è´¥: {error_msg}")

                # æ¸…ç†å¤±è´¥çš„æ–‡ä»¶
                if os.path.exists(output_path):
                    os.remove(output_path)
                if os.path.exists(consistency_file):
                    os.remove(consistency_file)

                return False

        except subprocess.TimeoutExpired:
            print(f"  âŒ å‰ªè¾‘è¶…æ—¶")
            return False
        except Exception as e:
            print(f"  âŒ åˆ›å»ºè§†é¢‘ç‰‡æ®µæ—¶å‡ºé”™: {e}")
            return False

    def create_narration_subtitle(self, clip: Dict, video_path: str):
        """ä¸ºè§†é¢‘ç‰‡æ®µåˆ›å»ºç¬¬ä¸€äººç§°å™è¿°å­—å¹•æ–‡ä»¶ - é—®é¢˜9ï¼šç²¾ç¡®æ—¶é—´åŒæ­¥"""
        try:
            subtitle_path = video_path.replace('.mp4', '_ç¬¬ä¸€äººç§°å™è¿°.srt')

            # è·å–è§†é¢‘ç‰‡æ®µçš„ç²¾ç¡®æ—¶é—´ä¿¡æ¯
            start_time = clip.get('start_time', '00:00:00,000')
            end_time = clip.get('end_time', '00:00:00,000')
            duration = clip.get('duration_seconds', self.time_to_seconds(end_time) - self.time_to_seconds(start_time))

            # è·å–ç¬¬ä¸€äººç§°å™è¿°å†…å®¹
            narration = clip.get('first_person_narration', {})

            print(f"    ğŸ™ï¸ ç”Ÿæˆç¬¬ä¸€äººç§°å™è¿°å­—å¹• (æ—¶é•¿: {duration:.1f}ç§’)")

            # é—®é¢˜9ï¼šç²¾ç¡®çš„åˆ†æ®µå™è¿°ï¼Œç¡®ä¿ä¸è§†é¢‘å†…å®¹å®Œç¾åŒæ­¥
            segments = self.create_synchronized_narration_segments(narration, duration, clip)

            # ç”ŸæˆSRTæ ¼å¼å­—å¹•
            srt_content = ""
            for i, segment in enumerate(segments, 1):
                start_time = self.seconds_to_srt_time(segment['start'])
                end_time = self.seconds_to_srt_time(segment['end'])

                srt_content += f"{i}\n"
                srt_content += f"{start_time} --> {end_time}\n"
                srt_content += f"{segment['text']}\n\n"

            with open(subtitle_path, 'w', encoding='utf-8') as f:
                f.write(srt_content)

            # åˆ›å»ºè¯¦ç»†çš„å™è¿°è¯´æ˜æ–‡ä»¶
            narration_detail_path = video_path.replace('.mp4', '_å™è¿°è¯¦æƒ….txt')
            self.create_detailed_narration_file(narration_detail_path, clip, segments, duration)

            print(f"    ğŸ“ å™è¿°å­—å¹•: {os.path.basename(subtitle_path)} ({len(segments)} æ®µ)")
            print(f"    ğŸ“‹ è¯¦ç»†è¯´æ˜: {os.path.basename(narration_detail_path)}")

        except Exception as e:
            print(f"    âš ï¸ å™è¿°å­—å¹•ç”Ÿæˆå¤±è´¥: {e}")

    def create_synchronized_narration_segments(self, narration: Dict, duration: float, clip: Dict) -> List[Dict]:
        """åˆ›å»ºä¸è§†é¢‘ç²¾ç¡®åŒæ­¥çš„ç¬¬ä¸€äººç§°å™è¿°åˆ†æ®µ - é—®é¢˜9"""
        segments = []

        # è·å–å„éƒ¨åˆ†å™è¿°å†…å®¹
        opening = narration.get('opening', '').strip()
        development = narration.get('development', '').strip()
        climax = narration.get('climax', '').strip()
        conclusion = narration.get('conclusion', '').strip()
        full_narration = narration.get('full_narration', '').strip()

        # å¦‚æœæ²¡æœ‰åˆ†æ®µå™è¿°ï¼Œä½¿ç”¨å®Œæ•´å™è¿°
        if not any([opening, development, climax, conclusion]) and full_narration:
            # å°†å®Œæ•´å™è¿°æ™ºèƒ½åˆ†æ®µ
            sentences = self.smart_split_narration(full_narration)
            segment_duration = duration / max(len(sentences), 1)

            current_time = 0
            for i, sentence in enumerate(sentences):
                end_time = min(current_time + segment_duration, duration)
                segments.append({
                    'start': current_time,
                    'end': end_time,
                    'text': f"æˆ‘{sentence}",
                    'type': f'ç¬¬{i+1}æ®µå™è¿°',
                    'sync_point': 'content_match'
                })
                current_time = end_time
                if current_time >= duration:
                    break
        else:
            # é—®é¢˜9ï¼šç²¾ç¡®çš„æ—¶é—´åˆ†é…ï¼ŒåŸºäºå†…å®¹é‡è¦æ€§
            narration_parts = []
            if opening:
                narration_parts.append(('opening', opening, 0.25))  # 25%æ—¶é—´
            if development:
                narration_parts.append(('development', development, 0.40))  # 40%æ—¶é—´
            if climax:
                narration_parts.append(('climax', climax, 0.25))  # 25%æ—¶é—´
            if conclusion:
                narration_parts.append(('conclusion', conclusion, 0.10))  # 10%æ—¶é—´

            # æ ‡å‡†åŒ–æ—¶é—´æ¯”ä¾‹
            total_weight = sum(part[2] for part in narration_parts)
            if total_weight > 0:
                narration_parts = [(part[0], part[1], part[2]/total_weight) for part in narration_parts]

            current_time = 0
            for part_type, text, time_ratio in narration_parts:
                segment_duration = duration * time_ratio
                end_time = min(current_time + segment_duration, duration)

                # é—®é¢˜9ï¼šç¬¬ä¸€äººç§°è§†è§’è¡¨è¿°
                first_person_text = self.convert_to_first_person(text, part_type)

                segments.append({
                    'start': current_time,
                    'end': end_time,
                    'text': first_person_text,
                    'type': part_type,
                    'sync_point': 'precise_timing',
                    'original_ratio': time_ratio
                })

                current_time = end_time
                if current_time >= duration:
                    break

        return segments

    def smart_split_narration(self, text: str) -> List[str]:
        """æ™ºèƒ½åˆ†å‰²å™è¿°æ–‡æœ¬"""
        if not text:
            return ["æ­£åœ¨è§‚çœ‹ç²¾å½©å†…å®¹"]

        # æŒ‰å¥å·ã€æ„Ÿå¹å·ã€é—®å·åˆ†å‰²
        import re
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]', text)
        sentences = [s.strip() for s in sentences if s.strip()]

        # å¦‚æœå¥å­å¤ªå°‘ï¼ŒæŒ‰é€—å·åˆ†å‰²
        if len(sentences) < 3:
            all_parts = []
            for sentence in sentences:
                parts = re.split(r'[ï¼Œ,ã€]', sentence)
                all_parts.extend([p.strip() for p in parts if p.strip()])
            sentences = all_parts

        # ç¡®ä¿æœ‰åˆé€‚æ•°é‡çš„åˆ†æ®µï¼ˆ3-6ä¸ªï¼‰
        if len(sentences) < 3:
            # æŒ‰é•¿åº¦åˆ†å‰²
            text_length = len(text)
            if text_length > 60:
                chunk_size = text_length // 3
                sentences = [
                    text[0:chunk_size],
                    text[chunk_size:chunk_size*2],
                    text[chunk_size*2:]
                ]

        return sentences[:6]  # æœ€å¤š6æ®µ

    def convert_to_first_person(self, text: str, part_type: str) -> str:
        """è½¬æ¢ä¸ºç¬¬ä¸€äººç§°è¡¨è¿° - é—®é¢˜9"""
        first_person_prefixes = {
            'opening': 'æˆ‘çœ‹åˆ°',
            'development': 'æˆ‘æ³¨æ„åˆ°',
            'climax': 'æˆ‘æ„Ÿå—åˆ°',
            'conclusion': 'æˆ‘è®¤ä¸º'
        }

        prefix = first_person_prefixes.get(part_type, 'æˆ‘è§‚å¯Ÿåˆ°')

        # å¦‚æœæ–‡æœ¬å·²ç»æ˜¯ç¬¬ä¸€äººç§°ï¼Œç›´æ¥è¿”å›
        if text.startswith('æˆ‘') or text.startswith('æˆ‘çš„'):
            return text

        # æ·»åŠ ç¬¬ä¸€äººç§°å‰ç¼€
        return f"{prefix}ï¼š{text}"

    def create_detailed_narration_file(self, file_path: str, clip: Dict, segments: List[Dict], duration: float):
        """åˆ›å»ºè¯¦ç»†çš„å™è¿°è¯´æ˜æ–‡ä»¶"""
        try:
            content = f"""ğŸ“ ã€Š{clip.get('title', 'ç²¾å½©ç‰‡æ®µ')}ã€‹ç¬¬ä¸€äººç§°å™è¿°è¯¦æƒ…
{'=' * 80}

ğŸ¬ ç‰‡æ®µåŸºæœ¬ä¿¡æ¯ï¼š
â€¢ å‰§æƒ…ç±»å‹ï¼š{clip.get('plot_type', 'æœªçŸ¥')}
â€¢ å¼€å§‹æ—¶é—´ï¼š{clip.get('start_time', '00:00:00,000')}
â€¢ ç»“æŸæ—¶é—´ï¼š{clip.get('end_time', '00:00:00,000')}
â€¢ æ€»æ—¶é•¿ï¼š{duration:.1f} ç§’

ğŸ™ï¸ ç¬¬ä¸€äººç§°å™è¿°åˆ†æ®µï¼ˆå…±{len(segments)}æ®µï¼‰ï¼š
"""

            for i, segment in enumerate(segments, 1):
                content += f"""
æ®µè½ {i}ï¼š{segment.get('type', 'å™è¿°ç‰‡æ®µ')}
æ—¶é—´ï¼š{segment['start']:.1f}s - {segment['end']:.1f}s ({segment['end'] - segment['start']:.1f}s)
å†…å®¹ï¼š{segment['text']}
åŒæ­¥ï¼š{segment.get('sync_point', 'æ ‡å‡†åŒæ­¥')}
"""

            content += f"""

ğŸ¯ å™è¿°ç‰¹è‰²ï¼š
â€¢ âœ… å®Œå…¨ç¬¬ä¸€äººç§°è§†è§’ - "æˆ‘çœ‹åˆ°/æˆ‘æ³¨æ„åˆ°/æˆ‘æ„Ÿå—åˆ°/æˆ‘è®¤ä¸º"
â€¢ âœ… ç²¾ç¡®æ—¶é—´åŒæ­¥ - å™è¿°ä¸è§†é¢‘å†…å®¹å®æ—¶å¯¹åº”
â€¢ âœ… æ— å£°è§†é¢‘è®¾è®¡ - ä¸“ä¸ºç¬¬ä¸€äººç§°å™è¿°é…éŸ³åˆ¶ä½œ
â€¢ âœ… å†…å®¹å±‚æ¬¡åˆ†æ˜ - å¼€åœºâ†’å‘å±•â†’é«˜æ½®â†’ç»“è®º

ğŸ“‹ ä½¿ç”¨è¯´æ˜ï¼š
1. è§†é¢‘æ–‡ä»¶å·²ç§»é™¤åŸå£°ï¼Œé€‚åˆé…ç¬¬ä¸€äººç§°å™è¿°
2. å­—å¹•æ–‡ä»¶æä¾›ç²¾ç¡®çš„æ—¶é—´åŒæ­¥
3. æ¯æ®µå™è¿°éƒ½æœ‰æ˜ç¡®çš„æ—¶é—´æ ‡è®°
4. æ”¯æŒä¸“ä¸šé…éŸ³åˆ¶ä½œ

ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
åŒæ­¥ç²¾åº¦ï¼šæ¯«ç§’çº§æ—¶é—´åŒ¹é…
"""

            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)

        except Exception as e:
            print(f"âš ï¸ è¯¦ç»†å™è¿°æ–‡ä»¶åˆ›å»ºå¤±è´¥: {e}")

    def split_narration_to_segments(self, narration: Dict, total_duration: float) -> List[Dict]:
        """å°†ç¬¬ä¸€äººç§°å™è¿°åˆ†æ®µï¼Œä¸è§†é¢‘æ—¶é—´åŒæ­¥"""
        segments = []

        # è·å–å„éƒ¨åˆ†å™è¿°
        opening = narration.get('opening', '')
        development = narration.get('development', '')
        climax = narration.get('climax', '')
        conclusion = narration.get('conclusion', '')

        # åˆ†é…æ—¶é—´æ®µ
        opening_duration = total_duration * 0.2  # å¼€åœº20%
        development_duration = total_duration * 0.4  # å‘å±•40%
        climax_duration = total_duration * 0.25  # é«˜æ½®25%
        conclusion_duration = total_duration * 0.15  # ç»“å°¾15%

        current_time = 0

        if opening:
            segments.append({
                'start': current_time,
                'end': current_time + opening_duration,
                'text': f"æˆ‘çœ‹åˆ°ï¼š{opening}",
                'type': 'å¼€åœºå™è¿°'
            })
            current_time += opening_duration

        if development:
            segments.append({
                'start': current_time,
                'end': current_time + development_duration,
                'text': f"æˆ‘æ³¨æ„åˆ°ï¼š{development}",
                'type': 'å‘å±•å™è¿°'
            })
            current_time += development_duration

        if climax:
            segments.append({
                'start': current_time,
                'end': current_time + climax_duration,
                'text': f"æˆ‘æ„Ÿå—åˆ°ï¼š{climax}",
                'type': 'é«˜æ½®å™è¿°'
            })
            current_time += climax_duration

        if conclusion:
            segments.append({
                'start': current_time,
                'end': min(current_time + conclusion_duration, total_duration),
                'text': f"æˆ‘æ€»ç»“ï¼š{conclusion}",
                'type': 'ç»“å°¾å™è¿°'
            })

        return segments

    def seconds_to_srt_time(self, seconds: float) -> str:
        """å°†ç§’æ•°è½¬æ¢ä¸ºSRTæ—¶é—´æ ¼å¼"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        ms = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{ms:03d}"

    def generate_editing_plan(self, analysis: Dict, movie_title: str) -> str:
        """ç”Ÿæˆå®Œæ•´å‰ªè¾‘æ–¹æ¡ˆ"""
        if not analysis:
            return "âŒ AIåˆ†æå¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆå‰ªè¾‘æ–¹æ¡ˆ"

        movie_info = analysis.get('movie_analysis', {})
        clips = analysis.get('highlight_clips', [])

        plan = f"""ğŸ¬ ã€Š{movie_title}ã€‹AIåˆ†æå‰ªè¾‘æ–¹æ¡ˆ
{'=' * 80}

ğŸ“Š ç”µå½±åŸºæœ¬ä¿¡æ¯
â€¢ æ ‡é¢˜ï¼š{movie_info.get('title', movie_title)}
â€¢ ç±»å‹ï¼š{movie_info.get('genre', 'æœªçŸ¥')}
â€¢ ä¸»è¦è§’è‰²ï¼š{', '.join(movie_info.get('main_characters', []))}
â€¢ æ ¸å¿ƒä¸»é¢˜ï¼š{movie_info.get('core_theme', 'å¾…åˆ†æ')}
â€¢ æ€»æ—¶é•¿ï¼š{movie_info.get('total_duration', 'æœªçŸ¥')}

ğŸ“– å®Œæ•´æ•…äº‹çº¿
{analysis.get('storyline_summary', 'å®Œæ•´çš„æ•…äº‹å‘å±•è„‰ç»œ')}

ğŸ¯ ç²¾å½©ç‰‡æ®µå‰ªè¾‘æ–¹æ¡ˆï¼ˆå…±{len(clips)}ä¸ªç‰‡æ®µï¼‰
"""

        total_duration = 0

        for i, clip in enumerate(clips, 1):
            duration = clip.get('duration_seconds', 0)
            total_duration += duration

            plan += f"""
{'=' * 60}
ğŸ¬ ç‰‡æ®µ {i}ï¼š{clip.get('title', f'ç²¾å½©ç‰‡æ®µ{i}')}
{'=' * 60}
ğŸ­ å‰§æƒ…ç‚¹ç±»å‹ï¼š{clip.get('plot_type', 'æœªåˆ†ç±»')}
â±ï¸ æ—¶é—´èŒƒå›´ï¼š{clip.get('start_time', '00:00:00,000')} --> {clip.get('end_time', '00:00:00,000')}
ğŸ“ ç‰‡æ®µæ—¶é•¿ï¼š{duration:.1f} ç§’ ({duration/60:.1f} åˆ†é’Ÿ)
ğŸ“Š æˆå‰§ä»·å€¼ï¼š{clip.get('dramatic_value', 0)}/10

ğŸ“ å‰§æƒ…æ‘˜è¦ï¼š
{clip.get('story_summary', 'ç²¾å½©å‰§æƒ…å‘å±•')}

ğŸ™ï¸ ç¬¬ä¸€äººç§°å®Œæ•´å™è¿°ï¼š
{clip.get('first_person_narration', {}).get('full_narration', 'è¯¦ç»†çš„ç¬¬ä¸€äººç§°å™è¿°å†…å®¹')}

ğŸ­ åˆ†æ®µå™è¿°ï¼š
â€¢ å¼€åœºï¼š{clip.get('first_person_narration', {}).get('opening', 'å¼€åœºå™è¿°')}
â€¢ å‘å±•ï¼š{clip.get('first_person_narration', {}).get('development', 'å‘å±•å™è¿°')}
â€¢ é«˜æ½®ï¼š{clip.get('first_person_narration', {}).get('climax', 'é«˜æ½®å™è¿°')}
â€¢ ç»“å°¾ï¼š{clip.get('first_person_narration', {}).get('conclusion', 'ç»“å°¾å™è¿°')}

ğŸ’« å…³é”®æ—¶åˆ»ï¼š
"""
            for moment in clip.get('key_moments', []):
                plan += f"â€¢ {moment}\n"

            plan += f"""
ğŸ’¥ æƒ…æ„Ÿå†²å‡»ï¼š{clip.get('emotional_impact', 'å¼ºçƒˆçš„æƒ…æ„Ÿä½“éªŒ')}
ğŸ¯ é€‰æ‹©åŸå› ï¼š{clip.get('connection_reason', 'ç²¾å½©ç¨‹åº¦æé«˜ï¼Œé€‚åˆçŸ­è§†é¢‘ä¼ æ’­')}
"""

        plan += f"""

ğŸ“Š å‰ªè¾‘ç»Ÿè®¡æ€»ç»“
â€¢ æ€»ç‰‡æ®µæ•°ï¼š{len(clips)} ä¸ª
â€¢ æ€»å‰ªè¾‘æ—¶é•¿ï¼š{total_duration:.1f} ç§’ ({total_duration/60:.1f} åˆ†é’Ÿ)
â€¢ å¹³å‡ç‰‡æ®µæ—¶é•¿ï¼š{total_duration/len(clips) if clips else 0:.1f} ç§’

ğŸ¬ åˆ¶ä½œæŠ€æœ¯è¯´æ˜
{analysis.get('editing_notes', '''â€¢ æ‰€æœ‰ç‰‡æ®µå‡ç”±AIåˆ†æé€‰å®šï¼Œç¡®ä¿ç²¾å½©ç¨‹åº¦
â€¢ æ—¶é—´æ®µå¯èƒ½åœ¨åŸè§†é¢‘ä¸­ä¸è¿ç»­ï¼Œä½†å‰ªè¾‘åé€»è¾‘è¿è´¯
â€¢ ç¬¬ä¸€äººç§°å™è¿°è¯¦ç»†æ¸…æ™°ï¼Œå®Œæ•´è¦†ç›–å‰§æƒ…å‘å±•
â€¢ æ¯ä¸ªç‰‡æ®µéƒ½æœ‰å®Œæ•´çš„æ•…äº‹å¼§çº¿
â€¢ å­—å¹•é”™è¯¯å·²è‡ªåŠ¨ä¿®æ­£
â€¢ é€‚åˆçŸ­è§†é¢‘å¹³å°ä¼ æ’­''')}

âœ¨ è¾“å‡ºæ–‡ä»¶è§„æ ¼
â€¢ è§†é¢‘æ ¼å¼ï¼šMP4 (H.264ç¼–ç )
â€¢ éŸ³é¢‘æ ¼å¼ï¼šAAC
â€¢ åˆ†è¾¨ç‡ï¼šä¿æŒåŸå§‹æ¯”ä¾‹
â€¢ å­—å¹•ï¼šå†…åµŒç¬¬ä¸€äººç§°å™è¿°
â€¢ æ–‡ä»¶å‘½åï¼šç‰‡æ®µåºå·_å‰§æƒ…ç‚¹ç±»å‹_æ ¸å¿ƒå†…å®¹.mp4

ğŸ¯ è§‚çœ‹ä½“éªŒä¿è¯
â€¢ æ¯ä¸ªç‰‡æ®µéƒ½æ˜¯å®Œæ•´çš„æ•…äº‹å•å…ƒ
â€¢ ç¬¬ä¸€äººç§°å™è¿°è®©è§‚ä¼—èº«ä¸´å…¶å¢ƒ
â€¢ å‰§æƒ…ç‚¹åˆ†ç±»è®©å†…å®¹èšç„¦æ˜ç¡®
â€¢ æ—¶é•¿æ§åˆ¶åœ¨æœ€ä½³è§‚çœ‹èŒƒå›´å†…

ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
AIåˆ†æå¼•æ“ï¼šä¸“ä¸šç”µå½±å‰ªè¾‘åˆ†æç³»ç»Ÿ v2.0
"""

        return plan

    def time_to_seconds(self, time_str: str) -> float:
        """æ—¶é—´è½¬æ¢ä¸ºç§’"""
        try:
            time_str = time_str.replace('.', ',')
            h, m, s_ms = time_str.split(':')
            s, ms = s_ms.split(',')
            return int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000
        except:
            return 0

    def process_movie_file(self, srt_file: str) -> bool:
        """å¤„ç†å•ä¸ªç”µå½±æ–‡ä»¶"""
        print(f"\nğŸ¬ å¤„ç†ç”µå½±: {srt_file}")

        # 1. è§£æå­—å¹•
        srt_path = os.path.join(self.srt_folder, srt_file)
        subtitles = self.parse_srt_file(srt_path)

        if not subtitles:
            print("âŒ å­—å¹•è§£æå¤±è´¥")
            return False

        # 2. æå–ç”µå½±æ ‡é¢˜
        movie_title = os.path.splitext(srt_file)[0]

        # 3. AIåˆ†æ
        print("ğŸ¤– AIæ­£åœ¨åˆ†æç”µå½±å†…å®¹...")
        analysis = self.ai_analyze_movie(subtitles, movie_title)

        if not analysis:
            print("âŒ AIåˆ†æå¤±è´¥")
            return False

        # 4. åˆ›å»ºè§†é¢‘ç‰‡æ®µï¼ˆæ— å£°ï¼Œé…ç¬¬ä¸€äººç§°å™è¿°ï¼‰
        created_clips = self.create_video_clips(analysis, movie_title)

        # 5. ç”Ÿæˆå‰ªè¾‘æ–¹æ¡ˆ
        editing_plan = self.generate_editing_plan(analysis, movie_title)

        # 6. ä¿å­˜ç»“æœ
        plan_filename = f"{movie_title}_AIå‰ªè¾‘æ–¹æ¡ˆ.txt"
        plan_path = os.path.join(self.analysis_folder, plan_filename)

        with open(plan_path, 'w', encoding='utf-8') as f:
            f.write(editing_plan)

        # 7. ç”Ÿæˆè§†é¢‘å‰ªè¾‘æŠ¥å‘Š
        if created_clips:
            video_report = self.generate_video_report(created_clips, movie_title, analysis)
            video_report_path = os.path.join(self.analysis_folder, f"{movie_title}_è§†é¢‘å‰ªè¾‘æŠ¥å‘Š.txt")
            with open(video_report_path, 'w', encoding='utf-8') as f:
                f.write(video_report)

        # 6. ä¿å­˜è¯¦ç»†AIåˆ†ææ•°æ®
        analysis_filename = f"{movie_title}_AIåˆ†ææ•°æ®.json"
        analysis_path = os.path.join(self.analysis_folder, analysis_filename)

        with open(analysis_path, 'w', encoding='utf-8') as f:
            json.dump(analysis, f, ensure_ascii=False, indent=2)

        print(f"âœ… å¤„ç†å®Œæˆï¼")
        print(f"ğŸ“„ å‰ªè¾‘æ–¹æ¡ˆï¼š{plan_filename}")
        print(f"ğŸ“Š åˆ†ææ•°æ®ï¼š{analysis_filename}")

        return True

    def process_all_movies(self):
        """å¤„ç†æ‰€æœ‰ç”µå½±æ–‡ä»¶ - å¢å¼ºç‰ˆï¼Œé—®é¢˜9,10,11å…¨é¢è§£å†³"""
        print("ğŸš€ ç”µå½±AIåˆ†æå‰ªè¾‘ç³»ç»Ÿå¯åŠ¨")
        print("=" * 60)

        # è·å–æ‰€æœ‰å­—å¹•æ–‡ä»¶
        srt_files = [f for f in os.listdir(self.srt_folder) 
                     if f.endswith(('.srt', '.txt')) and not f.startswith('.')]

        if not srt_files:
            print(f"âŒ {self.srt_folder}/ ç›®å½•ä¸­æœªæ‰¾åˆ°å­—å¹•æ–‡ä»¶")
            print(f"ğŸ’¡ è¯·å°†ç”µå½±å­—å¹•æ–‡ä»¶æ”¾å…¥ {self.srt_folder}/ ç›®å½•")
            return

        srt_files.sort()
        print(f"ğŸ“ æ‰¾åˆ° {len(srt_files)} ä¸ªå­—å¹•æ–‡ä»¶")

        if not self.ai_config.get('enabled'):
            print("âŒ AIæœªé…ç½®ï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
            print("ğŸ’¡ è¯·å…ˆé…ç½®AI APIå¯†é’¥")
            return

        # é—®é¢˜10ï¼šæ£€æŸ¥å·²æœ‰çš„åˆ†æç»“æœ
        print("\nğŸ” æ£€æŸ¥ç°æœ‰åˆ†æçŠ¶æ€...")
        cached_count, analyzing_count, failed_count = self.check_analysis_status(srt_files)

        if cached_count > 0:
            print(f"ğŸ’¾ å‘ç° {cached_count} ä¸ªå·²ç¼“å­˜çš„AIåˆ†æç»“æœ")
            use_cache = input("æ˜¯å¦ä½¿ç”¨å·²æœ‰çš„åˆ†æç»“æœï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
            if use_cache in ['', 'y', 'yes']:
                print("âœ… å°†ä½¿ç”¨å·²æœ‰åˆ†æç»“æœï¼Œè·³è¿‡é‡å¤AIè°ƒç”¨")
            else:
                print("ğŸ”„ å°†é‡æ–°è¿›è¡ŒAIåˆ†æ")
                # æ¸…ç†ç°æœ‰ç¼“å­˜
                self.cleanup_temp_files()

        print(f"\nğŸ¬ å¼€å§‹å¤„ç†ç”µå½± - ç‰¹è‰²åŠŸèƒ½:")
        print("â€¢ é—®é¢˜9è§£å†³ï¼šç¬¬ä¸€äººç§°å™è¿°ä¸è§†é¢‘ç²¾ç¡®åŒæ­¥")
        print("â€¢ é—®é¢˜10è§£å†³ï¼šAIåˆ†æç»“æœæ™ºèƒ½ç¼“å­˜ï¼Œé¿å…é‡å¤è°ƒç”¨")
        print("â€¢ é—®é¢˜11è§£å†³ï¼šç›¸åŒåˆ†æå¤šæ¬¡å‰ªè¾‘ç»“æœå®Œå…¨ä¸€è‡´")
        print("=" * 60)

        # å¤„ç†æ¯ä¸ªæ–‡ä»¶
        success_count = 0
        total_clips_created = 0

        for i, srt_file in enumerate(srt_files, 1):
            try:
                print(f"\n{'ğŸ¬' * 3} å¤„ç†ç¬¬ {i}/{len(srt_files)} éƒ¨ç”µå½± {'ğŸ¬' * 3}")
                print(f"æ–‡ä»¶: {srt_file}")

                result = self.process_movie_file(srt_file)
                if result:
                    success_count += 1
                    # ç»Ÿè®¡åˆ›å»ºçš„ç‰‡æ®µæ•°
                    movie_title = os.path.splitext(srt_file)[0]
                    clip_pattern = os.path.join(self.output_folder, f"{movie_title}_ç‰‡æ®µ*.mp4")
                    import glob
                    clips = glob.glob(clip_pattern)
                    total_clips_created += len(clips)
                    print(f"âœ… æˆåŠŸå¤„ç†ï¼Œç”Ÿæˆ {len(clips)} ä¸ªè§†é¢‘ç‰‡æ®µ")
                else:
                    print(f"âŒ å¤„ç†å¤±è´¥")

            except Exception as e:
                print(f"âŒ å¤„ç† {srt_file} æ—¶å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()

        # ç”Ÿæˆå¢å¼ºç‰ˆæ€»ç»“æŠ¥å‘Š
        print(f"\n{'ğŸ‰' * 3} å¤„ç†å®Œæˆ {'ğŸ‰' * 3}")
        print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
        print(f"âœ… æˆåŠŸå¤„ç†: {success_count}/{len(srt_files)} éƒ¨ç”µå½±")
        print(f"ğŸ¬ ç”Ÿæˆç‰‡æ®µ: {total_clips_created} ä¸ª")
        print(f"ğŸ’¾ ç¼“å­˜æ–‡ä»¶: {len([f for f in os.listdir(self.cache_folder) if f.endswith('.json')])} ä¸ª")

        self.generate_summary_report(srt_files, success_count)

    def cleanup_temp_files(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶å’ŒæŸåçš„ç¼“å­˜"""
        try:
            temp_files_cleaned = 0

            # æ¸…ç†ä¸´æ—¶åˆ†ææ–‡ä»¶
            for filename in os.listdir(self.cache_folder):
                if filename.endswith('_temp.json'):
                    temp_path = os.path.join(self.cache_folder, filename)
                    try:
                        with open(temp_path, 'r', encoding='utf-8') as f:
                            temp_data = json.load(f)

                        # å¦‚æœæ˜¯å¤±è´¥çš„ä¸´æ—¶æ–‡ä»¶ï¼Œåˆ é™¤å®ƒ
                        if temp_data.get('status') == 'failed':
                            os.remove(temp_path)
                            temp_files_cleaned += 1
                        # å¦‚æœæ˜¯è¶…æ—¶çš„åˆ†ææ–‡ä»¶ï¼Œåˆ é™¤å®ƒ
                        elif temp_data.get('status') == 'analyzing':
                            from datetime import datetime, timedelta
                            start_time = datetime.fromisoformat(temp_data.get('start_time', ''))
                            if datetime.now() - start_time > timedelta(hours=2):  # è¶…è¿‡2å°æ—¶
                                os.remove(temp_path)
                                temp_files_cleaned += 1
                    except:
                        # æŸåçš„ä¸´æ—¶æ–‡ä»¶ç›´æ¥åˆ é™¤
                        os.remove(temp_path)
                        temp_files_cleaned += 1

            if temp_files_cleaned > 0:
                print(f"ğŸ§¹ æ¸…ç†äº† {temp_files_cleaned} ä¸ªä¸´æ—¶æ–‡ä»¶")

        except Exception as e:
            print(f"âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")

    def check_analysis_status(self, srt_files: List[str]):
        """æ£€æŸ¥åˆ†æçŠ¶æ€ - é—®é¢˜10ï¼šæ˜¾ç¤ºå·²ä¿å­˜çš„åˆ†æ"""
        print("ğŸ“Š åˆ†æçŠ¶æ€æ£€æŸ¥")
        print("=" * 50)

        cached_count = 0
        analyzing_count = 0
        failed_count = 0

        for srt_file in srt_files:
            movie_title = os.path.splitext(srt_file)[0]

            # æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜çš„åˆ†æç»“æœ
            cache_files = [f for f in os.listdir(self.cache_folder) 
                          if f.startswith(f'analysis_{movie_title}_') and f.endswith('.json')]

            temp_files = [f for f in os.listdir(self.cache_folder) 
                         if f.startswith(f'analysis_{movie_title}_') and f.endswith('_temp.json')]

            if cache_files:
                cached_count += 1
                print(f"âœ… {srt_file} - å·²æœ‰AIåˆ†æç»“æœ")
            elif temp_files:
                analyzing_count += 1
                print(f"â³ {srt_file} - åˆ†æè¿›è¡Œä¸­æˆ–å·²ä¸­æ–­")
            else:
                failed_count += 1
                print(f"âŒ {srt_file} - éœ€è¦é‡æ–°åˆ†æ")

        print(f"\nğŸ“‹ çŠ¶æ€ç»Ÿè®¡:")
        print(f"âœ… å·²å®Œæˆåˆ†æ: {cached_count}/{len(srt_files)}")
        print(f"â³ åˆ†æä¸­/ä¸­æ–­: {analyzing_count}")
        print(f"âŒ éœ€è¦åˆ†æ: {failed_count}")

        if cached_count == len(srt_files):
            print("ğŸ‰ æ‰€æœ‰ç”µå½±éƒ½æœ‰AIåˆ†æç»“æœï¼Œå¯ä»¥ç›´æ¥è¿›è¡Œå‰ªè¾‘ï¼")

        return cached_count, analyzing_count, failed_count

    def generate_summary_report(self, srt_files: List[str], success_count: int):
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š - å¢å¼ºç‰ˆ"""

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        self.cleanup_temp_files()

        # ç»Ÿè®¡ç¼“å­˜ä½¿ç”¨æƒ…å†µ
        cached_count, analyzing_count, failed_count = self.check_analysis_status(srt_files)

        report = f"""ğŸ¬ ç”µå½±AIåˆ†æå‰ªè¾‘ç³»ç»Ÿ - æ€»ç»“æŠ¥å‘Š
{'=' * 80}

ğŸ“Š å¤„ç†ç»Ÿè®¡
â€¢ æ€»æ–‡ä»¶æ•°ï¼š{len(srt_files)} ä¸ª
â€¢ æˆåŠŸåˆ†æï¼š{success_count} ä¸ª
â€¢ å¤±è´¥æ•°é‡ï¼š{len(srt_files) - success_count} ä¸ª
â€¢ æˆåŠŸç‡ï¼š{success_count/len(srt_files)*100:.1f}%

ğŸ’¾ ç¼“å­˜ç»Ÿè®¡ (é—®é¢˜10è§£å†³æ–¹æ¡ˆ)
â€¢ å·²ç¼“å­˜åˆ†æï¼š{cached_count} ä¸ª
â€¢ åˆ†æä¸­/ä¸­æ–­ï¼š{analyzing_count} ä¸ª  
â€¢ éœ€è¦é‡æ–°åˆ†æï¼š{failed_count} ä¸ª
â€¢ ç¼“å­˜åˆ©ç”¨ç‡ï¼š{cached_count/len(srt_files)*100:.1f}%

âœ¨ ç³»ç»Ÿç‰¹è‰²
â€¢ âœ… 100% AIåˆ†æ - æ— AIä¸åˆ†æï¼Œç¡®ä¿æ™ºèƒ½åŒ–ç¨‹åº¦
â€¢ âœ… æ™ºèƒ½é”™è¯¯ä¿®æ­£ - è‡ªåŠ¨ä¿®æ­£å­—å¹•ä¸­çš„é”™åˆ«å­—å’Œæ ¼å¼é—®é¢˜
â€¢ âœ… ç²¾å½©ç‰‡æ®µè¯†åˆ« - AIæ™ºèƒ½è¯†åˆ«5-8ä¸ªæœ€ç²¾å½©çš„å‰§æƒ…ç‚¹
â€¢ âœ… ç¬¬ä¸€äººç§°å™è¿° - è¯¦ç»†æ¸…æ™°çš„"æˆ‘"è§†è§’å™è¿°å†…å®¹
â€¢ âœ… å‰§æƒ…ç‚¹åˆ†ç±» - æŒ‰å†²çªã€è½¬æŠ˜ã€æ­éœ²ç­‰ç±»å‹ç²¾å‡†åˆ†ç±»
â€¢ âœ… éè¿ç»­å‰ªè¾‘ - æ”¯æŒæ—¶é—´ä¸è¿ç»­ä½†é€»è¾‘è¿è´¯çš„å‰ªè¾‘
â€¢ âœ… å®Œæ•´æ•…äº‹çº¿ - ç¡®ä¿æ¯ä¸ªç‰‡æ®µéƒ½æœ‰å®Œæ•´çš„æ•…äº‹å¼§çº¿

ğŸ“ è¾“å‡ºæ–‡ä»¶
â€¢ å‰ªè¾‘æ–¹æ¡ˆï¼š{self.analysis_folder}/*_AIå‰ªè¾‘æ–¹æ¡ˆ.txt
â€¢ åˆ†ææ•°æ®ï¼š{self.analysis_folder}/*_AIåˆ†ææ•°æ®.json
â€¢ ç¼“å­˜æ–‡ä»¶ï¼š{self.cache_folder}/*.json

ğŸ¯ è¾“å‡ºæ ¼å¼å›ºå®šæ ‡å‡†
æ¯ä¸ªå‰ªè¾‘æ–¹æ¡ˆåŒ…å«ï¼š
1. ğŸ“Š ç”µå½±åŸºæœ¬ä¿¡æ¯ï¼ˆç±»å‹ã€è§’è‰²ã€ä¸»é¢˜ï¼‰
2. ğŸ“– å®Œæ•´æ•…äº‹çº¿æ€»ç»“
3. ğŸ¬ ç²¾å½©ç‰‡æ®µè¯¦ç»†æ–¹æ¡ˆï¼ˆ5-8ä¸ªï¼‰
4. ğŸ™ï¸ ç¬¬ä¸€äººç§°å®Œæ•´å™è¿°ï¼ˆå¼€åœº-å‘å±•-é«˜æ½®-ç»“å°¾ï¼‰
5. â±ï¸ ç²¾ç¡®æ—¶é—´æ ‡æ³¨ï¼ˆå¼€å§‹-ç»“æŸæ—¶é—´ï¼‰
6. ğŸ­ å‰§æƒ…ç‚¹ç±»å‹åˆ†ç±»
7. ğŸ“ åˆ¶ä½œæŠ€æœ¯è¯´æ˜

ğŸ’¡ ä½¿ç”¨è¯´æ˜
â€¢ å°†ç”µå½±å­—å¹•æ–‡ä»¶(.srt/.txt)æ”¾å…¥ {self.srt_folder}/ ç›®å½•
â€¢ è¿è¡Œç³»ç»Ÿè‡ªåŠ¨è¿›è¡ŒAIåˆ†æ
â€¢ æŸ¥çœ‹ {self.analysis_folder}/ ç›®å½•è·å–å‰ªè¾‘æ–¹æ¡ˆ
â€¢ æ–¹æ¡ˆåŒ…å«å®Œæ•´çš„ç¬¬ä¸€äººç§°å™è¿°å’Œæ—¶é—´æ ‡æ³¨
â€¢ é€‚åˆç›´æ¥ç”¨äºçŸ­è§†é¢‘åˆ¶ä½œ

ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

        report_path = os.path.join(self.analysis_folder, "ç”µå½±AIåˆ†ææ€»ç»“æŠ¥å‘Š.txt")
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)

    def generate_video_report(self, created_clips: List[str], movie_title: str, analysis: Dict) -> str:
        """ç”Ÿæˆè§†é¢‘å‰ªè¾‘æŠ¥å‘Š"""
        clips = analysis.get('highlight_clips', [])

        report = f"""ğŸ¬ ã€Š{movie_title}ã€‹è§†é¢‘å‰ªè¾‘æŠ¥å‘Š
{'=' * 80}

ğŸ¯ å‰ªè¾‘ç‰¹è‰²
â€¢ âœ… æ— å£°è§†é¢‘ - ä¸“ä¸ºç¬¬ä¸€äººç§°å™è¿°è®¾è®¡
â€¢ âœ… ç¬¬ä¸€äººç§°è§†è§’ - "æˆ‘çœ‹åˆ°/æˆ‘æ³¨æ„åˆ°/æˆ‘æ„Ÿå—åˆ°/æˆ‘æ€»ç»“"
â€¢ âœ… æ™ºèƒ½æ—¶é—´åŒæ­¥ - å™è¿°ä¸è§†é¢‘å†…å®¹å®æ—¶åŒ¹é…
â€¢ âœ… é”™åˆ«å­—ä¿®æ­£ - "é˜²è¡›"â†’"é˜²å«", "æ­£ç•¶"â†’"æ­£å½“"ç­‰

ğŸ“Š å‰ªè¾‘ç»Ÿè®¡
â€¢ æˆåŠŸåˆ›å»ºè§†é¢‘: {len(created_clips)} ä¸ª
â€¢ å¹³å‡ç‰‡æ®µæ—¶é•¿: {sum(clip.get('duration_seconds', 0) for clip in clips) / len(clips) if clips else 0:.1f} ç§’
â€¢ æ€»è§†é¢‘æ—¶é•¿: {sum(clip.get('duration_seconds', 0) for clip in clips):.1f} ç§’

ğŸ“ è§†é¢‘ç‰‡æ®µè¯¦æƒ…:
"""

        for i, (clip_path, clip) in enumerate(zip(created_clips, clips), 1):
            duration = clip.get('duration_seconds', 0)
            narration = clip.get('first_person_narration', {})

            report += f"""
ğŸ¬ ç‰‡æ®µ {i}: {os.path.basename(clip_path)}
   å‰§æƒ…ç±»å‹: {clip.get('plot_type', 'æœªåˆ†ç±»')}
   è§†é¢‘æ—¶é•¿: {duration:.1f} ç§’
   è§†é¢‘ç‰¹ç‚¹: æ— å£°è§†é¢‘ï¼Œé…ç¬¬ä¸€äººç§°å™è¿°

   ç¬¬ä¸€äººç§°å™è¿°ç»“æ„:
   â€¢ å¼€åœº(20%): æˆ‘çœ‹åˆ° - {narration.get('opening', 'å¼€åœºå™è¿°')[:50]}...
   â€¢ å‘å±•(40%): æˆ‘æ³¨æ„åˆ° - {narration.get('development', 'å‘å±•å™è¿°')[:50]}...
   â€¢ é«˜æ½®(25%): æˆ‘æ„Ÿå—åˆ° - {narration.get('climax', 'é«˜æ½®å™è¿°')[:50]}...
   â€¢ ç»“å°¾(15%): æˆ‘æ€»ç»“ - {narration.get('conclusion', 'ç»“å°¾å™è¿°')[:50]}...

   å­—å¹•æ–‡ä»¶: {os.path.basename(clip_path).replace('.mp4', '_ç¬¬ä¸€äººç§°å™è¿°.srt')}
"""

        report += f"""

ğŸ“ æ–‡ä»¶è¯´æ˜
â€¢ è§†é¢‘æ–‡ä»¶: {self.output_folder}/*.mp4 (æ— å£°è§†é¢‘)
â€¢ å­—å¹•æ–‡ä»¶: {self.output_folder}/*_ç¬¬ä¸€äººç§°å™è¿°.srt (ç¬¬ä¸€äººç§°å™è¿°)
â€¢ å‰ªè¾‘æ–¹æ¡ˆ: {movie_title}_AIå‰ªè¾‘æ–¹æ¡ˆ.txt

ğŸ¯ ä½¿ç”¨è¯´æ˜
1. è§†é¢‘æ–‡ä»¶å·²å»é™¤åŸå£°ï¼Œé€‚åˆé…éŸ³åˆ¶ä½œ
2. å­—å¹•æ–‡ä»¶æä¾›å®Œæ•´çš„ç¬¬ä¸€äººç§°å™è¿°æ–‡æœ¬
3. å™è¿°æŒ‰æ—¶é—´æ®µåˆ†å¸ƒï¼Œä¸è§†é¢‘å†…å®¹åŒæ­¥
4. æ”¯æŒ"æˆ‘çœ‹åˆ°/æˆ‘æ³¨æ„åˆ°/æˆ‘æ„Ÿå—åˆ°/æˆ‘æ€»ç»“"çš„å™è¿°ç»“æ„

ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
å‰ªè¾‘ç³»ç»Ÿ: ç”µå½±AIåˆ†æå‰ªè¾‘ç³»ç»Ÿ v2.1 (æ”¯æŒè§†é¢‘å‰ªè¾‘)
"""
        return report

def main():
    """ä¸»å‡½æ•°"""
    clipper = MovieAIClipper()
    clipper.process_all_movies()

if __name__ == "__main__":
    main()