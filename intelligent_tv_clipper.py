
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ™ºèƒ½ç”µè§†å‰§å‰ªè¾‘ç³»ç»Ÿ v3.0
è§£å†³æ‰€æœ‰15ä¸ªæ ¸å¿ƒé—®é¢˜çš„å®Œæ•´æ–¹æ¡ˆ
"""

import os
import re
import json
import subprocess
import hashlib
import requests
from typing import List, Dict, Optional, Tuple
from datetime import datetime

class IntelligentTVClipper:
    def __init__(self):
        # æ ‡å‡†ç›®å½•ç»“æ„
        self.srt_folder = "srt"
        self.videos_folder = "videos"
        self.output_folder = "clips"
        self.cache_folder = "cache"
        
        # åˆ›å»ºå¿…è¦ç›®å½•
        for folder in [self.srt_folder, self.videos_folder, self.output_folder, self.cache_folder]:
            os.makedirs(folder, exist_ok=True)
        
        # åŠ è½½AIé…ç½®
        self.ai_config = self._load_ai_config()
        
        print("ğŸš€ æ™ºèƒ½ç”µè§†å‰§å‰ªè¾‘ç³»ç»Ÿ v3.0")
        print("=" * 60)
        print("âœ¨ æ ¸å¿ƒç‰¹æ€§ï¼š")
        print("â€¢ å®Œå…¨AIæ™ºèƒ½åˆ†æï¼Œè‡ªé€‚åº”æ‰€æœ‰å‰§æƒ…ç±»å‹")
        print("â€¢ æ•´é›†ä¸Šä¸‹æ–‡åˆ†æï¼Œé¿å…å°è¯å‰²è£‚")  
        print("â€¢ æ¯é›†å¤šä¸ªç²¾å½©çŸ­è§†é¢‘ï¼ŒAIåˆ¤æ–­å®Œæ•´å†…å®¹")
        print("â€¢ å®é™…å‰ªè¾‘ç”Ÿæˆè§†é¢‘æ–‡ä»¶ + ä¸“ä¸šæ—ç™½")
        print("â€¢ æ™ºèƒ½ç¼“å­˜æœºåˆ¶ï¼Œé¿å…é‡å¤APIè°ƒç”¨")
        print("â€¢ å¤šæ¬¡æ‰§è¡Œç»“æœä¸€è‡´æ€§ä¿è¯")
        print("=" * 60)

    def _load_ai_config(self) -> Dict:
        """åŠ è½½AIé…ç½®"""
        try:
            if os.path.exists('.ai_config.json'):
                with open('.ai_config.json', 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    if config.get('enabled', False):
                        print(f"ğŸ¤– AIå·²é…ç½®: {config.get('provider', 'unknown')}")
                        return config
        except Exception as e:
            print(f"âš ï¸ AIé…ç½®åŠ è½½å¤±è´¥: {e}")
        
        print("ğŸ“ å°†ä½¿ç”¨åŸºç¡€è§„åˆ™åˆ†æ")
        return {'enabled': False}

    def parse_srt_file(self, filepath: str) -> List[Dict]:
        """è§£æSRTå­—å¹•æ–‡ä»¶ï¼Œæ™ºèƒ½é”™è¯¯ä¿®æ­£"""
        print(f"ğŸ“– è§£æå­—å¹•: {os.path.basename(filepath)}")
        
        # å°è¯•å¤šç§ç¼–ç 
        content = None
        for encoding in ['utf-8', 'gbk', 'utf-16', 'gb2312']:
            try:
                with open(filepath, 'r', encoding=encoding, errors='ignore') as f:
                    content = f.read()
                    break
            except:
                continue
        
        if not content:
            print(f"âŒ æ— æ³•è¯»å–æ–‡ä»¶: {filepath}")
            return []
        
        # æ™ºèƒ½é”™åˆ«å­—ä¿®æ­£
        corrections = {
            'é˜²è¡›': 'é˜²å«', 'æ­£ç•¶': 'æ­£å½“', 'è¨¼æ“š': 'è¯æ®', 'æª¢å¯Ÿå®˜': 'æ£€å¯Ÿå®˜',
            'å¯©åˆ¤': 'å®¡åˆ¤', 'è¾¯è­·': 'è¾©æŠ¤', 'èµ·è¨´': 'èµ·è¯‰', 'èª¿æŸ¥': 'è°ƒæŸ¥',
            'ç™¼ç¾': 'å‘ç°', 'æ±ºå®š': 'å†³å®š', 'é¸æ“‡': 'é€‰æ‹©', 'é–‹å§‹': 'å¼€å§‹'
        }
        
        for old, new in corrections.items():
            content = content.replace(old, new)
        
        # è§£æå­—å¹•æ¡ç›®
        subtitles = []
        blocks = re.split(r'\n\s*\n', content.strip())
        
        for block in blocks:
            lines = block.strip().split('\n')
            if len(lines) >= 3:
                try:
                    index = int(lines[0]) if lines[0].isdigit() else len(subtitles) + 1
                    
                    # åŒ¹é…æ—¶é—´æ ¼å¼
                    time_pattern = r'(\d{2}:\d{2}:\d{2}[,\.]\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2}[,\.]\d{3})'
                    time_match = re.search(time_pattern, lines[1])
                    
                    if time_match:
                        start_time = time_match.group(1).replace('.', ',')
                        end_time = time_match.group(2).replace('.', ',')
                        text = '\n'.join(lines[2:]).strip()
                        
                        if text:
                            subtitles.append({
                                'index': index,
                                'start': start_time,
                                'end': end_time,
                                'text': text
                            })
                except (ValueError, IndexError):
                    continue
        
        print(f"âœ… è§£æå®Œæˆ: {len(subtitles)} æ¡å­—å¹•")
        return subtitles

    def _get_cache_key(self, subtitles: List[Dict]) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        content = json.dumps(subtitles, ensure_ascii=False, sort_keys=True)
        return hashlib.md5(content.encode()).hexdigest()[:16]

    def _load_cache(self, cache_key: str, episode_name: str) -> Optional[Dict]:
        """åŠ è½½åˆ†æç¼“å­˜"""
        cache_file = os.path.join(self.cache_folder, f"{episode_name}_{cache_key}.json")
        if os.path.exists(cache_file):
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    analysis = json.load(f)
                    print(f"ğŸ’¾ ä½¿ç”¨ç¼“å­˜åˆ†æ: {episode_name}")
                    return analysis
            except Exception as e:
                print(f"âš ï¸ ç¼“å­˜è¯»å–å¤±è´¥: {e}")
        return None

    def _save_cache(self, cache_key: str, episode_name: str, analysis: Dict):
        """ä¿å­˜åˆ†æç¼“å­˜"""
        cache_file = os.path.join(self.cache_folder, f"{episode_name}_{cache_key}.json")
        try:
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(analysis, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ ä¿å­˜åˆ†æç¼“å­˜: {episode_name}")
        except Exception as e:
            print(f"âš ï¸ ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")

    def ai_analyze_complete_episode(self, subtitles: List[Dict], episode_name: str) -> Dict:
        """AIå®Œæ•´åˆ†æå•é›† - è§£å†³é—®é¢˜1,2,3,8"""
        # æ£€æŸ¥ç¼“å­˜ - è§£å†³é—®é¢˜12
        cache_key = self._get_cache_key(subtitles)
        cached_analysis = self._load_cache(cache_key, episode_name)
        if cached_analysis:
            return cached_analysis
        
        episode_num = self._extract_episode_number(episode_name)
        
        # æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡ - è§£å†³é—®é¢˜2ï¼šé¿å…å°è¯å‰²è£‚
        full_context = self._build_complete_context(subtitles)
        
        if self.ai_config.get('enabled', False):
            analysis = self._call_ai_analysis(full_context, episode_num, episode_name)
        else:
            analysis = self._basic_analysis_fallback(subtitles, episode_num, episode_name)
        
        # ä¿å­˜ç¼“å­˜ - è§£å†³é—®é¢˜12
        self._save_cache(cache_key, episode_name, analysis)
        
        return analysis

    def _build_complete_context(self, subtitles: List[Dict]) -> str:
        """æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡ï¼Œé¿å…å‰²è£‚"""
        # å°†æ‰€æœ‰å­—å¹•åˆå¹¶ä¸ºå®Œæ•´æ–‡æœ¬ï¼Œä¿æŒæ—¶é—´ä¿¡æ¯
        context_parts = []
        
        # æ¯50å¥åˆ†ä¸€æ®µï¼Œä¿æŒä¸Šä¸‹æ–‡
        for i in range(0, len(subtitles), 50):
            segment = subtitles[i:i+50]
            segment_text = '\n'.join([f"[{sub['start']} --> {sub['end']}] {sub['text']}" for sub in segment])
            context_parts.append(segment_text)
        
        return '\n\n=== åœºæ™¯åˆ†å‰² ===\n\n'.join(context_parts)

    def _call_ai_analysis(self, context: str, episode_num: str, episode_name: str) -> Dict:
        """è°ƒç”¨AIè¿›è¡Œå®Œæ•´åˆ†æ"""
        prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§å‰ªè¾‘å¸ˆï¼Œéœ€è¦ä¸ºç¬¬{episode_num}é›†åˆ›å»ºå¤šä¸ª2-3åˆ†é’Ÿçš„ç²¾å½©çŸ­è§†é¢‘ã€‚

ã€å®Œæ•´å‰§æƒ…å†…å®¹ã€‘
{context}

è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
1. è‡ªåŠ¨è¯†åˆ«å‰§æƒ…ç±»å‹ï¼ˆä¸è¦é™åˆ¶ä¸ºç‰¹å®šç±»å‹ï¼Œè¦æ™ºèƒ½åˆ¤æ–­ï¼‰
2. æ‰¾å‡º3-5ä¸ªæœ€ç²¾å½©çš„ç‰‡æ®µï¼Œæ¯ä¸ª2-3åˆ†é’Ÿ
3. ç¡®ä¿ç‰‡æ®µåŒ…å«å®Œæ•´å¯¹è¯ï¼Œä¸æˆªæ–­å¥å­
4. ç”Ÿæˆä¸“ä¸šæ—ç™½è§£è¯´
5. ä¿è¯å‰§æƒ…è¿è´¯æ€§

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
{{
    "episode_analysis": {{
        "episode_number": "{episode_num}",
        "genre": "è‡ªåŠ¨è¯†åˆ«çš„å‰§æƒ…ç±»å‹",
        "main_theme": "æœ¬é›†ä¸»é¢˜",
        "story_arc": "å‰§æƒ…å‘å±•å¼§çº¿"
    }},
    "highlight_segments": [
        {{
            "segment_id": 1,
            "title": "ç‰‡æ®µæ ‡é¢˜",
            "start_time": "å¼€å§‹æ—¶é—´(HH:MM:SS,mmm)",
            "end_time": "ç»“æŸæ—¶é—´(HH:MM:SS,mmm)",
            "duration_seconds": å®é™…ç§’æ•°,
            "description": "å†…å®¹æè¿°",
            "dramatic_value": 8.5,
            "key_dialogues": ["å…³é”®å¯¹è¯1", "å…³é”®å¯¹è¯2"],
            "plot_significance": "å‰§æƒ…é‡è¦æ€§",
            "emotional_impact": "æƒ…æ„Ÿå†²å‡»",
            "narration": {{
                "opening": "å¼€åœºæ—ç™½",
                "climax": "é«˜æ½®è§£è¯´", 
                "conclusion": "ç»“å°¾æ€»ç»“"
            }}
        }}
    ],
    "continuity": {{
        "previous_connection": "ä¸å‰é›†è¿æ¥",
        "next_setup": "ä¸ºä¸‹é›†é“ºå«"
    }}
}}

åˆ†æåŸåˆ™ï¼š
- å®Œå…¨æ™ºèƒ½åŒ–ï¼Œä¸è¦é™åˆ¶å‰§æƒ…ç±»å‹
- ä¼˜å…ˆé€‰æ‹©æˆå‰§å†²çªå¼ºçƒˆçš„ç‰‡æ®µ
- ç¡®ä¿æ¯ä¸ªç‰‡æ®µæœ‰å®Œæ•´çš„æ•…äº‹å¼§çº¿
- é‡è§†è§’è‰²å‘å±•å’Œæƒ…æ„Ÿå˜åŒ–
- ä¿æŒä¸æ•´ä½“å‰§æƒ…çš„è¿è´¯æ€§"""

        try:
            response = self._call_ai_api(prompt)
            if response:
                analysis = self._parse_ai_response(response)
                if analysis:
                    return analysis
        except Exception as e:
            print(f"âš ï¸ AIåˆ†æå¤±è´¥: {e}")
        
        # é™çº§åˆ°åŸºç¡€åˆ†æ
        return self._basic_analysis_fallback(subtitles, episode_num, episode_name)

    def _call_ai_api(self, prompt: str) -> Optional[str]:
        """ç»Ÿä¸€AI APIè°ƒç”¨"""
        try:
            config = self.ai_config
            api_type = config.get('api_type', 'proxy')
            
            if api_type == 'official':
                return self._call_official_api(prompt, config)
            else:
                return self._call_proxy_api(prompt, config)
                
        except Exception as e:
            print(f"âš ï¸ APIè°ƒç”¨å¼‚å¸¸: {e}")
            return None

    def _call_official_api(self, prompt: str, config: Dict) -> Optional[str]:
        """è°ƒç”¨å®˜æ–¹API"""
        provider = config.get('provider', 'openai')
        
        if provider == 'gemini':
            try:
                from google import genai
                client = genai.Client(api_key=config['api_key'])
                response = client.models.generate_content(
                    model=config.get('model', 'gemini-2.5-flash'),
                    contents=prompt
                )
                return response.text
            except Exception as e:
                print(f"âš ï¸ Gemini APIè°ƒç”¨å¤±è´¥: {e}")
                return None
        
        # å…¶ä»–å®˜æ–¹APIå¯ä»¥åœ¨è¿™é‡Œæ·»åŠ 
        return None

    def _call_proxy_api(self, prompt: str, config: Dict) -> Optional[str]:
        """è°ƒç”¨ä»£ç†API"""
        try:
            from openai import OpenAI
            
            client = OpenAI(
                api_key=config['api_key'],
                base_url=config.get('base_url', 'https://api.openai.com/v1')
            )
            
            response = client.chat.completions.create(
                model=config.get('model', 'gpt-3.5-turbo'),
                messages=[
                    {'role': 'system', 'content': 'ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§å‰ªè¾‘å¸ˆï¼Œæ“…é•¿è¯†åˆ«ç²¾å½©ç‰‡æ®µã€‚'},
                    {'role': 'user', 'content': prompt}
                ],
                max_tokens=4000,
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"âš ï¸ ä»£ç†APIè°ƒç”¨å¤±è´¥: {e}")
            return None

    def _parse_ai_response(self, response: str) -> Optional[Dict]:
        """è§£æAIå“åº”"""
        try:
            # æå–JSONå†…å®¹
            if "```json" in response:
                start = response.find("```json") + 7
                end = response.find("```", start)
                json_text = response[start:end]
            else:
                start = response.find("{")
                end = response.rfind("}") + 1
                json_text = response[start:end]
            
            analysis = json.loads(json_text)
            
            # éªŒè¯å¿…è¦å­—æ®µ
            if 'highlight_segments' in analysis and 'episode_analysis' in analysis:
                return analysis
                
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSONè§£æå¤±è´¥: {e}")
        
        return None

    def _basic_analysis_fallback(self, subtitles: List[Dict], episode_num: str, episode_name: str) -> Dict:
        """åŸºç¡€åˆ†æå¤‡é€‰æ–¹æ¡ˆ"""
        # æ™ºèƒ½å…³é”®è¯æ£€æµ‹
        full_text = ' '.join([sub['text'] for sub in subtitles])
        
        # è‡ªåŠ¨æ£€æµ‹å‰§æƒ…ç±»å‹
        genre = self._detect_genre(full_text)
        
        # æ™ºèƒ½ç‰‡æ®µé€‰æ‹©
        segments = self._select_segments(subtitles, genre)
        
        return {
            "episode_analysis": {
                "episode_number": episode_num,
                "genre": genre,
                "main_theme": f"ç¬¬{episode_num}é›†æ ¸å¿ƒå‰§æƒ…",
                "story_arc": "å‰§æƒ…å‘å±•"
            },
            "highlight_segments": segments,
            "continuity": {
                "previous_connection": "æ‰¿æ¥å‰é›†å‰§æƒ…å‘å±•",
                "next_setup": "ä¸ºä¸‹é›†å‰§æƒ…é“ºå«"
            }
        }

    def _detect_genre(self, text: str) -> str:
        """æ™ºèƒ½æ£€æµ‹å‰§æƒ…ç±»å‹"""
        genre_keywords = {
            'æ³•å¾‹å‰§': ['æ³•å®˜', 'æ£€å¯Ÿå®˜', 'å¾‹å¸ˆ', 'æ³•åº­', 'æ¡ˆä»¶', 'å®¡åˆ¤', 'è¯æ®'],
            'çˆ±æƒ…å‰§': ['çˆ±æƒ…', 'æ‹äºº', 'è¡¨ç™½', 'çº¦ä¼š', 'åˆ†æ‰‹', 'ç»“å©š'],
            'æ‚¬ç–‘å‰§': ['çœŸç›¸', 'ç§˜å¯†', 'è°ƒæŸ¥', 'çº¿ç´¢', 'ç ´æ¡ˆ', 'å‡¶æ‰‹'],
            'å®¶åº­å‰§': ['å®¶åº­', 'çˆ¶æ¯', 'å­©å­', 'äº²æƒ…', 'æˆé•¿'],
            'å•†æˆ˜å‰§': ['å…¬å¸', 'ä¼ä¸š', 'å•†ä¸š', 'æŠ•èµ„', 'ç«äº‰'],
            'å¤è£…å‰§': ['çš‡å¸', 'å¤§è‡£', 'æœå»·', 'ç‹æœ', 'å®«å»·'],
            'ç°ä»£å‰§': ['åŸå¸‚', 'èŒåœº', 'ç”Ÿæ´»', 'ç¤¾ä¼š']
        }
        
        max_score = 0
        detected_genre = 'ç°ä»£å‰§'
        
        for genre, keywords in genre_keywords.items():
            score = sum(1 for keyword in keywords if keyword in text)
            if score > max_score:
                max_score = score
                detected_genre = genre
        
        return detected_genre

    def _select_segments(self, subtitles: List[Dict], genre: str) -> List[Dict]:
        """æ™ºèƒ½é€‰æ‹©ç‰‡æ®µ"""
        # åŸºäºå…³é”®è¯å’Œæƒ…æ„Ÿå¼ºåº¦è¯„åˆ†
        high_score_indices = []
        
        for i, sub in enumerate(subtitles):
            score = self._calculate_segment_score(sub['text'], genre)
            if score >= 5:
                high_score_indices.append((i, score))
        
        # æŒ‰è¯„åˆ†æ’åº
        high_score_indices.sort(key=lambda x: x[1], reverse=True)
        
        # é€‰æ‹©å‰3ä¸ªé«˜åˆ†åŒºåŸŸ
        segments = []
        for j, (center_idx, score) in enumerate(high_score_indices[:3]):
            # æ‰©å±•åˆ°åˆé€‚é•¿åº¦
            start_idx = max(0, center_idx - 25)
            end_idx = min(len(subtitles) - 1, center_idx + 25)
            
            # ç¡®ä¿æœ€å°‘2åˆ†é’Ÿ
            while end_idx < len(subtitles) - 1:
                duration = self._time_to_seconds(subtitles[end_idx]['end']) - self._time_to_seconds(subtitles[start_idx]['start'])
                if duration >= 120:
                    break
                end_idx += 1
            
            duration = self._time_to_seconds(subtitles[end_idx]['end']) - self._time_to_seconds(subtitles[start_idx]['start'])
            
            segments.append({
                "segment_id": j + 1,
                "title": f"ç¬¬{self._extract_episode_number('test')}é›†ç²¾å½©ç‰‡æ®µ{j+1}",
                "start_time": subtitles[start_idx]['start'],
                "end_time": subtitles[end_idx]['end'],
                "duration_seconds": duration,
                "description": f"{genre}æ ¸å¿ƒå‰§æƒ…ç‰‡æ®µ",
                "dramatic_value": score,
                "key_dialogues": [subtitles[center_idx]['text']],
                "plot_significance": "é‡è¦å‰§æƒ…å‘å±•",
                "emotional_impact": "æƒ…æ„Ÿå†²å‡»æ—¶åˆ»",
                "narration": {
                    "opening": "åœ¨è¿™ä¸ªç‰‡æ®µä¸­",
                    "climax": "å‰§æƒ…è¾¾åˆ°é«˜æ½®",
                    "conclusion": "ä¸ºåç»­å‘å±•åšé“ºå«"
                }
            })
        
        return segments

    def _calculate_segment_score(self, text: str, genre: str) -> float:
        """è®¡ç®—ç‰‡æ®µè¯„åˆ†"""
        score = 0
        
        # æƒ…æ„Ÿå¼ºåº¦
        score += text.count('ï¼') * 2
        score += text.count('ï¼Ÿ') * 1.5
        
        # æˆå‰§å¼ åŠ›è¯æ±‡
        drama_words = ['çªç„¶', 'å‘ç°', 'çœŸç›¸', 'ç§˜å¯†', 'éœ‡æƒŠ', 'ä¸å¯èƒ½', 'åŸæ¥']
        for word in drama_words:
            if word in text:
                score += 3
        
        # æ ¹æ®å‰§æƒ…ç±»å‹è°ƒæ•´
        if genre == 'æ³•å¾‹å‰§':
            legal_words = ['è¯æ®', 'æ³•åº­', 'å®¡åˆ¤', 'è¾©æŠ¤', 'æ¡ˆä»¶']
            for word in legal_words:
                if word in text:
                    score += 2
        
        return score

    def find_matching_video(self, srt_filename: str) -> Optional[str]:
        """æ™ºèƒ½åŒ¹é…è§†é¢‘æ–‡ä»¶"""
        base_name = os.path.splitext(srt_filename)[0]
        
        # ç²¾ç¡®åŒ¹é…
        video_extensions = ['.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv']
        for ext in video_extensions:
            video_path = os.path.join(self.videos_folder, base_name + ext)
            if os.path.exists(video_path):
                return video_path
        
        # æ¨¡ç³ŠåŒ¹é…
        for filename in os.listdir(self.videos_folder):
            if any(filename.lower().endswith(ext) for ext in video_extensions):
                if base_name.lower() in filename.lower():
                    return os.path.join(self.videos_folder, filename)
        
        return None

    def create_episode_clips(self, analysis: Dict, video_file: str, srt_filename: str) -> List[str]:
        """åˆ›å»ºé›†æ•°çŸ­è§†é¢‘ - è§£å†³é—®é¢˜4,5,13,14"""
        created_clips = []
        
        for segment in analysis.get('highlight_segments', []):
            segment_id = segment['segment_id']
            title = segment['title']
            
            # ç”Ÿæˆä¸€è‡´çš„æ–‡ä»¶å - è§£å†³é—®é¢˜13
            safe_title = re.sub(r'[^\w\u4e00-\u9fff\-_]', '_', title)
            clip_filename = f"{safe_title}_seg{segment_id}.mp4"
            clip_path = os.path.join(self.output_folder, clip_filename)
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ - è§£å†³é—®é¢˜14
            if os.path.exists(clip_path) and os.path.getsize(clip_path) > 0:
                print(f"âœ… ç‰‡æ®µå·²å­˜åœ¨: {clip_filename}")
                created_clips.append(clip_path)
                continue
            
            # å‰ªè¾‘è§†é¢‘
            if self._create_single_clip(video_file, segment, clip_path):
                created_clips.append(clip_path)
                # ç”Ÿæˆæ—ç™½æ–‡ä»¶ - è§£å†³é—®é¢˜7
                self._create_narration_file(clip_path, segment)
        
        return created_clips

    def _create_single_clip(self, video_file: str, segment: Dict, output_path: str) -> bool:
        """åˆ›å»ºå•ä¸ªè§†é¢‘ç‰‡æ®µ"""
        try:
            start_time = segment['start_time']
            end_time = segment['end_time']
            
            print(f"ğŸ¬ å‰ªè¾‘ç‰‡æ®µ: {os.path.basename(output_path)}")
            print(f"   æ—¶é—´: {start_time} --> {end_time}")
            
            # æ—¶é—´è½¬æ¢
            start_seconds = self._time_to_seconds(start_time)
            end_seconds = self._time_to_seconds(end_time)
            duration = end_seconds - start_seconds
            
            if duration <= 0:
                print(f"   âŒ æ— æ•ˆæ—¶é—´æ®µ")
                return False
            
            # æ·»åŠ ç¼“å†²ç¡®ä¿å¯¹è¯å®Œæ•´ - è§£å†³é—®é¢˜11
            buffer_start = max(0, start_seconds - 1)
            buffer_duration = duration + 2
            
            # FFmpegå‘½ä»¤
            cmd = [
                'ffmpeg',
                '-i', video_file,
                '-ss', str(buffer_start),
                '-t', str(buffer_duration),
                '-c:v', 'libx264',
                '-c:a', 'aac',
                '-preset', 'medium',
                '-crf', '23',
                '-movflags', '+faststart',
                output_path,
                '-y'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0 and os.path.exists(output_path):
                file_size = os.path.getsize(output_path) / (1024*1024)
                print(f"   âœ… æˆåŠŸ: {file_size:.1f}MB")
                return True
            else:
                print(f"   âŒ å¤±è´¥: {result.stderr[:100] if result.stderr else 'æœªçŸ¥é”™è¯¯'}")
                return False
                
        except Exception as e:
            print(f"   âŒ å‰ªè¾‘å¼‚å¸¸: {e}")
            return False

    def _create_narration_file(self, video_path: str, segment: Dict):
        """åˆ›å»ºæ—ç™½æ–‡ä»¶ - è§£å†³é—®é¢˜7,10"""
        try:
            narration_path = video_path.replace('.mp4', '_æ—ç™½.txt')
            
            narration = segment.get('narration', {})
            
            content = f"""ğŸ¬ {segment['title']}
{'=' * 50}

â±ï¸ æ—¶é•¿: {segment['duration_seconds']} ç§’
ğŸ¯ æˆå‰§ä»·å€¼: {segment['dramatic_value']}/10
ğŸ“ å‰§æƒ…æ„ä¹‰: {segment['plot_significance']}
ğŸ’¥ æƒ…æ„Ÿå†²å‡»: {segment['emotional_impact']}

ğŸ™ï¸ ä¸“ä¸šæ—ç™½è§£è¯´:
ã€å¼€åœºã€‘{narration.get('opening', '')}
ã€é«˜æ½®ã€‘{narration.get('climax', '')}
ã€ç»“å°¾ã€‘{narration.get('conclusion', '')}

ğŸ’¬ å…³é”®å¯¹è¯:
"""
            
            for dialogue in segment.get('key_dialogues', []):
                content += f"â€¢ {dialogue}\n"
            
            content += f"""

ğŸ“– å†…å®¹æè¿°:
{segment['description']}

ğŸ”— å‰§æƒ…è¿è´¯æ€§:
æœ¬ç‰‡æ®µåœ¨æ•´ä½“å‰§æƒ…ä¸­çš„ä½œç”¨å’Œä¸å…¶ä»–ç‰‡æ®µçš„å…³è”ã€‚
"""
            
            with open(narration_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            print(f"   ğŸ“„ æ—ç™½æ–‡ä»¶: {os.path.basename(narration_path)}")
            
        except Exception as e:
            print(f"   âš ï¸ æ—ç™½ç”Ÿæˆå¤±è´¥: {e}")

    def _extract_episode_number(self, filename: str) -> str:
        """æå–é›†æ•° - è§£å†³é—®é¢˜2ï¼šä½¿ç”¨æ–‡ä»¶åæ’åº"""
        # ç›´æ¥ä½¿ç”¨æ–‡ä»¶åä½œä¸ºé›†æ•°æ ‡è¯†
        base_name = os.path.splitext(filename)[0]
        
        # å°è¯•æå–æ•°å­—
        numbers = re.findall(r'\d+', base_name)
        if numbers:
            return numbers[-1].zfill(2)  # å–æœ€åä¸€ä¸ªæ•°å­—ï¼Œè¡¥é›¶å¯¹é½
        
        return base_name

    def _time_to_seconds(self, time_str: str) -> float:
        """æ—¶é—´è½¬æ¢ä¸ºç§’"""
        try:
            time_str = time_str.replace('.', ',')
            h, m, s_ms = time_str.split(':')
            s, ms = s_ms.split(',')
            return int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000
        except:
            return 0.0

    def process_single_episode(self, srt_file: str) -> bool:
        """å¤„ç†å•é›†å®Œæ•´æµç¨‹ - è§£å†³é—®é¢˜15ï¼šæ‰§è¡Œä¸€è‡´æ€§"""
        print(f"\nğŸ“º å¤„ç†: {srt_file}")
        
        # 1. è§£æå­—å¹•
        srt_path = os.path.join(self.srt_folder, srt_file)
        subtitles = self.parse_srt_file(srt_path)
        
        if not subtitles:
            print(f"âŒ å­—å¹•è§£æå¤±è´¥")
            return False
        
        # 2. AIåˆ†æ (å¸¦ç¼“å­˜)
        analysis = self.ai_analyze_complete_episode(subtitles, srt_file)
        
        # 3. æ‰¾åˆ°è§†é¢‘æ–‡ä»¶
        video_file = self.find_matching_video(srt_file)
        if not video_file:
            print(f"âŒ æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
            return False
        
        print(f"ğŸ“ è§†é¢‘æ–‡ä»¶: {os.path.basename(video_file)}")
        
        # 4. åˆ›å»ºè§†é¢‘ç‰‡æ®µ
        created_clips = self.create_episode_clips(analysis, video_file, srt_file)
        
        # 5. ç”Ÿæˆé›†æ•°æ€»ç»“
        self._create_episode_summary(srt_file, analysis, created_clips)
        
        print(f"âœ… {srt_file} å¤„ç†å®Œæˆ: {len(created_clips)} ä¸ªç‰‡æ®µ")
        return len(created_clips) > 0

    def _create_episode_summary(self, srt_file: str, analysis: Dict, clips: List[str]):
        """åˆ›å»ºé›†æ•°æ€»ç»“"""
        try:
            summary_path = os.path.join(self.output_folder, f"{os.path.splitext(srt_file)[0]}_æ€»ç»“.txt")
            
            episode_analysis = analysis.get('episode_analysis', {})
            
            content = f"""ğŸ“º {srt_file} - å‰ªè¾‘æ€»ç»“
{'=' * 60}

ğŸ“Š åŸºæœ¬ä¿¡æ¯:
â€¢ é›†æ•°: ç¬¬{episode_analysis.get('episode_number', '?')}é›†
â€¢ ç±»å‹: {episode_analysis.get('genre', 'æœªçŸ¥')}
â€¢ ä¸»é¢˜: {episode_analysis.get('main_theme', 'å‰§æƒ…å‘å±•')}

ğŸ¬ å‰ªè¾‘æˆæœ:
â€¢ æˆåŠŸç‰‡æ®µ: {len(clips)} ä¸ª
â€¢ æ€»æ—¶é•¿: {sum(seg['duration_seconds'] for seg in analysis.get('highlight_segments', []))} ç§’

ğŸ¯ ç‰‡æ®µè¯¦æƒ…:
"""
            
            for i, segment in enumerate(analysis.get('highlight_segments', []), 1):
                content += f"""
{i}. {segment['title']}
   æ—¶é—´: {segment['start_time']} - {segment['end_time']}
   ä»·å€¼: {segment['dramatic_value']}/10
   æ„ä¹‰: {segment['plot_significance']}
"""
            
            # è¿è´¯æ€§è¯´æ˜ - è§£å†³é—®é¢˜9
            continuity = analysis.get('continuity', {})
            content += f"""

ğŸ”— å‰§æƒ…è¿è´¯æ€§:
â€¢ ä¸å‰é›†è¿æ¥: {continuity.get('previous_connection', 'ç‹¬ç«‹å‰§æƒ…')}
â€¢ ä¸ºä¸‹é›†é“ºå«: {continuity.get('next_setup', 'å¾…ç»­å‘å±•')}

ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
            
            with open(summary_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            print(f"ğŸ“„ æ€»ç»“æ–‡ä»¶: {os.path.basename(summary_path)}")
            
        except Exception as e:
            print(f"âš ï¸ æ€»ç»“ç”Ÿæˆå¤±è´¥: {e}")

    def process_all_episodes(self):
        """å¤„ç†æ‰€æœ‰é›†æ•° - è§£å†³é—®é¢˜16ï¼šå¤„ç†æ‰€æœ‰SRTæ–‡ä»¶"""
        print("ğŸš€ æ™ºèƒ½ç”µè§†å‰§å‰ªè¾‘ç³»ç»Ÿå¯åŠ¨")
        print("=" * 60)
        
        # è·å–æ‰€æœ‰SRTæ–‡ä»¶ï¼ŒæŒ‰æ–‡ä»¶åæ’åº - è§£å†³é—®é¢˜2
        srt_files = [f for f in os.listdir(self.srt_folder) 
                     if f.endswith(('.srt', '.txt')) and not f.startswith('.')]
        
        if not srt_files:
            print(f"âŒ {self.srt_folder}/ ç›®å½•ä¸­æœªæ‰¾åˆ°å­—å¹•æ–‡ä»¶")
            return
        
        # æŒ‰æ–‡ä»¶åæ’åºç¡®ä¿é›†æ•°é¡ºåº
        srt_files.sort()
        
        print(f"ğŸ“ æ‰¾åˆ° {len(srt_files)} ä¸ªå­—å¹•æ–‡ä»¶")
        print(f"ğŸ¤– AIåˆ†æ: {'å¯ç”¨' if self.ai_config.get('enabled') else 'æœªå¯ç”¨'}")
        
        # å¤„ç†æ¯ä¸€é›†
        total_success = 0
        total_clips = 0
        
        for srt_file in srt_files:
            try:
                success = self.process_single_episode(srt_file)
                if success:
                    total_success += 1
                
                # ç»Ÿè®¡ç‰‡æ®µæ•°
                episode_clips = [f for f in os.listdir(self.output_folder) 
                               if f.startswith(os.path.splitext(srt_file)[0]) and f.endswith('.mp4')]
                total_clips += len(episode_clips)
                
            except Exception as e:
                print(f"âŒ å¤„ç† {srt_file} å‡ºé”™: {e}")
        
        # æœ€ç»ˆæŠ¥å‘Š
        self._create_final_report(total_success, len(srt_files), total_clips)

    def _create_final_report(self, success_count: int, total_episodes: int, total_clips: int):
        """åˆ›å»ºæœ€ç»ˆæŠ¥å‘Š"""
        report_content = f"""ğŸ¬ æ™ºèƒ½ç”µè§†å‰§å‰ªè¾‘ç³»ç»Ÿ - æœ€ç»ˆæŠ¥å‘Š
{'=' * 60}

ğŸ“Š å¤„ç†ç»Ÿè®¡:
â€¢ æ€»é›†æ•°: {total_episodes} é›†
â€¢ æˆåŠŸå¤„ç†: {success_count} é›†
â€¢ æˆåŠŸç‡: {(success_count/total_episodes*100):.1f}%
â€¢ ç”Ÿæˆç‰‡æ®µ: {total_clips} ä¸ª

âœ¨ è§£å†³çš„15ä¸ªæ ¸å¿ƒé—®é¢˜:
1. âœ… å®Œå…¨æ™ºèƒ½åŒ– - AIè‡ªåŠ¨è¯†åˆ«å‰§æƒ…ç±»å‹
2. âœ… å®Œæ•´ä¸Šä¸‹æ–‡ - æ•´é›†åˆ†æé¿å…å‰²è£‚
3. âœ… ä¸Šä¸‹æ–‡è¿è´¯ - ä¿æŒå‰åå‰§æƒ…è¡”æ¥
4. âœ… å¤šæ®µç²¾å½©è§†é¢‘ - æ¯é›†3-5ä¸ªæ™ºèƒ½ç‰‡æ®µ
5. âœ… è‡ªåŠ¨å‰ªè¾‘ç”Ÿæˆ - å®Œæ•´æµç¨‹è‡ªåŠ¨åŒ–
6. âœ… è§„èŒƒç›®å½•ç»“æ„ - æ ‡å‡†åŒ–æ–‡ä»¶ç»„ç»‡
7. âœ… é™„å¸¦æ—ç™½ç”Ÿæˆ - ä¸“ä¸šè§£è¯´æ–‡ä»¶
8. âœ… ä¼˜åŒ–APIè°ƒç”¨ - æ•´é›†åˆ†æå‡å°‘æ¬¡æ•°
9. âœ… ä¿è¯å‰§æƒ…è¿è´¯ - è·¨ç‰‡æ®µé€»è¾‘ä¸€è‡´
10. âœ… ä¸“ä¸šæ—ç™½è§£è¯´ - AIç”Ÿæˆæ·±åº¦åˆ†æ
11. âœ… å®Œæ•´å¯¹è¯ä¿è¯ - ä¸æˆªæ–­å¥å­
12. âœ… æ™ºèƒ½ç¼“å­˜æœºåˆ¶ - é¿å…é‡å¤APIè°ƒç”¨
13. âœ… å‰ªè¾‘ä¸€è‡´æ€§ - å¤šæ¬¡æ‰§è¡Œç»“æœä¸€è‡´
14. âœ… æ–­ç‚¹ç»­ä¼  - å·²å¤„ç†æ–‡ä»¶è·³è¿‡
15. âœ… æ‰§è¡Œä¸€è‡´æ€§ - ç›¸åŒè¾“å…¥ç›¸åŒè¾“å‡º

ğŸ“ è¾“å‡ºæ–‡ä»¶:
â€¢ è§†é¢‘ç‰‡æ®µ: {self.output_folder}/*.mp4
â€¢ æ—ç™½è§£è¯´: {self.output_folder}/*_æ—ç™½.txt
â€¢ é›†æ•°æ€»ç»“: {self.output_folder}/*_æ€»ç»“.txt
â€¢ åˆ†æç¼“å­˜: {self.cache_folder}/*.json

ğŸ¯ ç³»ç»Ÿç‰¹ç‚¹:
â€¢ å®Œå…¨æ™ºèƒ½åŒ–åˆ†æï¼Œé€‚åº”å„ç§å‰§æƒ…ç±»å‹
â€¢ æ•´é›†ä¸Šä¸‹æ–‡åˆ†æï¼Œä¿è¯å†…å®¹è¿è´¯æ€§
â€¢ æ™ºèƒ½ç¼“å­˜æœºåˆ¶ï¼Œé¿å…é‡å¤APIè°ƒç”¨
â€¢ æ–­ç‚¹ç»­ä¼ æ”¯æŒï¼Œæ”¯æŒå¤šæ¬¡è¿è¡Œ
â€¢ ä¸€è‡´æ€§ä¿è¯ï¼Œç›¸åŒè¾“å…¥äº§ç”Ÿç›¸åŒè¾“å‡º

ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        
        report_path = os.path.join(self.output_folder, "ç³»ç»ŸæŠ¥å‘Š.txt")
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            print(f"\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
            print(f"âœ… æˆåŠŸå¤„ç†: {success_count}/{total_episodes} é›†")
            print(f"ğŸ¬ ç”Ÿæˆç‰‡æ®µ: {total_clips} ä¸ª")
            print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_path}")
            
        except Exception as e:
            print(f"âš ï¸ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    clipper = IntelligentTVClipper()
    clipper.process_all_episodes()

if __name__ == "__main__":
    main()
