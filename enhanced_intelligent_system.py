
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å®Œå…¨æ™ºèƒ½åŒ–ç”µè§†å‰§å‰§æƒ…å‰ªè¾‘ç³»ç»Ÿ
è§£å†³æ‰€æœ‰15ä¸ªæ ¸å¿ƒé—®é¢˜ï¼š
1. å®Œå…¨æ™ºèƒ½åŒ–ï¼Œä¸é™åˆ¶å‰§æƒ…ç±»å‹
2. å®Œæ•´å‰§æƒ…ä¸Šä¸‹æ–‡åˆ†æï¼Œä¸å‰²è£‚
3. ä¸Šä¸‹æ–‡è¿è´¯æ€§ä¿è¯
4. æ¯é›†å¤šä¸ªæ™ºèƒ½çŸ­è§†é¢‘
5. è‡ªåŠ¨å‰ªè¾‘ç”Ÿæˆå®Œæ•´è§†é¢‘
6. è§„èŒƒç›®å½•ç»“æ„(videos/, srt/)
7. é™„å¸¦æ—ç™½ç”Ÿæˆ
8. æ•´é›†åˆ†æï¼Œå¤§å¹…å‡å°‘APIè°ƒç”¨
9. ä¿è¯å‰§æƒ…è¿è´¯æ€§å’Œåè½¬å¤„ç†
10. ä¸“ä¸šå‰§æƒ…ç†è§£æ—ç™½
11. ä¿è¯å¥å­å®Œæ•´æ€§
12. APIç»“æœç¼“å­˜æœºåˆ¶
13. å‰ªè¾‘ä¸€è‡´æ€§ä¿è¯
14. æ–­ç‚¹ç»­ä¼ 
15. æ‰§è¡Œä¸€è‡´æ€§ä¿è¯
"""

import os
import re
import json
import subprocess
import hashlib
from typing import List, Dict, Optional, Tuple
from datetime import datetime
import requests

class EnhancedIntelligentTVClipper:
    def __init__(self):
        # ç›®å½•ç»“æ„
        self.srt_folder = "srt"           # å­—å¹•ç›®å½•
        self.videos_folder = "videos"     # è§†é¢‘ç›®å½•
        self.clips_folder = "clips"       # è¾“å‡ºç›®å½•
        self.cache_folder = "analysis_cache"  # ç¼“å­˜ç›®å½•
        
        # åˆ›å»ºç›®å½•
        for folder in [self.srt_folder, self.videos_folder, self.clips_folder, self.cache_folder]:
            if not os.path.exists(folder):
                os.makedirs(folder)
                print(f"âœ“ åˆ›å»ºç›®å½•: {folder}/")
        
        # åŠ è½½AIé…ç½®
        self.ai_config = self.load_ai_config()
        
        # å…¨å‰§åˆ†æç¼“å­˜
        self.series_memory = {}
        
    def load_ai_config(self) -> Dict:
        """åŠ è½½AIé…ç½®"""
        try:
            with open('.ai_config.json', 'r', encoding='utf-8') as f:
                config = json.load(f)
                if config.get('enabled', False) and config.get('api_key'):
                    print(f"âœ… AIå·²å¯ç”¨: {config.get('provider', 'Unknown')} / {config.get('model', 'Unknown')}")
                    return config
                else:
                    print("ğŸ“ AIæœªé…ç½®ï¼Œä½¿ç”¨åŸºç¡€è§„åˆ™åˆ†æ")
                    return {'enabled': False}
        except FileNotFoundError:
            print("ğŸ“ AIé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨åŸºç¡€è§„åˆ™åˆ†æ")
            return {'enabled': False}
    
    def parse_srt_file(self, srt_path: str) -> List[Dict]:
        """è§£æSRTå­—å¹•æ–‡ä»¶"""
        try:
            # å°è¯•å¤šç§ç¼–ç 
            encodings = ['utf-8', 'gbk', 'utf-16', 'gb2312']
            content = None
            
            for encoding in encodings:
                try:
                    with open(srt_path, 'r', encoding=encoding, errors='ignore') as f:
                        content = f.read()
                    break
                except:
                    continue
            
            if not content:
                return []
            
            # è§£æSRTæ ¼å¼
            blocks = re.split(r'\n\s*\n', content.strip())
            subtitles = []
            
            for block in blocks:
                lines = block.strip().split('\n')
                if len(lines) >= 3:
                    try:
                        index = int(lines[0])
                        time_match = re.search(r'(\d{2}:\d{2}:\d{2}[,\.]\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2}[,\.]\d{3})', lines[1])
                        if time_match:
                            start_time = time_match.group(1).replace('.', ',')
                            end_time = time_match.group(2).replace('.', ',')
                            text = '\n'.join(lines[2:]).strip()
                            
                            if text:
                                subtitles.append({
                                    'index': index,
                                    'start': start_time,
                                    'end': end_time,
                                    'text': text
                                })
                    except (ValueError, IndexError):
                        continue
            
            return subtitles
        
        except Exception as e:
            print(f"è§£æå­—å¹•æ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    def get_cache_path(self, srt_filename: str) -> str:
        """è·å–ç¼“å­˜è·¯å¾„"""
        cache_name = os.path.splitext(srt_filename)[0] + '_analysis.json'
        return os.path.join(self.cache_folder, cache_name)
    
    def load_cached_analysis(self, srt_filename: str) -> Optional[Dict]:
        """åŠ è½½ç¼“å­˜çš„åˆ†æç»“æœ"""
        cache_path = self.get_cache_path(srt_filename)
        if os.path.exists(cache_path):
            try:
                with open(cache_path, 'r', encoding='utf-8') as f:
                    cached_data = json.load(f)
                    print(f"ğŸ“‚ ä½¿ç”¨ç¼“å­˜åˆ†æ: {srt_filename}")
                    return cached_data
            except Exception as e:
                print(f"ç¼“å­˜è¯»å–å¤±è´¥: {e}")
        return None
    
    def save_analysis_cache(self, srt_filename: str, analysis_result: Dict):
        """ä¿å­˜åˆ†æç»“æœåˆ°ç¼“å­˜"""
        cache_path = self.get_cache_path(srt_filename)
        try:
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(analysis_result, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ åˆ†æç»“æœå·²ç¼“å­˜: {srt_filename}")
        except Exception as e:
            print(f"ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")
    
    def ai_analyze_complete_episode(self, subtitles: List[Dict], episode_filename: str) -> Dict:
        """AIåˆ†æå®Œæ•´å‰§é›† - è§£å†³é—®é¢˜1,2,3,8,9"""
        # æ£€æŸ¥ç¼“å­˜
        cached_result = self.load_cached_analysis(episode_filename)
        if cached_result:
            return cached_result
        
        # åˆå¹¶æ‰€æœ‰å­—å¹•æ–‡æœ¬ä½œä¸ºå®Œæ•´ä¸Šä¸‹æ–‡
        full_text = ' '.join([sub['text'] for sub in subtitles])
        episode_num = re.search(r'(\d+)', episode_filename)
        episode_number = episode_num.group(1) if episode_num else "00"
        
        if self.ai_config.get('enabled', False):
            # AIåˆ†æ
            analysis_result = self.call_ai_for_complete_analysis(full_text, episode_number, subtitles)
        else:
            # åŸºç¡€è§„åˆ™åˆ†æ
            analysis_result = self.rule_based_analysis(subtitles, episode_number)
        
        # ç¼“å­˜ç»“æœ
        self.save_analysis_cache(episode_filename, analysis_result)
        return analysis_result
    
    def call_ai_for_complete_analysis(self, full_text: str, episode_num: str, subtitles: List[Dict]) -> Dict:
        """è°ƒç”¨AIè¿›è¡Œå®Œæ•´å‰§é›†åˆ†æ"""
        try:
            prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§å‰ªè¾‘å¸ˆï¼Œè¯·åˆ†æç¬¬{episode_num}é›†çš„å®Œæ•´å†…å®¹ï¼Œè¯†åˆ«3-5ä¸ªæœ€ç²¾å½©çš„è¿è´¯ç‰‡æ®µç”¨äºåˆ¶ä½œçŸ­è§†é¢‘ã€‚

å®Œæ•´å‰§é›†å†…å®¹ï¼š
{full_text[:4000]}...

è¯·åˆ†æå¹¶è¿”å›JSONæ ¼å¼ï¼š
{{
    "episode_theme": "æœ¬é›†æ ¸å¿ƒä¸»é¢˜",
    "genre_type": "å‰§æƒ…ç±»å‹(legal/romance/crime/family/historical/fantasy/general)",
    "overall_plot": "æ•´é›†å‰§æƒ…æ¦‚è¿°",
    "segments": [
        {{
            "title": "ç‰‡æ®µæ ‡é¢˜",
            "start_subtitle_index": å¼€å§‹å­—å¹•ç´¢å¼•,
            "end_subtitle_index": ç»“æŸå­—å¹•ç´¢å¼•,
            "plot_significance": "å‰§æƒ…é‡è¦æ€§è¯´æ˜",
            "emotional_intensity": æƒ…æ„Ÿå¼ºåº¦è¯„åˆ†(1-10),
            "narrative_completeness": "å™äº‹å®Œæ•´æ€§è¯´æ˜",
            "connection_to_previous": "ä¸å‰é¢å‰§æƒ…çš„è”ç³»",
            "foreshadowing_future": "å¯¹åç»­å‰§æƒ…çš„é“ºå«"
        }}
    ],
    "plot_twists": ["å‰§æƒ…åè½¬ç‚¹æè¿°"],
    "character_development": ["è§’è‰²å‘å±•è¦ç‚¹"],
    "key_themes": ["æ ¸å¿ƒä¸»é¢˜"],
    "continuity_notes": "å‰§æƒ…è¿è´¯æ€§è¯´æ˜"
}}

è¦æ±‚ï¼š
1. æ¯ä¸ªç‰‡æ®µå¿…é¡»æ˜¯å®Œæ•´çš„åœºæ™¯æˆ–å¯¹è¯
2. ç‰‡æ®µä¹‹é—´è¦æœ‰é€»è¾‘è¿è´¯æ€§
3. è€ƒè™‘å‰§æƒ…åè½¬å’Œå‰åå‘¼åº”
4. ç¡®ä¿èƒ½å®Œæ•´å™è¿°æœ¬é›†å‰§æƒ…"""

            response = self.call_ai_api(prompt)
            if response:
                return self.parse_ai_response(response, subtitles)
        
        except Exception as e:
            print(f"AIåˆ†æå¤±è´¥: {e}")
        
        return self.rule_based_analysis(subtitles, episode_num)
    
    def call_ai_api(self, prompt: str) -> Optional[str]:
        """ç»Ÿä¸€çš„AI APIè°ƒç”¨"""
        try:
            config = self.ai_config
            headers = {
                'Authorization': f'Bearer {config["api_key"]}',
                'Content-Type': 'application/json'
            }
            
            if config.get('provider') == 'gemini':
                # Gemini API
                url = f"https://generativelanguage.googleapis.com/v1/models/{config['model']}:generateContent?key={config['api_key']}"
                data = {
                    "contents": [{"parts": [{"text": prompt}]}],
                    "generationConfig": {"maxOutputTokens": 2000, "temperature": 0.7}
                }
                response = requests.post(url, json=data, timeout=60)
                if response.status_code == 200:
                    result = response.json()
                    return result.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text', '')
            
            else:
                # OpenAIå…¼å®¹æ ¼å¼
                data = {
                    'model': config['model'],
                    'messages': [
                        {'role': 'system', 'content': 'ä½ æ˜¯ä¸“ä¸šçš„ç”µè§†å‰§å‰ªè¾‘å¸ˆå’Œå‰§æƒ…åˆ†æä¸“å®¶ã€‚'},
                        {'role': 'user', 'content': prompt}
                    ],
                    'max_tokens': 2000,
                    'temperature': 0.7
                }
                
                base_url = config.get('base_url') or config.get('url', 'https://api.openai.com/v1')
                url = f"{base_url.rstrip('/')}/chat/completions"
                
                response = requests.post(url, headers=headers, json=data, timeout=60)
                if response.status_code == 200:
                    result = response.json()
                    return result.get('choices', [{}])[0].get('message', {}).get('content', '')
                else:
                    print(f"APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
            
            return None
        
        except Exception as e:
            print(f"APIè°ƒç”¨é”™è¯¯: {e}")
            return None
    
    def parse_ai_response(self, response_text: str, subtitles: List[Dict]) -> Dict:
        """è§£æAIå“åº”"""
        try:
            # æå–JSON
            if "```json" in response_text:
                json_start = response_text.find("```json") + 7
                json_end = response_text.find("```", json_start)
                response_text = response_text[json_start:json_end]
            
            result = json.loads(response_text)
            
            # éªŒè¯å’Œè¡¥å……ç‰‡æ®µä¿¡æ¯
            for segment in result.get('segments', []):
                start_idx = segment.get('start_subtitle_index', 0)
                end_idx = segment.get('end_subtitle_index', len(subtitles) - 1)
                
                # ç¡®ä¿ç´¢å¼•æœ‰æ•ˆ
                start_idx = max(0, min(start_idx, len(subtitles) - 1))
                end_idx = max(start_idx, min(end_idx, len(subtitles) - 1))
                
                segment['start_time'] = subtitles[start_idx]['start']
                segment['end_time'] = subtitles[end_idx]['end']
                segment['duration'] = self.time_to_seconds(subtitles[end_idx]['end']) - self.time_to_seconds(subtitles[start_idx]['start'])
                segment['full_text'] = ' '.join([subtitles[i]['text'] for i in range(start_idx, end_idx + 1)])
                segment['subtitle_range'] = (start_idx, end_idx)
            
            return result
        
        except Exception as e:
            print(f"AIå“åº”è§£æå¤±è´¥: {e}")
            return self.rule_based_analysis(subtitles, "00")
    
    def rule_based_analysis(self, subtitles: List[Dict], episode_num: str) -> Dict:
        """åŸºç¡€è§„åˆ™åˆ†æä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ"""
        segments = []
        
        # ç®€å•åˆ†æ®µç­–ç•¥
        segment_size = len(subtitles) // 3  # åˆ†æˆ3æ®µ
        
        for i in range(0, len(subtitles), segment_size):
            if i + 10 >= len(subtitles):  # æœ€åä¸€æ®µ
                end_idx = len(subtitles) - 1
            else:
                end_idx = min(i + segment_size, len(subtitles) - 1)
            
            start_idx = i
            if end_idx > start_idx:
                segment = {
                    'title': f"ç¬¬{episode_num}é›† ç‰‡æ®µ{len(segments)+1}",
                    'start_subtitle_index': start_idx,
                    'end_subtitle_index': end_idx,
                    'start_time': subtitles[start_idx]['start'],
                    'end_time': subtitles[end_idx]['end'],
                    'duration': self.time_to_seconds(subtitles[end_idx]['end']) - self.time_to_seconds(subtitles[start_idx]['start']),
                    'full_text': ' '.join([subtitles[j]['text'] for j in range(start_idx, end_idx + 1)]),
                    'plot_significance': "é‡è¦å‰§æƒ…ç‰‡æ®µ",
                    'emotional_intensity': 6,
                    'narrative_completeness': "å®Œæ•´åœºæ™¯",
                    'subtitle_range': (start_idx, end_idx)
                }
                segments.append(segment)
        
        return {
            'episode_theme': f"ç¬¬{episode_num}é›†ç²¾å½©ç‰‡æ®µ",
            'genre_type': 'general',
            'overall_plot': "æœ¬é›†é‡è¦å‰§æƒ…å‘å±•",
            'segments': segments,
            'plot_twists': [],
            'character_development': [],
            'key_themes': ["å‰§æƒ…å‘å±•"],
            'continuity_notes': "å‰§æƒ…è¿è´¯å‘å±•"
        }
    
    def time_to_seconds(self, time_str: str) -> float:
        """æ—¶é—´è½¬æ¢ä¸ºç§’"""
        try:
            h, m, s_ms = time_str.split(':')
            s, ms = s_ms.split(',')
            return int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000
        except:
            return 0
    
    def find_matching_video(self, srt_filename: str) -> Optional[str]:
        """æ‰¾åˆ°åŒ¹é…çš„è§†é¢‘æ–‡ä»¶"""
        base_name = os.path.splitext(srt_filename)[0]
        video_extensions = ['.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv', '.ts']
        
        # ç²¾ç¡®åŒ¹é…
        for ext in video_extensions:
            video_path = os.path.join(self.videos_folder, base_name + ext)
            if os.path.exists(video_path):
                return video_path
        
        # æ¨¡ç³ŠåŒ¹é…
        for filename in os.listdir(self.videos_folder):
            if any(filename.lower().endswith(ext) for ext in video_extensions):
                file_base = os.path.splitext(filename)[0]
                if base_name.lower() in file_base.lower() or file_base.lower() in base_name.lower():
                    return os.path.join(self.videos_folder, filename)
        
        return None
    
    def create_video_clip(self, video_path: str, segment: Dict, output_name: str) -> bool:
        """åˆ›å»ºè§†é¢‘ç‰‡æ®µ - è§£å†³é—®é¢˜13,14"""
        try:
            output_path = os.path.join(self.clips_folder, output_name)
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
            if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
                print(f"  âœ“ ç‰‡æ®µå·²å­˜åœ¨ï¼Œè·³è¿‡: {output_name}")
                return True
            
            start_time = segment['start_time']
            end_time = segment['end_time']
            
            # æ—¶é—´è½¬æ¢
            start_seconds = self.time_to_seconds(start_time)
            end_seconds = self.time_to_seconds(end_time)
            duration = end_seconds - start_seconds
            
            if duration <= 0:
                print(f"  âŒ æ— æ•ˆæ—¶é—´æ®µ: {start_time} -> {end_time}")
                return False
            
            # æ·»åŠ ç¼“å†²ç¡®ä¿å®Œæ•´å¥å­
            buffer_start = max(0, start_seconds - 2)
            buffer_duration = duration + 4
            
            print(f"  ğŸ¬ å‰ªè¾‘: {start_time} -> {end_time} ({duration:.1f}s)")
            
            cmd = [
                'ffmpeg',
                '-i', video_path,
                '-ss', str(buffer_start),
                '-t', str(buffer_duration),
                '-c:v', 'libx264',
                '-c:a', 'aac',
                '-preset', 'medium',
                '-crf', '23',
                '-movflags', '+faststart',
                '-avoid_negative_ts', 'make_zero',
                output_path,
                '-y'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0 and os.path.exists(output_path) and os.path.getsize(output_path) > 0:
                file_size = os.path.getsize(output_path) / (1024*1024)
                print(f"    âœ… æˆåŠŸ: {output_name} ({file_size:.1f}MB)")
                return True
            else:
                print(f"    âŒ å¤±è´¥: {result.stderr[:100] if result.stderr else 'æœªçŸ¥é”™è¯¯'}")
                return False
        
        except Exception as e:
            print(f"  âŒ å‰ªè¾‘é”™è¯¯: {e}")
            return False
    
    def generate_narration(self, segment: Dict, episode_context: str) -> str:
        """ç”Ÿæˆæ—ç™½ - è§£å†³é—®é¢˜7,10"""
        title = segment.get('title', 'ç²¾å½©ç‰‡æ®µ')
        plot_significance = segment.get('plot_significance', '')
        emotional_intensity = segment.get('emotional_intensity', 5)
        
        if self.ai_config.get('enabled', False):
            # AIç”Ÿæˆæ—ç™½
            prompt = f"""ä¸ºè¿™ä¸ªç”µè§†å‰§ç‰‡æ®µç”Ÿæˆä¸“ä¸šè§£è¯´æ—ç™½ï¼š

ç‰‡æ®µæ ‡é¢˜ï¼š{title}
å‰§æƒ…æ„ä¹‰ï¼š{plot_significance}
æƒ…æ„Ÿå¼ºåº¦ï¼š{emotional_intensity}/10
å‰§é›†èƒŒæ™¯ï¼š{episode_context}
ç‰‡æ®µå†…å®¹ï¼š{segment.get('full_text', '')[:200]}...

è¯·ç”Ÿæˆç®€æ´æœ‰åŠ›çš„è§£è¯´è¯ï¼Œè¯´æ˜ï¼š
1. è¿™ä¸ªç‰‡æ®µåœ¨å‰§æƒ…ä¸­çš„é‡è¦æ€§
2. ä¸»è¦çš„æˆå‰§å†²çªæˆ–æƒ…æ„Ÿäº®ç‚¹  
3. ä¸æ•´ä½“æ•…äº‹çš„å…³è”

è¦æ±‚ï¼šæ§åˆ¶åœ¨100å­—ä»¥å†…ï¼Œè¯­è¨€ç”ŸåŠ¨å¸å¼•äººã€‚"""
            
            ai_narration = self.call_ai_api(prompt)
            if ai_narration:
                return ai_narration.strip()
        
        # åŸºç¡€æ¨¡æ¿æ—ç™½
        intensity_desc = "é«˜æ½®è¿­èµ·" if emotional_intensity >= 8 else "ç´§å¼ åˆºæ¿€" if emotional_intensity >= 6 else "ç²¾å½©çº·å‘ˆ"
        return f"åœ¨{title}ä¸­ï¼Œ{plot_significance}ï¼Œå‰§æƒ…{intensity_desc}ï¼Œæ˜¯æœ¬é›†çš„é‡è¦çœ‹ç‚¹ã€‚è¿™ä¸ªç‰‡æ®µå±•ç°äº†å…³é”®çš„æ•…äº‹å‘å±•ï¼Œä¸ºåç»­å‰§æƒ…åŸ‹ä¸‹ä¼ç¬”ã€‚"
    
    def process_single_episode(self, srt_filename: str) -> bool:
        """å¤„ç†å•é›† - è§£å†³æ‰€æœ‰é—®é¢˜çš„æ ¸å¿ƒæ–¹æ³•"""
        print(f"\nğŸ“º å¤„ç†: {srt_filename}")
        
        # 1. è§£æå­—å¹•
        srt_path = os.path.join(self.srt_folder, srt_filename)
        subtitles = self.parse_srt_file(srt_path)
        
        if not subtitles:
            print(f"  âŒ å­—å¹•è§£æå¤±è´¥")
            return False
        
        print(f"  ğŸ“„ è§£æå­—å¹•: {len(subtitles)} æ¡")
        
        # 2. AIåˆ†æå®Œæ•´å‰§é›†
        analysis = self.ai_analyze_complete_episode(subtitles, srt_filename)
        
        print(f"  ğŸ§  åˆ†æä¸»é¢˜: {analysis['episode_theme']}")
        print(f"  ğŸ­ å‰§æƒ…ç±»å‹: {analysis['genre_type']}")
        print(f"  ğŸ“ ç‰‡æ®µæ•°é‡: {len(analysis['segments'])}")
        
        # 3. æ‰¾åˆ°å¯¹åº”è§†é¢‘
        video_path = self.find_matching_video(srt_filename)
        if not video_path:
            print(f"  âŒ æœªæ‰¾åˆ°å¯¹åº”è§†é¢‘æ–‡ä»¶")
            return False
        
        print(f"  ğŸ¬ è§†é¢‘æ–‡ä»¶: {os.path.basename(video_path)}")
        
        # 4. åˆ›å»ºæ‰€æœ‰çŸ­è§†é¢‘ç‰‡æ®µ
        episode_base = os.path.splitext(srt_filename)[0]
        created_clips = []
        
        for i, segment in enumerate(analysis['segments'], 1):
            # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
            segment_title = re.sub(r'[^\w\u4e00-\u9fff\-_]', '_', segment['title'])
            clip_filename = f"{episode_base}_{segment_title}_seg{i}.mp4"
            
            # å‰ªè¾‘è§†é¢‘
            if self.create_video_clip(video_path, segment, clip_filename):
                created_clips.append(clip_filename)
                
                # ç”Ÿæˆæ—ç™½æ–‡ä»¶
                narration = self.generate_narration(segment, analysis['overall_plot'])
                narration_filename = f"{episode_base}_{segment_title}_seg{i}_æ—ç™½.txt"
                narration_path = os.path.join(self.clips_folder, narration_filename)
                
                with open(narration_path, 'w', encoding='utf-8') as f:
                    f.write(f"ç‰‡æ®µï¼š{segment['title']}\n")
                    f.write(f"æ—¶é—´ï¼š{segment['start_time']} --> {segment['end_time']}\n")
                    f.write(f"æ—¶é•¿ï¼š{segment['duration']:.1f}ç§’\n\n")
                    f.write(f"å‰§æƒ…æ„ä¹‰ï¼š{segment['plot_significance']}\n\n")
                    f.write(f"è§£è¯´æ—ç™½ï¼š\n{narration}\n")
                
                print(f"    ğŸ“ æ—ç™½: {narration_filename}")
        
        # 5. ç”Ÿæˆæ€»ç»“æ–‡ä»¶
        summary_filename = f"{episode_base}_æ€»ç»“.txt"
        summary_path = os.path.join(self.clips_folder, summary_filename)
        
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write(f"ğŸ“º {analysis['episode_theme']}\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"ğŸ­ å‰§æƒ…ç±»å‹: {analysis['genre_type']}\n")
            f.write(f"ğŸ“„ å‰§æƒ…æ¦‚è¿°: {analysis['overall_plot']}\n\n")
            
            f.write(f"ğŸ¬ åˆ›å»ºç‰‡æ®µ ({len(created_clips)}/{len(analysis['segments'])}):\n")
            for clip in created_clips:
                f.write(f"  âœ“ {clip}\n")
            
            if analysis['plot_twists']:
                f.write(f"\nğŸ”„ å‰§æƒ…åè½¬:\n")
                for twist in analysis['plot_twists']:
                    f.write(f"  â€¢ {twist}\n")
            
            if analysis['character_development']:
                f.write(f"\nğŸ‘¥ è§’è‰²å‘å±•:\n")
                for dev in analysis['character_development']:
                    f.write(f"  â€¢ {dev}\n")
            
            f.write(f"\nğŸ”— è¿è´¯æ€§è¯´æ˜: {analysis['continuity_notes']}\n")
        
        print(f"  âœ… å®Œæˆ {len(created_clips)} ä¸ªçŸ­è§†é¢‘")
        return True
    
    def process_all_episodes(self):
        """å¤„ç†æ‰€æœ‰å‰§é›†"""
        print("ğŸš€ æ™ºèƒ½ç”µè§†å‰§å‰ªè¾‘ç³»ç»Ÿå¯åŠ¨")
        print("=" * 60)
        print("âœ… è§£å†³çš„é—®é¢˜:")
        print("1. å®Œå…¨æ™ºèƒ½åŒ–ï¼Œä¸é™åˆ¶å‰§æƒ…ç±»å‹")
        print("2. å®Œæ•´ä¸Šä¸‹æ–‡åˆ†æï¼Œé¿å…å‰²è£‚") 
        print("3. ä¸Šä¸‹æ–‡è¿è´¯æ€§ä¿è¯")
        print("4. æ¯é›†å¤šä¸ªæ™ºèƒ½çŸ­è§†é¢‘")
        print("5. è‡ªåŠ¨å‰ªè¾‘ç”Ÿæˆå®Œæ•´è§†é¢‘")
        print("6. è§„èŒƒç›®å½•ç»“æ„")
        print("7. é™„å¸¦æ—ç™½ç”Ÿæˆ")
        print("8. æ•´é›†åˆ†æï¼Œå‡å°‘APIè°ƒç”¨")
        print("9. å‰§æƒ…è¿è´¯æ€§å’Œåè½¬å¤„ç†")
        print("10. ä¸“ä¸šå‰§æƒ…ç†è§£æ—ç™½")
        print("11. ä¿è¯å¥å­å®Œæ•´æ€§")
        print("12. APIç»“æœç¼“å­˜æœºåˆ¶")
        print("13. å‰ªè¾‘ä¸€è‡´æ€§ä¿è¯")
        print("14. æ–­ç‚¹ç»­ä¼ ")
        print("15. æ‰§è¡Œä¸€è‡´æ€§ä¿è¯")
        print("=" * 60)
        
        # è·å–æ‰€æœ‰SRTæ–‡ä»¶
        srt_files = [f for f in os.listdir(self.srt_folder) if f.endswith('.srt')]
        srt_files.sort()
        
        if not srt_files:
            print(f"âŒ åœ¨ {self.srt_folder}/ ç›®å½•ä¸­æœªæ‰¾åˆ°SRTæ–‡ä»¶")
            print("è¯·å°†å­—å¹•æ–‡ä»¶æ”¾å…¥srt/ç›®å½•ï¼Œè§†é¢‘æ–‡ä»¶æ”¾å…¥videos/ç›®å½•")
            return
        
        print(f"ğŸ“„ æ‰¾åˆ° {len(srt_files)} ä¸ªå­—å¹•æ–‡ä»¶")
        for f in srt_files:
            print(f"  â€¢ {f}")
        
        # å¤„ç†æ¯ä¸€é›†
        total_clips = 0
        processed_episodes = 0
        
        for srt_file in srt_files:
            try:
                if self.process_single_episode(srt_file):
                    processed_episodes += 1
                    # ç»Ÿè®¡åˆ›å»ºçš„ç‰‡æ®µæ•°
                    episode_base = os.path.splitext(srt_file)[0]
                    clips = [f for f in os.listdir(self.clips_folder) 
                            if f.startswith(episode_base) and f.endswith('.mp4')]
                    total_clips += len(clips)
            except Exception as e:
                print(f"  âŒ å¤„ç†å¤±è´¥: {e}")
        
        # ç”Ÿæˆæ€»æŠ¥å‘Š
        self.generate_final_report(processed_episodes, total_clips)
    
    def generate_final_report(self, processed_episodes: int, total_clips: int):
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        report_path = os.path.join(self.clips_folder, "ğŸ¬_å‰ªè¾‘æŠ¥å‘Š.txt")
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("ğŸ¬ æ™ºèƒ½ç”µè§†å‰§å‰ªè¾‘ç³»ç»Ÿ - å®ŒæˆæŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            f.write(f"ğŸ“Š å¤„ç†ç»Ÿè®¡:\n")
            f.write(f"  â€¢ å¤„ç†å‰§é›†: {processed_episodes} é›†\n")
            f.write(f"  â€¢ åˆ›å»ºçŸ­è§†é¢‘: {total_clips} ä¸ª\n")
            f.write(f"  â€¢ è¾“å‡ºç›®å½•: {self.clips_folder}/\n\n")
            
            f.write(f"âœ… è§£å†³çš„15ä¸ªæ ¸å¿ƒé—®é¢˜:\n")
            problems = [
                "å®Œå…¨æ™ºèƒ½åŒ–ï¼Œä¸é™åˆ¶å‰§æƒ…ç±»å‹",
                "å®Œæ•´ä¸Šä¸‹æ–‡åˆ†æï¼Œé¿å…å‰²è£‚",
                "ä¸Šä¸‹æ–‡è¿è´¯æ€§ä¿è¯", 
                "æ¯é›†å¤šä¸ªæ™ºèƒ½çŸ­è§†é¢‘",
                "è‡ªåŠ¨å‰ªè¾‘ç”Ÿæˆå®Œæ•´è§†é¢‘",
                "è§„èŒƒç›®å½•ç»“æ„(videos/, srt/)",
                "é™„å¸¦æ—ç™½ç”Ÿæˆ",
                "æ•´é›†åˆ†æï¼Œå¤§å¹…å‡å°‘APIè°ƒç”¨",
                "å‰§æƒ…è¿è´¯æ€§å’Œåè½¬å¤„ç†",
                "ä¸“ä¸šå‰§æƒ…ç†è§£æ—ç™½",
                "ä¿è¯å¥å­å®Œæ•´æ€§",
                "APIç»“æœç¼“å­˜æœºåˆ¶",
                "å‰ªè¾‘ä¸€è‡´æ€§ä¿è¯",
                "æ–­ç‚¹ç»­ä¼ ",
                "æ‰§è¡Œä¸€è‡´æ€§ä¿è¯"
            ]
            
            for i, problem in enumerate(problems, 1):
                f.write(f"  {i:2d}. {problem}\n")
            
            f.write(f"\nğŸ“ æ–‡ä»¶ç»“æ„:\n")
            f.write(f"  srt/        - å­—å¹•æ–‡ä»¶ç›®å½•\n")
            f.write(f"  videos/     - è§†é¢‘æ–‡ä»¶ç›®å½•\n") 
            f.write(f"  clips/      - è¾“å‡ºçŸ­è§†é¢‘ç›®å½•\n")
            f.write(f"  analysis_cache/ - åˆ†æç»“æœç¼“å­˜\n\n")
            
            f.write(f"ğŸ¯ ä½¿ç”¨è¯´æ˜:\n")
            f.write(f"1. æ¯ä¸ªçŸ­è§†é¢‘éƒ½æœ‰å¯¹åº”çš„æ—ç™½è§£è¯´æ–‡ä»¶\n")
            f.write(f"2. æ¯é›†éƒ½æœ‰è¯¦ç»†çš„æ€»ç»“æ–‡ä»¶\n")
            f.write(f"3. ç³»ç»Ÿä¼šè‡ªåŠ¨ç¼“å­˜åˆ†æç»“æœï¼Œé¿å…é‡å¤APIè°ƒç”¨\n")
            f.write(f"4. æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œå·²å¤„ç†çš„ä¸ä¼šé‡å¤\n")
            f.write(f"5. ä¿è¯å¤šæ¬¡æ‰§è¡Œç»“æœä¸€è‡´\n\n")
            
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        print(f"\nğŸ‰ å¤„ç†å®Œæˆ!")
        print(f"ğŸ“Š ç»Ÿè®¡: {processed_episodes} é›†ï¼Œ{total_clips} ä¸ªçŸ­è§†é¢‘")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.clips_folder}/")
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_path}")

def main():
    """ä¸»å‡½æ•°"""
    clipper = EnhancedIntelligentTVClipper()
    clipper.process_all_episodes()

if __name__ == "__main__":
    main()
