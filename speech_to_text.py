#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è¯­éŸ³è½¬æ–‡å­—æ¨¡å—
ä½¿ç”¨AI APIå°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡å­—å­—å¹•
"""

import os
import json
import hashlib
from typing import Optional, Dict, List
from config_manager import ConfigManager
from multi_module_api_helper import MultiModuleAPIHelper


class SpeechToText:
    """è¯­éŸ³è½¬æ–‡å­— - ä½¿ç”¨AI APIè¿›è¡Œè¯­éŸ³è¯†åˆ«"""

    def __init__(self, config_manager: ConfigManager, api_helper: MultiModuleAPIHelper):
        """åˆå§‹åŒ–è¯­éŸ³è½¬æ–‡å­—æ¨¡å—"""
        self.config_manager = config_manager
        self.api_helper = api_helper

        paths = config_manager.get_paths()
        self.srt_folder = paths.get('srt_folder', 'srt')
        self.cache_folder = paths.get('analysis_cache', 'cache')

        # åˆ›å»ºç›®å½•
        os.makedirs(self.srt_folder, exist_ok=True)
        os.makedirs(self.cache_folder, exist_ok=True)

    def transcribe_audio(self, audio_path: str, video_name: str = None) -> Optional[str]:
        """
        è½¬å½•éŸ³é¢‘ä¸ºæ–‡å­—å¹¶ç”ŸæˆSRTå­—å¹•

        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            video_name: è§†é¢‘åç§°ï¼ˆç”¨äºç”Ÿæˆå­—å¹•æ–‡ä»¶åï¼‰

        Returns:
            SRTå­—å¹•æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        if not os.path.exists(audio_path):
            print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
            return None

        # æ£€æŸ¥ç¼“å­˜
        cached_srt = self.check_transcription_cache(audio_path)
        if cached_srt:
            print(f"ğŸ’¾ ä½¿ç”¨ç¼“å­˜çš„å­—å¹•: {os.path.basename(cached_srt)}")
            return cached_srt

        print(f"ğŸ™ï¸ å¼€å§‹è¯­éŸ³è¯†åˆ«: {os.path.basename(audio_path)}")

        # è°ƒç”¨APIè¿›è¡Œè½¬å½•
        transcription = self._call_transcription_api(audio_path)

        if not transcription:
            print(f"âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥")
            return None

        # ç”ŸæˆSRTæ–‡ä»¶
        srt_path = self._generate_srt_file(transcription, audio_path, video_name)

        if srt_path:
            print(f"âœ… å­—å¹•ç”ŸæˆæˆåŠŸ: {os.path.basename(srt_path)}")
            # ä¿å­˜ç¼“å­˜
            self._save_transcription_cache(audio_path, transcription, srt_path)
            return srt_path
        else:
            print(f"âŒ å­—å¹•ç”Ÿæˆå¤±è´¥")
            return None

    def _call_transcription_api(self, audio_path: str) -> Optional[Dict]:
        """è°ƒç”¨APIè¿›è¡Œè¯­éŸ³è¯†åˆ«"""
        module_config = self.config_manager.get_module_config('speech_to_text')

        if not module_config or not module_config.get('enabled'):
            print(f"âŒ è¯­éŸ³è½¬æ–‡å­—æ¨¡å—æœªå¯ç”¨")
            return None

        provider = module_config.get('provider', '').lower()

        try:
            if provider == 'openai':
                return self._transcribe_with_openai(audio_path, module_config)
            elif provider == 'gemini':
                return self._transcribe_with_gemini(audio_path, module_config)
            else:
                print(f"âŒ ä¸æ”¯æŒçš„è¯­éŸ³è¯†åˆ«æä¾›å•†: {provider}")
                return None
        except Exception as e:
            print(f"âŒ è¯­éŸ³è¯†åˆ«APIè°ƒç”¨å¤±è´¥: {e}")
            return None

    def _transcribe_with_openai(self, audio_path: str, config: Dict) -> Optional[Dict]:
        """ä½¿ç”¨OpenAI Whisper APIè½¬å½•"""
        try:
            from openai import OpenAI

            client = OpenAI(
                api_key=config['api_key'],
                base_url=config.get('base_url', 'https://api.openai.com/v1')
            )

            with open(audio_path, 'rb') as audio_file:
                transcript = client.audio.transcriptions.create(
                    model=config.get('model', 'whisper-1'),
                    file=audio_file,
                    response_format='verbose_json',
                    language=config.get('language', 'zh')
                )

            # è§£æå“åº”
            return self._parse_whisper_response(transcript)

        except Exception as e:
            print(f"âš ï¸ OpenAI Whisper APIè°ƒç”¨å¤±è´¥: {e}")
            return None

    def _transcribe_with_gemini(self, audio_path: str, config: Dict) -> Optional[Dict]:
        """ä½¿ç”¨Gemini APIè½¬å½•ï¼ˆå¦‚æœæ”¯æŒï¼‰"""
        print(f"âš ï¸ Geminiè¯­éŸ³è¯†åˆ«åŠŸèƒ½æš‚æœªå®ç°")
        return None

    def _parse_whisper_response(self, transcript) -> Dict:
        """è§£æWhisper APIå“åº”"""
        segments = []

        if hasattr(transcript, 'segments'):
            for seg in transcript.segments:
                segments.append({
                    'start': seg.get('start', 0),
                    'end': seg.get('end', 0),
                    'text': seg.get('text', '').strip()
                })
        else:
            # å¦‚æœæ²¡æœ‰åˆ†æ®µä¿¡æ¯ï¼Œåˆ›å»ºå•ä¸ªåˆ†æ®µ
            segments.append({
                'start': 0,
                'end': 0,
                'text': transcript.text if hasattr(transcript, 'text') else str(transcript)
            })

        return {
            'text': transcript.text if hasattr(transcript, 'text') else '',
            'segments': segments
        }

    def _generate_srt_file(
        self,
        transcription: Dict,
        audio_path: str,
        video_name: str = None
    ) -> Optional[str]:
        """ç”ŸæˆSRTå­—å¹•æ–‡ä»¶"""
        try:
            segments = transcription.get('segments', [])

            if not segments:
                print(f"âš ï¸ æ²¡æœ‰å¯ç”¨çš„å­—å¹•åˆ†æ®µ")
                return None

            # ç”ŸæˆSRTæ–‡ä»¶è·¯å¾„
            if video_name:
                srt_filename = f"{video_name}.srt"
            else:
                audio_basename = os.path.splitext(os.path.basename(audio_path))[0]
                srt_filename = f"{audio_basename}.srt"

            srt_path = os.path.join(self.srt_folder, srt_filename)

            # ç”ŸæˆSRTå†…å®¹
            srt_content = self._build_srt_content(segments)

            # ä¿å­˜æ–‡ä»¶
            with open(srt_path, 'w', encoding='utf-8') as f:
                f.write(srt_content)

            return srt_path

        except Exception as e:
            print(f"âš ï¸ SRTæ–‡ä»¶ç”Ÿæˆå¤±è´¥: {e}")
            return None

    def _build_srt_content(self, segments: List[Dict]) -> str:
        """æ„å»ºSRTæ ¼å¼å†…å®¹"""
        srt_lines = []

        for i, segment in enumerate(segments, 1):
            start_time = self._format_timestamp(segment['start'])
            end_time = self._format_timestamp(segment['end'])
            text = segment['text'].strip()

            if text:
                srt_lines.append(f"{i}")
                srt_lines.append(f"{start_time} --> {end_time}")
                srt_lines.append(text)
                srt_lines.append("")

        return '\n'.join(srt_lines)

    def _format_timestamp(self, seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´æˆ³ä¸ºSRTæ ¼å¼"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        ms = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{ms:03d}"

    def check_transcription_cache(self, audio_path: str) -> Optional[str]:
        """æ£€æŸ¥è½¬å½•ç¼“å­˜"""
        cache_path = self._get_cache_path(audio_path)

        if os.path.exists(cache_path):
            try:
                with open(cache_path, 'r', encoding='utf-8') as f:
                    cache_data = json.load(f)
                    srt_path = cache_data.get('srt_path')

                    if srt_path and os.path.exists(srt_path):
                        return srt_path
            except:
                pass

        return None

    def _save_transcription_cache(
        self,
        audio_path: str,
        transcription: Dict,
        srt_path: str
    ):
        """ä¿å­˜è½¬å½•ç¼“å­˜"""
        try:
            cache_path = self._get_cache_path(audio_path)
            cache_data = {
                'audio_path': audio_path,
                'srt_path': srt_path,
                'transcription': transcription,
                'timestamp': os.path.getmtime(audio_path)
            }

            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)

        except Exception as e:
            print(f"âš ï¸ ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")

    def _get_cache_path(self, audio_path: str) -> str:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        audio_hash = self._get_file_hash(audio_path)
        cache_filename = f"transcription_{audio_hash}.json"
        return os.path.join(self.cache_folder, cache_filename)

    def _get_file_hash(self, file_path: str) -> str:
        """è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼"""
        try:
            hasher = hashlib.md5()
            with open(file_path, 'rb') as f:
                data = f.read(1024 * 1024)  # è¯»å–å‰1MB
                hasher.update(data)
            return hasher.hexdigest()[:12]
        except:
            file_stat = os.stat(file_path)
            fallback = f"{os.path.basename(file_path)}_{file_stat.st_size}"
            return hashlib.md5(fallback.encode()).hexdigest()[:12]
